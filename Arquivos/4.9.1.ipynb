{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/200, Total Reward: -742.50, Win Rate: 0.49, Wins: 410, Losses: 420, Epsilon: 0.4950, Steps: 36754, Time: 142.32s\n",
      "Ações: Manter=11500, Comprar=12740, Vender=12514\n",
      "Ganhos Totais: 8323.25, Perdas Totais: -9065.75\n",
      "Modelo e log do episódio 1 salvos em: 4.9.1\\model_episode_1.pth e 4.9.1\\log_episode_1.csv\n",
      "\n",
      "Episode 2/200, Total Reward: -665.00, Win Rate: 0.52, Wins: 448, Losses: 419, Epsilon: 0.4900, Steps: 36754, Time: 157.40s\n",
      "Ações: Manter=10466, Comprar=12807, Vender=13481\n",
      "Ganhos Totais: 8944.25, Perdas Totais: -9609.25\n",
      "Modelo e log do episódio 2 salvos em: 4.9.1\\model_episode_2.pth e 4.9.1\\log_episode_2.csv\n",
      "\n",
      "Episode 3/200, Total Reward: 103.00, Win Rate: 0.48, Wins: 387, Losses: 418, Epsilon: 0.4851, Steps: 36754, Time: 157.56s\n",
      "Ações: Manter=12191, Comprar=10982, Vender=13581\n",
      "Ganhos Totais: 9326.25, Perdas Totais: -9223.25\n",
      "Modelo e log do episódio 3 salvos em: 4.9.1\\model_episode_3.pth e 4.9.1\\log_episode_3.csv\n",
      "\n",
      "Episode 4/200, Total Reward: -1132.25, Win Rate: 0.50, Wins: 412, Losses: 412, Epsilon: 0.4803, Steps: 36754, Time: 184.24s\n",
      "Ações: Manter=13554, Comprar=10593, Vender=12607\n",
      "Ganhos Totais: 8418.50, Perdas Totais: -9550.75\n",
      "Modelo e log do episódio 4 salvos em: 4.9.1\\model_episode_4.pth e 4.9.1\\log_episode_4.csv\n",
      "\n",
      "Episode 5/200, Total Reward: -1769.00, Win Rate: 0.46, Wins: 366, Losses: 426, Epsilon: 0.4755, Steps: 36754, Time: 186.05s\n",
      "Ações: Manter=11465, Comprar=12758, Vender=12531\n",
      "Ganhos Totais: 7561.00, Perdas Totais: -9330.00\n",
      "Modelo e log do episódio 5 salvos em: 4.9.1\\model_episode_5.pth e 4.9.1\\log_episode_5.csv\n",
      "\n",
      "Episode 6/200, Total Reward: -1856.50, Win Rate: 0.50, Wins: 416, Losses: 420, Epsilon: 0.4707, Steps: 36754, Time: 201.66s\n",
      "Ações: Manter=12215, Comprar=11823, Vender=12716\n",
      "Ganhos Totais: 8153.00, Perdas Totais: -10009.50\n",
      "Modelo e log do episódio 6 salvos em: 4.9.1\\model_episode_6.pth e 4.9.1\\log_episode_6.csv\n",
      "\n",
      "Episode 7/200, Total Reward: -1724.75, Win Rate: 0.47, Wins: 376, Losses: 424, Epsilon: 0.4660, Steps: 36754, Time: 182.54s\n",
      "Ações: Manter=11705, Comprar=10796, Vender=14253\n",
      "Ganhos Totais: 7642.75, Perdas Totais: -9367.50\n",
      "Modelo e log do episódio 7 salvos em: 4.9.1\\model_episode_7.pth e 4.9.1\\log_episode_7.csv\n",
      "\n",
      "Episode 8/200, Total Reward: 793.00, Win Rate: 0.52, Wins: 454, Losses: 419, Epsilon: 0.4614, Steps: 36754, Time: 175.57s\n",
      "Ações: Manter=11375, Comprar=11634, Vender=13745\n",
      "Ganhos Totais: 9801.50, Perdas Totais: -9008.50\n",
      "Modelo e log do episódio 8 salvos em: 4.9.1\\model_episode_8.pth e 4.9.1\\log_episode_8.csv\n",
      "\n",
      "Episode 9/200, Total Reward: 663.50, Win Rate: 0.52, Wins: 459, Losses: 419, Epsilon: 0.4568, Steps: 36754, Time: 175.65s\n",
      "Ações: Manter=11735, Comprar=12831, Vender=12188\n",
      "Ganhos Totais: 9648.50, Perdas Totais: -8985.00\n",
      "Modelo e log do episódio 9 salvos em: 4.9.1\\model_episode_9.pth e 4.9.1\\log_episode_9.csv\n",
      "\n",
      "Episode 10/200, Total Reward: -667.25, Win Rate: 0.49, Wins: 400, Losses: 418, Epsilon: 0.4522, Steps: 36754, Time: 176.75s\n",
      "Ações: Manter=11923, Comprar=11974, Vender=12857\n",
      "Ganhos Totais: 8362.50, Perdas Totais: -9029.75\n",
      "Modelo e log do episódio 10 salvos em: 4.9.1\\model_episode_10.pth e 4.9.1\\log_episode_10.csv\n",
      "\n",
      "Episode 11/200, Total Reward: 1975.50, Win Rate: 0.49, Wins: 405, Losses: 416, Epsilon: 0.4477, Steps: 36754, Time: 175.88s\n",
      "Ações: Manter=11879, Comprar=10990, Vender=13885\n",
      "Ganhos Totais: 10059.00, Perdas Totais: -8083.50\n",
      "Modelo e log do episódio 11 salvos em: 4.9.1\\model_episode_11.pth e 4.9.1\\log_episode_11.csv\n",
      "\n",
      "Episode 12/200, Total Reward: -1043.75, Win Rate: 0.51, Wins: 441, Losses: 422, Epsilon: 0.4432, Steps: 36754, Time: 177.05s\n",
      "Ações: Manter=11074, Comprar=10914, Vender=14766\n",
      "Ganhos Totais: 8650.50, Perdas Totais: -9694.25\n",
      "Modelo e log do episódio 12 salvos em: 4.9.1\\model_episode_12.pth e 4.9.1\\log_episode_12.csv\n",
      "\n",
      "Episode 13/200, Total Reward: 764.75, Win Rate: 0.50, Wins: 407, Losses: 412, Epsilon: 0.4388, Steps: 36754, Time: 179.37s\n",
      "Ações: Manter=12412, Comprar=11215, Vender=13127\n",
      "Ganhos Totais: 9151.50, Perdas Totais: -8386.75\n",
      "Modelo e log do episódio 13 salvos em: 4.9.1\\model_episode_13.pth e 4.9.1\\log_episode_13.csv\n",
      "\n",
      "Episode 14/200, Total Reward: -642.75, Win Rate: 0.51, Wins: 424, Losses: 413, Epsilon: 0.4344, Steps: 36754, Time: 166.53s\n",
      "Ações: Manter=12790, Comprar=10700, Vender=13264\n",
      "Ganhos Totais: 9978.75, Perdas Totais: -10621.50\n",
      "Modelo e log do episódio 14 salvos em: 4.9.1\\model_episode_14.pth e 4.9.1\\log_episode_14.csv\n",
      "\n",
      "Episode 15/200, Total Reward: -252.75, Win Rate: 0.51, Wins: 434, Losses: 415, Epsilon: 0.4300, Steps: 36754, Time: 150.70s\n",
      "Ações: Manter=12536, Comprar=10501, Vender=13717\n",
      "Ganhos Totais: 9114.25, Perdas Totais: -9367.00\n",
      "Modelo e log do episódio 15 salvos em: 4.9.1\\model_episode_15.pth e 4.9.1\\log_episode_15.csv\n",
      "\n",
      "Episode 16/200, Total Reward: -143.50, Win Rate: 0.49, Wins: 399, Losses: 414, Epsilon: 0.4257, Steps: 36754, Time: 147.13s\n",
      "Ações: Manter=10917, Comprar=10714, Vender=15123\n",
      "Ganhos Totais: 9053.75, Perdas Totais: -9197.25\n",
      "Modelo e log do episódio 16 salvos em: 4.9.1\\model_episode_16.pth e 4.9.1\\log_episode_16.csv\n",
      "\n",
      "Episode 17/200, Total Reward: -466.00, Win Rate: 0.53, Wins: 459, Losses: 411, Epsilon: 0.4215, Steps: 36754, Time: 146.75s\n",
      "Ações: Manter=13677, Comprar=12100, Vender=10977\n",
      "Ganhos Totais: 8840.75, Perdas Totais: -9306.75\n",
      "Modelo e log do episódio 17 salvos em: 4.9.1\\model_episode_17.pth e 4.9.1\\log_episode_17.csv\n",
      "\n",
      "Episode 18/200, Total Reward: -444.50, Win Rate: 0.50, Wins: 416, Losses: 411, Epsilon: 0.4173, Steps: 36754, Time: 147.36s\n",
      "Ações: Manter=12166, Comprar=10072, Vender=14516\n",
      "Ganhos Totais: 9569.50, Perdas Totais: -10014.00\n",
      "Modelo e log do episódio 18 salvos em: 4.9.1\\model_episode_18.pth e 4.9.1\\log_episode_18.csv\n",
      "\n",
      "Episode 19/200, Total Reward: -53.00, Win Rate: 0.52, Wins: 443, Losses: 411, Epsilon: 0.4131, Steps: 36754, Time: 147.26s\n",
      "Ações: Manter=12120, Comprar=11671, Vender=12963\n",
      "Ganhos Totais: 9337.00, Perdas Totais: -9390.00\n",
      "Modelo e log do episódio 19 salvos em: 4.9.1\\model_episode_19.pth e 4.9.1\\log_episode_19.csv\n",
      "\n",
      "Episode 20/200, Total Reward: -1667.25, Win Rate: 0.48, Wins: 387, Losses: 414, Epsilon: 0.4090, Steps: 36754, Time: 147.48s\n",
      "Ações: Manter=11831, Comprar=10966, Vender=13957\n",
      "Ganhos Totais: 8224.50, Perdas Totais: -9891.75\n",
      "Episode 21/200, Total Reward: -2177.00, Win Rate: 0.52, Wins: 440, Losses: 414, Epsilon: 0.4049, Steps: 36754, Time: 147.85s\n",
      "Ações: Manter=12093, Comprar=11268, Vender=13393\n",
      "Ganhos Totais: 8656.00, Perdas Totais: -10833.00\n",
      "Episode 22/200, Total Reward: -1905.25, Win Rate: 0.48, Wins: 383, Losses: 417, Epsilon: 0.4008, Steps: 36754, Time: 148.17s\n",
      "Ações: Manter=12612, Comprar=11841, Vender=12301\n",
      "Ganhos Totais: 8102.50, Perdas Totais: -10007.75\n",
      "Episode 23/200, Total Reward: 1269.75, Win Rate: 0.50, Wins: 412, Losses: 414, Epsilon: 0.3968, Steps: 36754, Time: 149.26s\n",
      "Ações: Manter=12249, Comprar=11756, Vender=12749\n",
      "Ganhos Totais: 9898.00, Perdas Totais: -8628.25\n",
      "Modelo e log do episódio 23 salvos em: 4.9.1\\model_episode_23.pth e 4.9.1\\log_episode_23.csv\n",
      "\n",
      "Episode 24/200, Total Reward: 2316.50, Win Rate: 0.51, Wins: 427, Losses: 408, Epsilon: 0.3928, Steps: 36754, Time: 147.78s\n",
      "Ações: Manter=12888, Comprar=10396, Vender=13470\n",
      "Ganhos Totais: 10693.00, Perdas Totais: -8376.50\n",
      "Modelo e log do episódio 24 salvos em: 4.9.1\\model_episode_24.pth e 4.9.1\\log_episode_24.csv\n",
      "\n",
      "Episode 25/200, Total Reward: -1413.00, Win Rate: 0.50, Wins: 409, Losses: 410, Epsilon: 0.3889, Steps: 36754, Time: 148.06s\n",
      "Ações: Manter=12749, Comprar=12522, Vender=11483\n",
      "Ganhos Totais: 9668.50, Perdas Totais: -11081.50\n",
      "Episode 26/200, Total Reward: 681.50, Win Rate: 0.53, Wins: 460, Losses: 408, Epsilon: 0.3850, Steps: 36754, Time: 148.14s\n",
      "Ações: Manter=12911, Comprar=12462, Vender=11381\n",
      "Ganhos Totais: 11370.00, Perdas Totais: -10688.50\n",
      "Modelo e log do episódio 26 salvos em: 4.9.1\\model_episode_26.pth e 4.9.1\\log_episode_26.csv\n",
      "\n",
      "Episode 27/200, Total Reward: 1494.25, Win Rate: 0.50, Wins: 412, Losses: 409, Epsilon: 0.3812, Steps: 36754, Time: 147.90s\n",
      "Ações: Manter=12394, Comprar=10762, Vender=13598\n",
      "Ganhos Totais: 10768.25, Perdas Totais: -9274.00\n",
      "Modelo e log do episódio 27 salvos em: 4.9.1\\model_episode_27.pth e 4.9.1\\log_episode_27.csv\n",
      "\n",
      "Episode 28/200, Total Reward: -734.25, Win Rate: 0.49, Wins: 399, Losses: 414, Epsilon: 0.3774, Steps: 36754, Time: 148.39s\n",
      "Ações: Manter=13307, Comprar=11309, Vender=12138\n",
      "Ganhos Totais: 8829.75, Perdas Totais: -9564.00\n",
      "Episode 29/200, Total Reward: 503.25, Win Rate: 0.49, Wins: 403, Losses: 412, Epsilon: 0.3736, Steps: 36754, Time: 148.60s\n",
      "Ações: Manter=12056, Comprar=11490, Vender=13208\n",
      "Ganhos Totais: 10381.25, Perdas Totais: -9878.00\n",
      "Modelo e log do episódio 29 salvos em: 4.9.1\\model_episode_29.pth e 4.9.1\\log_episode_29.csv\n",
      "\n",
      "Episode 30/200, Total Reward: -738.25, Win Rate: 0.51, Wins: 423, Losses: 414, Epsilon: 0.3699, Steps: 36754, Time: 148.34s\n",
      "Ações: Manter=12868, Comprar=11342, Vender=12544\n",
      "Ganhos Totais: 9185.75, Perdas Totais: -9924.00\n",
      "Episode 31/200, Total Reward: -756.00, Win Rate: 0.50, Wins: 409, Losses: 412, Epsilon: 0.3662, Steps: 36754, Time: 148.44s\n",
      "Ações: Manter=13625, Comprar=9846, Vender=13283\n",
      "Ganhos Totais: 9764.25, Perdas Totais: -10520.25\n",
      "Episode 32/200, Total Reward: -2233.25, Win Rate: 0.51, Wins: 425, Losses: 411, Epsilon: 0.3625, Steps: 36754, Time: 148.83s\n",
      "Ações: Manter=13640, Comprar=11295, Vender=11819\n",
      "Ganhos Totais: 9131.75, Perdas Totais: -11365.00\n",
      "Episode 33/200, Total Reward: 2171.75, Win Rate: 0.52, Wins: 436, Losses: 408, Epsilon: 0.3589, Steps: 36754, Time: 148.61s\n",
      "Ações: Manter=11837, Comprar=12781, Vender=12136\n",
      "Ganhos Totais: 10524.25, Perdas Totais: -8352.50\n",
      "Modelo e log do episódio 33 salvos em: 4.9.1\\model_episode_33.pth e 4.9.1\\log_episode_33.csv\n",
      "\n",
      "Episode 34/200, Total Reward: -1346.25, Win Rate: 0.51, Wins: 421, Losses: 412, Epsilon: 0.3553, Steps: 36754, Time: 149.16s\n",
      "Ações: Manter=13099, Comprar=11931, Vender=11724\n",
      "Ganhos Totais: 9278.25, Perdas Totais: -10624.50\n",
      "Episode 35/200, Total Reward: -868.75, Win Rate: 0.56, Wins: 511, Losses: 408, Epsilon: 0.3517, Steps: 36754, Time: 148.75s\n",
      "Ações: Manter=14979, Comprar=11252, Vender=10523\n",
      "Ganhos Totais: 10817.50, Perdas Totais: -11686.25\n",
      "Episode 36/200, Total Reward: -1428.25, Win Rate: 0.52, Wins: 466, Losses: 424, Epsilon: 0.3482, Steps: 36754, Time: 148.95s\n",
      "Ações: Manter=10791, Comprar=13155, Vender=12808\n",
      "Ganhos Totais: 9275.50, Perdas Totais: -10703.75\n",
      "Episode 37/200, Total Reward: -955.75, Win Rate: 0.51, Wins: 425, Losses: 408, Epsilon: 0.3447, Steps: 36754, Time: 149.12s\n",
      "Ações: Manter=11471, Comprar=13207, Vender=12076\n",
      "Ganhos Totais: 9968.25, Perdas Totais: -10924.00\n",
      "Episode 38/200, Total Reward: -123.75, Win Rate: 0.51, Wins: 429, Losses: 405, Epsilon: 0.3413, Steps: 36754, Time: 148.86s\n",
      "Ações: Manter=10580, Comprar=10850, Vender=15324\n",
      "Ganhos Totais: 9934.00, Perdas Totais: -10057.75\n",
      "Episode 39/200, Total Reward: -2998.00, Win Rate: 0.47, Wins: 371, Losses: 419, Epsilon: 0.3379, Steps: 36754, Time: 148.86s\n",
      "Ações: Manter=14409, Comprar=8968, Vender=13377\n",
      "Ganhos Totais: 9040.75, Perdas Totais: -12038.75\n",
      "Episode 40/200, Total Reward: 274.75, Win Rate: 0.52, Wins: 447, Losses: 409, Epsilon: 0.3345, Steps: 36754, Time: 148.64s\n",
      "Ações: Manter=14116, Comprar=9867, Vender=12771\n",
      "Ganhos Totais: 10307.75, Perdas Totais: -10033.00\n",
      "Episode 41/200, Total Reward: -755.50, Win Rate: 0.53, Wins: 455, Losses: 411, Epsilon: 0.3311, Steps: 36754, Time: 148.83s\n",
      "Ações: Manter=12100, Comprar=12283, Vender=12371\n",
      "Ganhos Totais: 10636.75, Perdas Totais: -11392.25\n",
      "Episode 42/200, Total Reward: 806.00, Win Rate: 0.56, Wins: 514, Losses: 399, Epsilon: 0.3278, Steps: 36754, Time: 149.13s\n",
      "Ações: Manter=12822, Comprar=11089, Vender=12843\n",
      "Ganhos Totais: 11539.25, Perdas Totais: -10733.25\n",
      "Modelo e log do episódio 42 salvos em: 4.9.1\\model_episode_42.pth e 4.9.1\\log_episode_42.csv\n",
      "\n",
      "Episode 43/200, Total Reward: -503.50, Win Rate: 0.51, Wins: 419, Losses: 409, Epsilon: 0.3246, Steps: 36754, Time: 148.91s\n",
      "Ações: Manter=14701, Comprar=10543, Vender=11510\n",
      "Ganhos Totais: 9931.50, Perdas Totais: -10435.00\n",
      "Episode 44/200, Total Reward: -706.50, Win Rate: 0.51, Wins: 424, Losses: 407, Epsilon: 0.3213, Steps: 36754, Time: 149.29s\n",
      "Ações: Manter=13324, Comprar=10118, Vender=13312\n",
      "Ganhos Totais: 10678.50, Perdas Totais: -11385.00\n",
      "Episode 45/200, Total Reward: -369.25, Win Rate: 0.51, Wins: 427, Losses: 408, Epsilon: 0.3181, Steps: 36754, Time: 149.23s\n",
      "Ações: Manter=13929, Comprar=9053, Vender=13772\n",
      "Ganhos Totais: 11380.50, Perdas Totais: -11749.75\n",
      "Episode 46/200, Total Reward: -581.00, Win Rate: 0.50, Wins: 411, Losses: 418, Epsilon: 0.3149, Steps: 36754, Time: 149.14s\n",
      "Ações: Manter=12074, Comprar=11588, Vender=13092\n",
      "Ganhos Totais: 10415.00, Perdas Totais: -10996.00\n",
      "Episode 47/200, Total Reward: 585.50, Win Rate: 0.53, Wins: 463, Losses: 416, Epsilon: 0.3118, Steps: 36754, Time: 149.57s\n",
      "Ações: Manter=10444, Comprar=13991, Vender=12319\n",
      "Ganhos Totais: 10853.50, Perdas Totais: -10268.00\n",
      "Episode 48/200, Total Reward: -535.25, Win Rate: 0.48, Wins: 395, Losses: 420, Epsilon: 0.3086, Steps: 36754, Time: 150.08s\n",
      "Ações: Manter=10198, Comprar=15641, Vender=10915\n",
      "Ganhos Totais: 9220.25, Perdas Totais: -9755.50\n",
      "Episode 49/200, Total Reward: -1988.25, Win Rate: 0.49, Wins: 400, Losses: 410, Epsilon: 0.3056, Steps: 36754, Time: 150.04s\n",
      "Ações: Manter=11644, Comprar=12342, Vender=12768\n",
      "Ganhos Totais: 9479.75, Perdas Totais: -11468.00\n",
      "Episode 50/200, Total Reward: -171.00, Win Rate: 0.54, Wins: 474, Losses: 400, Epsilon: 0.3025, Steps: 36754, Time: 149.59s\n",
      "Ações: Manter=11918, Comprar=14385, Vender=10451\n",
      "Ganhos Totais: 11465.00, Perdas Totais: -11636.00\n",
      "Episode 51/200, Total Reward: 998.00, Win Rate: 0.52, Wins: 456, Losses: 413, Epsilon: 0.2995, Steps: 36754, Time: 149.58s\n",
      "Ações: Manter=11887, Comprar=11580, Vender=13287\n",
      "Ganhos Totais: 11757.00, Perdas Totais: -10759.00\n",
      "Modelo e log do episódio 51 salvos em: 4.9.1\\model_episode_51.pth e 4.9.1\\log_episode_51.csv\n",
      "\n",
      "Episode 52/200, Total Reward: -1334.00, Win Rate: 0.50, Wins: 418, Losses: 417, Epsilon: 0.2965, Steps: 36754, Time: 149.73s\n",
      "Ações: Manter=10552, Comprar=12272, Vender=13930\n",
      "Ganhos Totais: 9748.25, Perdas Totais: -11082.25\n",
      "Episode 53/200, Total Reward: -14.50, Win Rate: 0.53, Wins: 454, Losses: 408, Epsilon: 0.2935, Steps: 36754, Time: 150.40s\n",
      "Ações: Manter=12631, Comprar=10804, Vender=13319\n",
      "Ganhos Totais: 10548.25, Perdas Totais: -10562.75\n",
      "Episode 54/200, Total Reward: -295.00, Win Rate: 0.52, Wins: 434, Losses: 401, Epsilon: 0.2906, Steps: 36754, Time: 150.52s\n",
      "Ações: Manter=11485, Comprar=9908, Vender=15361\n",
      "Ganhos Totais: 11389.25, Perdas Totais: -11684.25\n",
      "Episode 55/200, Total Reward: 765.50, Win Rate: 0.52, Wins: 436, Losses: 407, Epsilon: 0.2877, Steps: 36754, Time: 150.08s\n",
      "Ações: Manter=9767, Comprar=14633, Vender=12354\n",
      "Ganhos Totais: 10926.50, Perdas Totais: -10161.00\n",
      "Modelo e log do episódio 55 salvos em: 4.9.1\\model_episode_55.pth e 4.9.1\\log_episode_55.csv\n",
      "\n",
      "Episode 56/200, Total Reward: 1234.75, Win Rate: 0.51, Wins: 425, Losses: 402, Epsilon: 0.2848, Steps: 36754, Time: 150.08s\n",
      "Ações: Manter=11403, Comprar=12850, Vender=12501\n",
      "Ganhos Totais: 11709.50, Perdas Totais: -10474.75\n",
      "Modelo e log do episódio 56 salvos em: 4.9.1\\model_episode_56.pth e 4.9.1\\log_episode_56.csv\n",
      "\n",
      "Episode 57/200, Total Reward: -981.50, Win Rate: 0.53, Wins: 451, Losses: 401, Epsilon: 0.2820, Steps: 36754, Time: 149.62s\n",
      "Ações: Manter=13104, Comprar=8294, Vender=15356\n",
      "Ganhos Totais: 11137.50, Perdas Totais: -12119.00\n",
      "Episode 58/200, Total Reward: -1665.50, Win Rate: 0.52, Wins: 434, Losses: 398, Epsilon: 0.2791, Steps: 36754, Time: 150.17s\n",
      "Ações: Manter=12266, Comprar=11462, Vender=13026\n",
      "Ganhos Totais: 11825.50, Perdas Totais: -13491.00\n",
      "Episode 59/200, Total Reward: -3122.50, Win Rate: 0.53, Wins: 456, Losses: 397, Epsilon: 0.2763, Steps: 36754, Time: 150.38s\n",
      "Ações: Manter=11164, Comprar=8690, Vender=16900\n",
      "Ganhos Totais: 10772.00, Perdas Totais: -13894.50\n",
      "Episode 60/200, Total Reward: -1398.75, Win Rate: 0.51, Wins: 412, Losses: 397, Epsilon: 0.2736, Steps: 36754, Time: 150.55s\n",
      "Ações: Manter=14208, Comprar=10715, Vender=11831\n",
      "Ganhos Totais: 10141.50, Perdas Totais: -11540.25\n",
      "Episode 61/200, Total Reward: -2583.75, Win Rate: 0.51, Wins: 422, Losses: 401, Epsilon: 0.2708, Steps: 36754, Time: 149.91s\n",
      "Ações: Manter=11309, Comprar=8563, Vender=16882\n",
      "Ganhos Totais: 11573.75, Perdas Totais: -14157.50\n",
      "Episode 62/200, Total Reward: -1464.50, Win Rate: 0.51, Wins: 409, Losses: 397, Epsilon: 0.2681, Steps: 36754, Time: 150.91s\n",
      "Ações: Manter=12330, Comprar=11946, Vender=12478\n",
      "Ganhos Totais: 9840.50, Perdas Totais: -11305.00\n",
      "Episode 63/200, Total Reward: -2970.00, Win Rate: 0.49, Wins: 379, Losses: 397, Epsilon: 0.2655, Steps: 36754, Time: 150.67s\n",
      "Ações: Manter=12477, Comprar=14688, Vender=9589\n",
      "Ganhos Totais: 10114.25, Perdas Totais: -13084.25\n",
      "Episode 64/200, Total Reward: -2985.00, Win Rate: 0.49, Wins: 385, Losses: 399, Epsilon: 0.2628, Steps: 36754, Time: 150.58s\n",
      "Ações: Manter=15230, Comprar=8338, Vender=13186\n",
      "Ganhos Totais: 10176.25, Perdas Totais: -13161.25\n",
      "Episode 65/200, Total Reward: 1402.00, Win Rate: 0.56, Wins: 502, Losses: 399, Epsilon: 0.2602, Steps: 36754, Time: 150.90s\n",
      "Ações: Manter=13057, Comprar=11224, Vender=12473\n",
      "Ganhos Totais: 13145.50, Perdas Totais: -11743.50\n",
      "Modelo e log do episódio 65 salvos em: 4.9.1\\model_episode_65.pth e 4.9.1\\log_episode_65.csv\n",
      "\n",
      "Episode 66/200, Total Reward: -1015.00, Win Rate: 0.53, Wins: 438, Losses: 396, Epsilon: 0.2576, Steps: 36754, Time: 151.11s\n",
      "Ações: Manter=9763, Comprar=12600, Vender=14391\n",
      "Ganhos Totais: 11854.75, Perdas Totais: -12869.75\n",
      "Episode 67/200, Total Reward: -2188.00, Win Rate: 0.49, Wins: 385, Losses: 402, Epsilon: 0.2550, Steps: 36754, Time: 150.75s\n",
      "Ações: Manter=13684, Comprar=7958, Vender=15112\n",
      "Ganhos Totais: 10736.75, Perdas Totais: -12924.75\n",
      "Episode 68/200, Total Reward: -2806.75, Win Rate: 0.50, Wins: 416, Losses: 411, Epsilon: 0.2524, Steps: 36754, Time: 151.27s\n",
      "Ações: Manter=10812, Comprar=11486, Vender=14456\n",
      "Ganhos Totais: 9559.50, Perdas Totais: -12366.25\n",
      "Episode 69/200, Total Reward: -949.50, Win Rate: 0.52, Wins: 441, Losses: 407, Epsilon: 0.2499, Steps: 36754, Time: 150.99s\n",
      "Ações: Manter=10970, Comprar=10867, Vender=14917\n",
      "Ganhos Totais: 11094.00, Perdas Totais: -12043.50\n",
      "Episode 70/200, Total Reward: 125.25, Win Rate: 0.49, Wins: 394, Losses: 403, Epsilon: 0.2474, Steps: 36754, Time: 150.86s\n",
      "Ações: Manter=10084, Comprar=11044, Vender=15626\n",
      "Ganhos Totais: 10277.00, Perdas Totais: -10151.75\n",
      "Episode 71/200, Total Reward: -388.25, Win Rate: 0.52, Wins: 432, Losses: 406, Epsilon: 0.2449, Steps: 36754, Time: 150.62s\n",
      "Ações: Manter=11946, Comprar=14363, Vender=10445\n",
      "Ganhos Totais: 11199.75, Perdas Totais: -11588.00\n",
      "Episode 72/200, Total Reward: 112.75, Win Rate: 0.53, Wins: 442, Losses: 395, Epsilon: 0.2425, Steps: 36754, Time: 152.08s\n",
      "Ações: Manter=16173, Comprar=7800, Vender=12781\n",
      "Ganhos Totais: 12257.25, Perdas Totais: -12144.50\n",
      "Episode 73/200, Total Reward: 1082.75, Win Rate: 0.51, Wins: 413, Losses: 393, Epsilon: 0.2401, Steps: 36754, Time: 151.37s\n",
      "Ações: Manter=13034, Comprar=8784, Vender=14936\n",
      "Ganhos Totais: 12749.25, Perdas Totais: -11666.50\n",
      "Modelo e log do episódio 73 salvos em: 4.9.1\\model_episode_73.pth e 4.9.1\\log_episode_73.csv\n",
      "\n",
      "Episode 74/200, Total Reward: 353.50, Win Rate: 0.54, Wins: 451, Losses: 390, Epsilon: 0.2377, Steps: 36754, Time: 150.89s\n",
      "Ações: Manter=11829, Comprar=10867, Vender=14058\n",
      "Ganhos Totais: 11296.50, Perdas Totais: -10943.00\n",
      "Episode 75/200, Total Reward: -2457.25, Win Rate: 0.48, Wins: 370, Losses: 405, Epsilon: 0.2353, Steps: 36754, Time: 151.13s\n",
      "Ações: Manter=12687, Comprar=11125, Vender=12942\n",
      "Ganhos Totais: 9096.00, Perdas Totais: -11553.25\n",
      "Episode 76/200, Total Reward: -585.75, Win Rate: 0.51, Wins: 421, Losses: 407, Epsilon: 0.2329, Steps: 36754, Time: 151.14s\n",
      "Ações: Manter=12695, Comprar=9455, Vender=14604\n",
      "Ganhos Totais: 10833.00, Perdas Totais: -11418.75\n",
      "Episode 77/200, Total Reward: 1522.75, Win Rate: 0.51, Wins: 400, Losses: 390, Epsilon: 0.2306, Steps: 36754, Time: 151.25s\n",
      "Ações: Manter=13726, Comprar=8319, Vender=14709\n",
      "Ganhos Totais: 13315.50, Perdas Totais: -11792.75\n",
      "Modelo e log do episódio 77 salvos em: 4.9.1\\model_episode_77.pth e 4.9.1\\log_episode_77.csv\n",
      "\n",
      "Episode 78/200, Total Reward: -932.50, Win Rate: 0.51, Wins: 412, Losses: 403, Epsilon: 0.2283, Steps: 36754, Time: 151.14s\n",
      "Ações: Manter=13885, Comprar=9055, Vender=13814\n",
      "Ganhos Totais: 10849.25, Perdas Totais: -11781.75\n",
      "Episode 79/200, Total Reward: -3524.00, Win Rate: 0.53, Wins: 448, Losses: 402, Epsilon: 0.2260, Steps: 36754, Time: 150.95s\n",
      "Ações: Manter=11840, Comprar=11008, Vender=13906\n",
      "Ganhos Totais: 13537.00, Perdas Totais: -17061.00\n",
      "Episode 80/200, Total Reward: 1725.00, Win Rate: 0.54, Wins: 458, Losses: 389, Epsilon: 0.2238, Steps: 36754, Time: 148.02s\n",
      "Ações: Manter=11364, Comprar=12246, Vender=13144\n",
      "Ganhos Totais: 13419.00, Perdas Totais: -11694.00\n",
      "Modelo e log do episódio 80 salvos em: 4.9.1\\model_episode_80.pth e 4.9.1\\log_episode_80.csv\n",
      "\n",
      "Episode 81/200, Total Reward: 1068.25, Win Rate: 0.51, Wins: 412, Losses: 389, Epsilon: 0.2215, Steps: 36754, Time: 138.19s\n",
      "Ações: Manter=13804, Comprar=8564, Vender=14386\n",
      "Ganhos Totais: 13899.75, Perdas Totais: -12831.50\n",
      "Episode 82/200, Total Reward: -2767.00, Win Rate: 0.50, Wins: 383, Losses: 383, Epsilon: 0.2193, Steps: 36754, Time: 138.87s\n",
      "Ações: Manter=16403, Comprar=10046, Vender=10305\n",
      "Ganhos Totais: 11169.50, Perdas Totais: -13936.50\n",
      "Episode 83/200, Total Reward: -485.50, Win Rate: 0.52, Wins: 418, Losses: 388, Epsilon: 0.2171, Steps: 36754, Time: 138.60s\n",
      "Ações: Manter=12506, Comprar=11075, Vender=13173\n",
      "Ganhos Totais: 12189.00, Perdas Totais: -12674.50\n",
      "Episode 84/200, Total Reward: -1230.00, Win Rate: 0.52, Wins: 429, Losses: 390, Epsilon: 0.2149, Steps: 36754, Time: 138.92s\n",
      "Ações: Manter=15754, Comprar=9522, Vender=11478\n",
      "Ganhos Totais: 10921.00, Perdas Totais: -12151.00\n",
      "Episode 85/200, Total Reward: -498.50, Win Rate: 0.50, Wins: 376, Losses: 383, Epsilon: 0.2128, Steps: 36754, Time: 138.25s\n",
      "Ações: Manter=12739, Comprar=13507, Vender=10508\n",
      "Ganhos Totais: 12087.00, Perdas Totais: -12585.50\n",
      "Episode 86/200, Total Reward: -149.25, Win Rate: 0.52, Wins: 422, Losses: 388, Epsilon: 0.2107, Steps: 36754, Time: 138.43s\n",
      "Ações: Manter=15267, Comprar=11463, Vender=10024\n",
      "Ganhos Totais: 14031.75, Perdas Totais: -14181.00\n",
      "Episode 87/200, Total Reward: -3294.25, Win Rate: 0.49, Wins: 383, Losses: 398, Epsilon: 0.2086, Steps: 36754, Time: 138.52s\n",
      "Ações: Manter=13274, Comprar=7450, Vender=16030\n",
      "Ganhos Totais: 11763.25, Perdas Totais: -15057.50\n",
      "Episode 88/200, Total Reward: 1985.75, Win Rate: 0.54, Wins: 462, Losses: 391, Epsilon: 0.2065, Steps: 36754, Time: 138.09s\n",
      "Ações: Manter=8854, Comprar=14791, Vender=13109\n",
      "Ganhos Totais: 14061.75, Perdas Totais: -12076.00\n",
      "Modelo e log do episódio 88 salvos em: 4.9.1\\model_episode_88.pth e 4.9.1\\log_episode_88.csv\n",
      "\n",
      "Episode 89/200, Total Reward: 1737.00, Win Rate: 0.54, Wins: 450, Losses: 390, Epsilon: 0.2044, Steps: 36754, Time: 138.58s\n",
      "Ações: Manter=11860, Comprar=13329, Vender=11565\n",
      "Ganhos Totais: 12615.00, Perdas Totais: -10878.00\n",
      "Modelo e log do episódio 89 salvos em: 4.9.1\\model_episode_89.pth e 4.9.1\\log_episode_89.csv\n",
      "\n",
      "Episode 90/200, Total Reward: 535.75, Win Rate: 0.54, Wins: 470, Losses: 401, Epsilon: 0.2024, Steps: 36754, Time: 138.05s\n",
      "Ações: Manter=10880, Comprar=14373, Vender=11501\n",
      "Ganhos Totais: 12496.75, Perdas Totais: -11961.00\n",
      "Episode 91/200, Total Reward: -421.75, Win Rate: 0.53, Wins: 444, Losses: 386, Epsilon: 0.2003, Steps: 36754, Time: 138.48s\n",
      "Ações: Manter=13909, Comprar=9793, Vender=13052\n",
      "Ganhos Totais: 11740.25, Perdas Totais: -12162.00\n",
      "Episode 92/200, Total Reward: -1651.50, Win Rate: 0.55, Wins: 430, Losses: 356, Epsilon: 0.1983, Steps: 36754, Time: 138.36s\n",
      "Ações: Manter=17577, Comprar=8733, Vender=10444\n",
      "Ganhos Totais: 12892.75, Perdas Totais: -14544.25\n",
      "Episode 93/200, Total Reward: -2641.00, Win Rate: 0.49, Wins: 377, Losses: 388, Epsilon: 0.1964, Steps: 36754, Time: 138.31s\n",
      "Ações: Manter=11906, Comprar=11934, Vender=12914\n",
      "Ganhos Totais: 11169.25, Perdas Totais: -13810.25\n",
      "Episode 94/200, Total Reward: -1152.75, Win Rate: 0.50, Wins: 394, Losses: 390, Epsilon: 0.1944, Steps: 36754, Time: 139.22s\n",
      "Ações: Manter=13575, Comprar=12563, Vender=10616\n",
      "Ganhos Totais: 11948.50, Perdas Totais: -13101.25\n",
      "Episode 95/200, Total Reward: 449.25, Win Rate: 0.56, Wins: 480, Losses: 384, Epsilon: 0.1924, Steps: 36754, Time: 138.64s\n",
      "Ações: Manter=13670, Comprar=8737, Vender=14347\n",
      "Ganhos Totais: 14279.25, Perdas Totais: -13830.00\n",
      "Episode 96/200, Total Reward: -1864.00, Win Rate: 0.53, Wins: 426, Losses: 383, Epsilon: 0.1905, Steps: 36754, Time: 139.02s\n",
      "Ações: Manter=14522, Comprar=9849, Vender=12383\n",
      "Ganhos Totais: 12443.75, Perdas Totais: -14307.75\n",
      "Episode 97/200, Total Reward: 1530.25, Win Rate: 0.54, Wins: 468, Losses: 392, Epsilon: 0.1886, Steps: 36754, Time: 138.41s\n",
      "Ações: Manter=11368, Comprar=14184, Vender=11202\n",
      "Ganhos Totais: 13629.50, Perdas Totais: -12099.25\n",
      "Modelo e log do episódio 97 salvos em: 4.9.1\\model_episode_97.pth e 4.9.1\\log_episode_97.csv\n",
      "\n",
      "Episode 98/200, Total Reward: 161.75, Win Rate: 0.53, Wins: 413, Losses: 373, Epsilon: 0.1867, Steps: 36754, Time: 139.28s\n",
      "Ações: Manter=14466, Comprar=10338, Vender=11950\n",
      "Ganhos Totais: 13133.25, Perdas Totais: -12971.50\n",
      "Episode 99/200, Total Reward: -896.25, Win Rate: 0.56, Wins: 468, Losses: 371, Epsilon: 0.1849, Steps: 36754, Time: 139.72s\n",
      "Ações: Manter=12316, Comprar=13140, Vender=11298\n",
      "Ganhos Totais: 14803.25, Perdas Totais: -15699.50\n",
      "Episode 100/200, Total Reward: -1207.25, Win Rate: 0.51, Wins: 401, Losses: 384, Epsilon: 0.1830, Steps: 36754, Time: 138.58s\n",
      "Ações: Manter=11954, Comprar=14852, Vender=9948\n",
      "Ganhos Totais: 11898.25, Perdas Totais: -13105.50\n",
      "Episode 101/200, Total Reward: 391.50, Win Rate: 0.52, Wins: 432, Losses: 395, Epsilon: 0.1812, Steps: 36754, Time: 136.76s\n",
      "Ações: Manter=13446, Comprar=13617, Vender=9691\n",
      "Ganhos Totais: 11854.75, Perdas Totais: -11463.25\n",
      "Episode 102/200, Total Reward: 2431.75, Win Rate: 0.55, Wins: 466, Losses: 377, Epsilon: 0.1794, Steps: 36754, Time: 131.55s\n",
      "Ações: Manter=16024, Comprar=10856, Vender=9874\n",
      "Ganhos Totais: 14744.00, Perdas Totais: -12312.25\n",
      "Modelo e log do episódio 102 salvos em: 4.9.1\\model_episode_102.pth e 4.9.1\\log_episode_102.csv\n",
      "\n",
      "Episode 103/200, Total Reward: 642.00, Win Rate: 0.54, Wins: 472, Losses: 397, Epsilon: 0.1776, Steps: 36754, Time: 131.47s\n",
      "Ações: Manter=11183, Comprar=11549, Vender=14022\n",
      "Ganhos Totais: 15104.25, Perdas Totais: -14462.25\n",
      "Episode 104/200, Total Reward: -1196.75, Win Rate: 0.52, Wins: 404, Losses: 378, Epsilon: 0.1758, Steps: 36754, Time: 131.51s\n",
      "Ações: Manter=17176, Comprar=8700, Vender=10878\n",
      "Ganhos Totais: 12836.00, Perdas Totais: -14032.75\n",
      "Episode 105/200, Total Reward: 2492.00, Win Rate: 0.54, Wins: 453, Losses: 383, Epsilon: 0.1740, Steps: 36754, Time: 131.40s\n",
      "Ações: Manter=10014, Comprar=14111, Vender=12629\n",
      "Ganhos Totais: 15051.25, Perdas Totais: -12559.25\n",
      "Modelo e log do episódio 105 salvos em: 4.9.1\\model_episode_105.pth e 4.9.1\\log_episode_105.csv\n",
      "\n",
      "Episode 106/200, Total Reward: -37.00, Win Rate: 0.52, Wins: 405, Losses: 375, Epsilon: 0.1723, Steps: 36754, Time: 132.31s\n",
      "Ações: Manter=15071, Comprar=12683, Vender=9000\n",
      "Ganhos Totais: 12368.00, Perdas Totais: -12405.00\n",
      "Episode 107/200, Total Reward: 1400.25, Win Rate: 0.54, Wins: 463, Losses: 399, Epsilon: 0.1706, Steps: 36754, Time: 135.10s\n",
      "Ações: Manter=12315, Comprar=10420, Vender=14019\n",
      "Ganhos Totais: 14368.75, Perdas Totais: -12968.50\n",
      "Episode 108/200, Total Reward: 600.25, Win Rate: 0.49, Wins: 367, Losses: 375, Epsilon: 0.1689, Steps: 36754, Time: 132.51s\n",
      "Ações: Manter=16872, Comprar=8214, Vender=11668\n",
      "Ganhos Totais: 12339.00, Perdas Totais: -11738.75\n",
      "Episode 109/200, Total Reward: 764.75, Win Rate: 0.54, Wins: 438, Losses: 378, Epsilon: 0.1672, Steps: 36754, Time: 131.59s\n",
      "Ações: Manter=14858, Comprar=9402, Vender=12494\n",
      "Ganhos Totais: 14034.25, Perdas Totais: -13269.50\n",
      "Episode 110/200, Total Reward: 2750.50, Win Rate: 0.58, Wins: 522, Losses: 371, Epsilon: 0.1655, Steps: 36754, Time: 131.81s\n",
      "Ações: Manter=12718, Comprar=14459, Vender=9577\n",
      "Ganhos Totais: 15385.75, Perdas Totais: -12635.25\n",
      "Modelo e log do episódio 110 salvos em: 4.9.1\\model_episode_110.pth e 4.9.1\\log_episode_110.csv\n",
      "\n",
      "Episode 111/200, Total Reward: 1846.00, Win Rate: 0.54, Wins: 459, Losses: 385, Epsilon: 0.1639, Steps: 36754, Time: 132.08s\n",
      "Ações: Manter=15270, Comprar=12397, Vender=9087\n",
      "Ganhos Totais: 15305.25, Perdas Totais: -13459.25\n",
      "Modelo e log do episódio 111 salvos em: 4.9.1\\model_episode_111.pth e 4.9.1\\log_episode_111.csv\n",
      "\n",
      "Episode 112/200, Total Reward: -549.25, Win Rate: 0.49, Wins: 362, Losses: 380, Epsilon: 0.1622, Steps: 36754, Time: 133.51s\n",
      "Ações: Manter=12685, Comprar=15654, Vender=8415\n",
      "Ganhos Totais: 13202.00, Perdas Totais: -13751.25\n",
      "Episode 113/200, Total Reward: 3253.25, Win Rate: 0.53, Wins: 422, Losses: 375, Epsilon: 0.1606, Steps: 36754, Time: 131.29s\n",
      "Ações: Manter=13222, Comprar=14194, Vender=9338\n",
      "Ganhos Totais: 15349.75, Perdas Totais: -12096.50\n",
      "Modelo e log do episódio 113 salvos em: 4.9.1\\model_episode_113.pth e 4.9.1\\log_episode_113.csv\n",
      "\n",
      "Episode 114/200, Total Reward: 369.25, Win Rate: 0.53, Wins: 439, Losses: 382, Epsilon: 0.1590, Steps: 36754, Time: 132.18s\n",
      "Ações: Manter=14626, Comprar=11782, Vender=10346\n",
      "Ganhos Totais: 13331.50, Perdas Totais: -12962.25\n",
      "Episode 115/200, Total Reward: 813.75, Win Rate: 0.53, Wins: 433, Losses: 386, Epsilon: 0.1574, Steps: 36754, Time: 132.25s\n",
      "Ações: Manter=12941, Comprar=11269, Vender=12544\n",
      "Ganhos Totais: 13726.25, Perdas Totais: -12912.50\n",
      "Episode 116/200, Total Reward: 1364.25, Win Rate: 0.54, Wins: 442, Losses: 379, Epsilon: 0.1558, Steps: 36754, Time: 132.25s\n",
      "Ações: Manter=14247, Comprar=13125, Vender=9382\n",
      "Ganhos Totais: 14587.50, Perdas Totais: -13223.25\n",
      "Episode 117/200, Total Reward: -547.75, Win Rate: 0.55, Wins: 448, Losses: 367, Epsilon: 0.1543, Steps: 36754, Time: 132.76s\n",
      "Ações: Manter=11283, Comprar=13851, Vender=11620\n",
      "Ganhos Totais: 14928.75, Perdas Totais: -15476.50\n",
      "Episode 118/200, Total Reward: -245.75, Win Rate: 0.53, Wins: 424, Losses: 382, Epsilon: 0.1527, Steps: 36754, Time: 132.53s\n",
      "Ações: Manter=13239, Comprar=12458, Vender=11057\n",
      "Ganhos Totais: 13956.25, Perdas Totais: -14202.00\n",
      "Episode 119/200, Total Reward: -353.25, Win Rate: 0.54, Wins: 443, Losses: 383, Epsilon: 0.1512, Steps: 36754, Time: 132.75s\n",
      "Ações: Manter=12606, Comprar=15224, Vender=8924\n",
      "Ganhos Totais: 14484.00, Perdas Totais: -14837.25\n",
      "Episode 120/200, Total Reward: -3523.50, Win Rate: 0.49, Wins: 366, Losses: 375, Epsilon: 0.1497, Steps: 36754, Time: 132.55s\n",
      "Ações: Manter=14474, Comprar=12259, Vender=10021\n",
      "Ganhos Totais: 11477.50, Perdas Totais: -15001.00\n",
      "Episode 121/200, Total Reward: 2200.00, Win Rate: 0.58, Wins: 515, Losses: 374, Epsilon: 0.1482, Steps: 36754, Time: 132.61s\n",
      "Ações: Manter=14791, Comprar=13337, Vender=8626\n",
      "Ganhos Totais: 16216.75, Perdas Totais: -14016.75\n",
      "Modelo e log do episódio 121 salvos em: 4.9.1\\model_episode_121.pth e 4.9.1\\log_episode_121.csv\n",
      "\n",
      "Episode 122/200, Total Reward: 1046.75, Win Rate: 0.53, Wins: 422, Losses: 380, Epsilon: 0.1467, Steps: 36754, Time: 132.50s\n",
      "Ações: Manter=13874, Comprar=12396, Vender=10484\n",
      "Ganhos Totais: 13151.00, Perdas Totais: -12104.25\n",
      "Episode 123/200, Total Reward: 1475.25, Win Rate: 0.53, Wins: 444, Losses: 392, Epsilon: 0.1452, Steps: 36754, Time: 132.10s\n",
      "Ações: Manter=12207, Comprar=15798, Vender=8749\n",
      "Ganhos Totais: 13901.25, Perdas Totais: -12426.00\n",
      "Episode 124/200, Total Reward: 1593.25, Win Rate: 0.53, Wins: 414, Losses: 374, Epsilon: 0.1438, Steps: 36754, Time: 132.45s\n",
      "Ações: Manter=16482, Comprar=8619, Vender=11653\n",
      "Ganhos Totais: 13963.75, Perdas Totais: -12370.50\n",
      "Episode 125/200, Total Reward: -166.25, Win Rate: 0.54, Wins: 458, Losses: 387, Epsilon: 0.1424, Steps: 36754, Time: 132.43s\n",
      "Ações: Manter=14734, Comprar=12702, Vender=9318\n",
      "Ganhos Totais: 13540.00, Perdas Totais: -13706.25\n",
      "Episode 126/200, Total Reward: 55.75, Win Rate: 0.56, Wins: 500, Losses: 390, Epsilon: 0.1409, Steps: 36754, Time: 133.91s\n",
      "Ações: Manter=11384, Comprar=15000, Vender=10370\n",
      "Ganhos Totais: 12384.50, Perdas Totais: -12328.75\n",
      "Episode 127/200, Total Reward: -3357.25, Win Rate: 0.50, Wins: 382, Losses: 381, Epsilon: 0.1395, Steps: 36754, Time: 132.47s\n",
      "Ações: Manter=16392, Comprar=12454, Vender=7908\n",
      "Ganhos Totais: 12265.75, Perdas Totais: -15623.00\n",
      "Episode 128/200, Total Reward: 2251.00, Win Rate: 0.54, Wins: 475, Losses: 398, Epsilon: 0.1381, Steps: 36754, Time: 132.82s\n",
      "Ações: Manter=12165, Comprar=15325, Vender=9264\n",
      "Ganhos Totais: 14288.00, Perdas Totais: -12037.00\n",
      "Modelo e log do episódio 128 salvos em: 4.9.1\\model_episode_128.pth e 4.9.1\\log_episode_128.csv\n",
      "\n",
      "Episode 129/200, Total Reward: 1253.75, Win Rate: 0.53, Wins: 435, Losses: 382, Epsilon: 0.1367, Steps: 36754, Time: 132.81s\n",
      "Ações: Manter=13126, Comprar=11351, Vender=12277\n",
      "Ganhos Totais: 13550.25, Perdas Totais: -12296.50\n",
      "Episode 130/200, Total Reward: -1552.50, Win Rate: 0.53, Wins: 435, Losses: 383, Epsilon: 0.1354, Steps: 36754, Time: 132.81s\n",
      "Ações: Manter=13359, Comprar=13666, Vender=9729\n",
      "Ganhos Totais: 13549.00, Perdas Totais: -15101.50\n",
      "Episode 131/200, Total Reward: -1800.25, Win Rate: 0.51, Wins: 399, Losses: 388, Epsilon: 0.1340, Steps: 36754, Time: 132.82s\n",
      "Ações: Manter=13521, Comprar=8952, Vender=14281\n",
      "Ganhos Totais: 14320.50, Perdas Totais: -16120.75\n",
      "Episode 132/200, Total Reward: -2172.00, Win Rate: 0.53, Wins: 426, Losses: 379, Epsilon: 0.1327, Steps: 36754, Time: 133.01s\n",
      "Ações: Manter=15020, Comprar=12436, Vender=9298\n",
      "Ganhos Totais: 12660.75, Perdas Totais: -14832.75\n",
      "Episode 133/200, Total Reward: 14.75, Win Rate: 0.55, Wins: 474, Losses: 385, Epsilon: 0.1314, Steps: 36754, Time: 132.75s\n",
      "Ações: Manter=13705, Comprar=15140, Vender=7909\n",
      "Ganhos Totais: 13777.50, Perdas Totais: -13762.75\n",
      "Episode 134/200, Total Reward: 629.00, Win Rate: 0.51, Wins: 402, Losses: 389, Epsilon: 0.1300, Steps: 36754, Time: 132.71s\n",
      "Ações: Manter=13485, Comprar=10665, Vender=12604\n",
      "Ganhos Totais: 11712.00, Perdas Totais: -11083.00\n",
      "Episode 135/200, Total Reward: 2325.50, Win Rate: 0.58, Wins: 531, Losses: 377, Epsilon: 0.1287, Steps: 36754, Time: 134.99s\n",
      "Ações: Manter=11861, Comprar=17063, Vender=7830\n",
      "Ganhos Totais: 15716.50, Perdas Totais: -13391.00\n",
      "Modelo e log do episódio 135 salvos em: 4.9.1\\model_episode_135.pth e 4.9.1\\log_episode_135.csv\n",
      "\n",
      "Episode 136/200, Total Reward: -129.00, Win Rate: 0.53, Wins: 443, Losses: 388, Epsilon: 0.1275, Steps: 36754, Time: 132.74s\n",
      "Ações: Manter=13412, Comprar=12845, Vender=10497\n",
      "Ganhos Totais: 13929.50, Perdas Totais: -14058.50\n",
      "Episode 137/200, Total Reward: -3064.50, Win Rate: 0.50, Wins: 378, Losses: 382, Epsilon: 0.1262, Steps: 36754, Time: 132.93s\n",
      "Ações: Manter=15226, Comprar=10924, Vender=10604\n",
      "Ganhos Totais: 12157.50, Perdas Totais: -15222.00\n",
      "Episode 138/200, Total Reward: 1891.00, Win Rate: 0.55, Wins: 466, Losses: 383, Epsilon: 0.1249, Steps: 36754, Time: 133.15s\n",
      "Ações: Manter=14529, Comprar=13626, Vender=8599\n",
      "Ganhos Totais: 14743.00, Perdas Totais: -12852.00\n",
      "Episode 139/200, Total Reward: -616.00, Win Rate: 0.54, Wins: 436, Losses: 374, Epsilon: 0.1237, Steps: 36754, Time: 132.55s\n",
      "Ações: Manter=16929, Comprar=12892, Vender=6933\n",
      "Ganhos Totais: 14873.25, Perdas Totais: -15489.25\n",
      "Episode 140/200, Total Reward: 2074.00, Win Rate: 0.59, Wins: 537, Losses: 377, Epsilon: 0.1224, Steps: 36754, Time: 133.02s\n",
      "Ações: Manter=13607, Comprar=14869, Vender=8278\n",
      "Ganhos Totais: 15515.75, Perdas Totais: -13441.75\n",
      "Modelo e log do episódio 140 salvos em: 4.9.1\\model_episode_140.pth e 4.9.1\\log_episode_140.csv\n",
      "\n",
      "Episode 141/200, Total Reward: -1599.50, Win Rate: 0.57, Wins: 485, Losses: 372, Epsilon: 0.1212, Steps: 36754, Time: 132.61s\n",
      "Ações: Manter=13512, Comprar=11475, Vender=11767\n",
      "Ganhos Totais: 15633.50, Perdas Totais: -17233.00\n",
      "Episode 142/200, Total Reward: 2601.25, Win Rate: 0.54, Wins: 440, Losses: 370, Epsilon: 0.1200, Steps: 36754, Time: 132.51s\n",
      "Ações: Manter=17378, Comprar=12332, Vender=7044\n",
      "Ganhos Totais: 14699.00, Perdas Totais: -12097.75\n",
      "Modelo e log do episódio 142 salvos em: 4.9.1\\model_episode_142.pth e 4.9.1\\log_episode_142.csv\n",
      "\n",
      "Episode 143/200, Total Reward: -306.75, Win Rate: 0.53, Wins: 407, Losses: 363, Epsilon: 0.1188, Steps: 36754, Time: 133.30s\n",
      "Ações: Manter=16367, Comprar=8244, Vender=12143\n",
      "Ganhos Totais: 14684.00, Perdas Totais: -14990.75\n",
      "Episode 144/200, Total Reward: -1118.00, Win Rate: 0.53, Wins: 421, Losses: 367, Epsilon: 0.1176, Steps: 36754, Time: 133.26s\n",
      "Ações: Manter=15584, Comprar=10295, Vender=10875\n",
      "Ganhos Totais: 13300.25, Perdas Totais: -14418.25\n",
      "Episode 145/200, Total Reward: -1552.00, Win Rate: 0.49, Wins: 357, Losses: 369, Epsilon: 0.1164, Steps: 36754, Time: 133.26s\n",
      "Ações: Manter=16667, Comprar=10184, Vender=9903\n",
      "Ganhos Totais: 11960.50, Perdas Totais: -13512.50\n",
      "Episode 146/200, Total Reward: 1780.75, Win Rate: 0.54, Wins: 438, Losses: 369, Epsilon: 0.1153, Steps: 36754, Time: 134.43s\n",
      "Ações: Manter=14802, Comprar=9628, Vender=12324\n",
      "Ganhos Totais: 13879.00, Perdas Totais: -12098.25\n",
      "Episode 147/200, Total Reward: 420.50, Win Rate: 0.54, Wins: 434, Losses: 363, Epsilon: 0.1141, Steps: 36754, Time: 133.61s\n",
      "Ações: Manter=13757, Comprar=16821, Vender=6176\n",
      "Ganhos Totais: 14786.75, Perdas Totais: -14366.25\n",
      "Episode 148/200, Total Reward: -2009.25, Win Rate: 0.53, Wins: 417, Losses: 371, Epsilon: 0.1130, Steps: 36754, Time: 133.56s\n",
      "Ações: Manter=17657, Comprar=9811, Vender=9286\n",
      "Ganhos Totais: 13520.75, Perdas Totais: -15530.00\n",
      "Episode 149/200, Total Reward: 55.00, Win Rate: 0.53, Wins: 405, Losses: 363, Epsilon: 0.1118, Steps: 36754, Time: 133.74s\n",
      "Ações: Manter=16606, Comprar=10243, Vender=9905\n",
      "Ganhos Totais: 15202.25, Perdas Totais: -15147.25\n",
      "Episode 150/200, Total Reward: -762.25, Win Rate: 0.57, Wins: 491, Losses: 375, Epsilon: 0.1107, Steps: 36754, Time: 133.38s\n",
      "Ações: Manter=17039, Comprar=12536, Vender=7179\n",
      "Ganhos Totais: 15607.00, Perdas Totais: -16369.25\n",
      "Episode 151/200, Total Reward: -2134.50, Win Rate: 0.48, Wins: 367, Losses: 390, Epsilon: 0.1096, Steps: 36754, Time: 133.43s\n",
      "Ações: Manter=15744, Comprar=10652, Vender=10358\n",
      "Ganhos Totais: 10915.00, Perdas Totais: -13049.50\n",
      "Episode 152/200, Total Reward: 335.25, Win Rate: 0.53, Wins: 443, Losses: 387, Epsilon: 0.1085, Steps: 36754, Time: 133.40s\n",
      "Ações: Manter=14915, Comprar=13285, Vender=8554\n",
      "Ganhos Totais: 12539.50, Perdas Totais: -12204.25\n",
      "Episode 153/200, Total Reward: 718.25, Win Rate: 0.55, Wins: 464, Losses: 373, Epsilon: 0.1074, Steps: 36754, Time: 134.65s\n",
      "Ações: Manter=16164, Comprar=11113, Vender=9477\n",
      "Ganhos Totais: 15008.75, Perdas Totais: -14290.50\n",
      "Episode 154/200, Total Reward: 944.00, Win Rate: 0.53, Wins: 423, Losses: 370, Epsilon: 0.1064, Steps: 36754, Time: 134.13s\n",
      "Ações: Manter=15798, Comprar=13295, Vender=7661\n",
      "Ganhos Totais: 14518.00, Perdas Totais: -13574.00\n",
      "Episode 155/200, Total Reward: -1884.50, Win Rate: 0.52, Wins: 389, Losses: 355, Epsilon: 0.1053, Steps: 36754, Time: 133.41s\n",
      "Ações: Manter=20101, Comprar=8007, Vender=8646\n",
      "Ganhos Totais: 10855.50, Perdas Totais: -12740.00\n",
      "Episode 156/200, Total Reward: 1396.25, Win Rate: 0.54, Wins: 429, Losses: 368, Epsilon: 0.1042, Steps: 36754, Time: 133.05s\n",
      "Ações: Manter=16432, Comprar=13016, Vender=7306\n",
      "Ganhos Totais: 15683.00, Perdas Totais: -14286.75\n",
      "Episode 157/200, Total Reward: 126.25, Win Rate: 0.55, Wins: 469, Losses: 378, Epsilon: 0.1032, Steps: 36754, Time: 133.50s\n",
      "Ações: Manter=16262, Comprar=9951, Vender=10541\n",
      "Ganhos Totais: 14380.75, Perdas Totais: -14254.50\n",
      "Episode 158/200, Total Reward: 351.75, Win Rate: 0.54, Wins: 442, Losses: 378, Epsilon: 0.1022, Steps: 36754, Time: 133.37s\n",
      "Ações: Manter=17054, Comprar=10057, Vender=9643\n",
      "Ganhos Totais: 13530.25, Perdas Totais: -13178.50\n",
      "Episode 159/200, Total Reward: -2312.75, Win Rate: 0.50, Wins: 370, Losses: 370, Epsilon: 0.1012, Steps: 36754, Time: 133.55s\n",
      "Ações: Manter=18872, Comprar=7914, Vender=9968\n",
      "Ganhos Totais: 12675.00, Perdas Totais: -14987.75\n",
      "Episode 160/200, Total Reward: 2696.50, Win Rate: 0.55, Wins: 422, Losses: 351, Epsilon: 0.1001, Steps: 36754, Time: 135.24s\n",
      "Ações: Manter=18012, Comprar=12532, Vender=6210\n",
      "Ganhos Totais: 16898.75, Perdas Totais: -14202.25\n",
      "Modelo e log do episódio 160 salvos em: 4.9.1\\model_episode_160.pth e 4.9.1\\log_episode_160.csv\n",
      "\n",
      "Episode 161/200, Total Reward: 635.00, Win Rate: 0.51, Wins: 385, Losses: 366, Epsilon: 0.0991, Steps: 36754, Time: 133.19s\n",
      "Ações: Manter=19854, Comprar=9120, Vender=7780\n",
      "Ganhos Totais: 15248.25, Perdas Totais: -14613.25\n",
      "Episode 162/200, Total Reward: 1600.25, Win Rate: 0.54, Wins: 431, Losses: 360, Epsilon: 0.0981, Steps: 36754, Time: 135.40s\n",
      "Ações: Manter=14603, Comprar=14035, Vender=8116\n",
      "Ganhos Totais: 15714.25, Perdas Totais: -14114.00\n",
      "Episode 163/200, Total Reward: 1183.25, Win Rate: 0.54, Wins: 426, Losses: 366, Epsilon: 0.0972, Steps: 36754, Time: 132.95s\n",
      "Ações: Manter=14677, Comprar=12278, Vender=9799\n",
      "Ganhos Totais: 14510.75, Perdas Totais: -13327.50\n",
      "Episode 164/200, Total Reward: 582.50, Win Rate: 0.56, Wins: 451, Losses: 353, Epsilon: 0.0962, Steps: 36754, Time: 133.22s\n",
      "Ações: Manter=17056, Comprar=13316, Vender=6382\n",
      "Ganhos Totais: 15873.25, Perdas Totais: -15290.75\n",
      "Episode 165/200, Total Reward: -4232.50, Win Rate: 0.51, Wins: 389, Losses: 368, Epsilon: 0.0952, Steps: 36754, Time: 133.21s\n",
      "Ações: Manter=19144, Comprar=11143, Vender=6467\n",
      "Ganhos Totais: 12359.25, Perdas Totais: -16591.75\n",
      "Episode 166/200, Total Reward: 1959.75, Win Rate: 0.57, Wins: 498, Losses: 375, Epsilon: 0.0943, Steps: 36754, Time: 132.88s\n",
      "Ações: Manter=15156, Comprar=13827, Vender=7771\n",
      "Ganhos Totais: 15954.75, Perdas Totais: -13995.00\n",
      "Episode 167/200, Total Reward: 890.50, Win Rate: 0.57, Wins: 507, Losses: 378, Epsilon: 0.0933, Steps: 36754, Time: 132.66s\n",
      "Ações: Manter=16186, Comprar=10970, Vender=9598\n",
      "Ganhos Totais: 14897.25, Perdas Totais: -14006.75\n",
      "Episode 168/200, Total Reward: 1095.25, Win Rate: 0.55, Wins: 447, Losses: 361, Epsilon: 0.0924, Steps: 36754, Time: 132.88s\n",
      "Ações: Manter=15773, Comprar=14517, Vender=6464\n",
      "Ganhos Totais: 15290.00, Perdas Totais: -14194.75\n",
      "Episode 169/200, Total Reward: -927.25, Win Rate: 0.54, Wins: 431, Losses: 361, Epsilon: 0.0915, Steps: 36754, Time: 132.71s\n",
      "Ações: Manter=20162, Comprar=8153, Vender=8439\n",
      "Ganhos Totais: 14031.50, Perdas Totais: -14958.75\n",
      "Episode 170/200, Total Reward: -1454.75, Win Rate: 0.55, Wins: 449, Losses: 364, Epsilon: 0.0906, Steps: 36754, Time: 132.70s\n",
      "Ações: Manter=20158, Comprar=7748, Vender=8848\n",
      "Ganhos Totais: 14018.00, Perdas Totais: -15472.75\n",
      "Episode 171/200, Total Reward: 2011.50, Win Rate: 0.56, Wins: 474, Losses: 374, Epsilon: 0.0897, Steps: 36754, Time: 133.16s\n",
      "Ações: Manter=13505, Comprar=11669, Vender=11580\n",
      "Ganhos Totais: 14246.75, Perdas Totais: -12235.25\n",
      "Episode 172/200, Total Reward: 856.75, Win Rate: 0.54, Wins: 449, Losses: 377, Epsilon: 0.0888, Steps: 36754, Time: 133.25s\n",
      "Ações: Manter=16126, Comprar=13103, Vender=7525\n",
      "Ganhos Totais: 15380.50, Perdas Totais: -14523.75\n",
      "Episode 173/200, Total Reward: -3318.75, Win Rate: 0.50, Wins: 362, Losses: 364, Epsilon: 0.0879, Steps: 36754, Time: 132.83s\n",
      "Ações: Manter=18996, Comprar=10520, Vender=7238\n",
      "Ganhos Totais: 13250.00, Perdas Totais: -16568.75\n",
      "Episode 174/200, Total Reward: 805.50, Win Rate: 0.56, Wins: 439, Losses: 344, Epsilon: 0.0870, Steps: 36754, Time: 132.51s\n",
      "Ações: Manter=20763, Comprar=9153, Vender=6838\n",
      "Ganhos Totais: 14962.75, Perdas Totais: -14157.25\n",
      "Episode 175/200, Total Reward: -2846.50, Win Rate: 0.52, Wins: 408, Losses: 384, Epsilon: 0.0861, Steps: 36754, Time: 133.16s\n",
      "Ações: Manter=13322, Comprar=12492, Vender=10940\n",
      "Ganhos Totais: 11648.50, Perdas Totais: -14495.00\n",
      "Episode 176/200, Total Reward: 561.75, Win Rate: 0.56, Wins: 497, Losses: 387, Epsilon: 0.0853, Steps: 36754, Time: 133.32s\n",
      "Ações: Manter=15124, Comprar=14177, Vender=7453\n",
      "Ganhos Totais: 14846.25, Perdas Totais: -14284.50\n",
      "Episode 177/200, Total Reward: -1929.75, Win Rate: 0.54, Wins: 424, Losses: 368, Epsilon: 0.0844, Steps: 36754, Time: 133.15s\n",
      "Ações: Manter=18629, Comprar=10372, Vender=7753\n",
      "Ganhos Totais: 14311.00, Perdas Totais: -16240.75\n",
      "Episode 178/200, Total Reward: 2345.25, Win Rate: 0.56, Wins: 454, Losses: 359, Epsilon: 0.0836, Steps: 36754, Time: 133.57s\n",
      "Ações: Manter=16989, Comprar=10960, Vender=8805\n",
      "Ganhos Totais: 15564.75, Perdas Totais: -13219.50\n",
      "Modelo e log do episódio 178 salvos em: 4.9.1\\model_episode_178.pth e 4.9.1\\log_episode_178.csv\n",
      "\n",
      "Episode 179/200, Total Reward: -2373.25, Win Rate: 0.53, Wins: 422, Losses: 373, Epsilon: 0.0827, Steps: 36754, Time: 133.37s\n",
      "Ações: Manter=18549, Comprar=10130, Vender=8075\n",
      "Ganhos Totais: 14987.25, Perdas Totais: -17360.50\n",
      "Episode 180/200, Total Reward: 4553.00, Win Rate: 0.57, Wins: 465, Losses: 350, Epsilon: 0.0819, Steps: 36754, Time: 134.63s\n",
      "Ações: Manter=18081, Comprar=9378, Vender=9295\n",
      "Ganhos Totais: 17966.75, Perdas Totais: -13413.75\n",
      "Modelo e log do episódio 180 salvos em: 4.9.1\\model_episode_180.pth e 4.9.1\\log_episode_180.csv\n",
      "\n",
      "Episode 181/200, Total Reward: 71.75, Win Rate: 0.54, Wins: 417, Losses: 362, Epsilon: 0.0811, Steps: 36754, Time: 133.55s\n",
      "Ações: Manter=15307, Comprar=14757, Vender=6690\n",
      "Ganhos Totais: 15049.75, Perdas Totais: -14978.00\n",
      "Episode 182/200, Total Reward: 2304.75, Win Rate: 0.55, Wins: 432, Losses: 359, Epsilon: 0.0803, Steps: 36754, Time: 133.40s\n",
      "Ações: Manter=19307, Comprar=9481, Vender=7966\n",
      "Ganhos Totais: 15787.75, Perdas Totais: -13483.00\n",
      "Episode 183/200, Total Reward: 761.00, Win Rate: 0.57, Wins: 494, Losses: 373, Epsilon: 0.0795, Steps: 36754, Time: 133.70s\n",
      "Ações: Manter=16140, Comprar=11044, Vender=9570\n",
      "Ganhos Totais: 13450.25, Perdas Totais: -12689.25\n",
      "Episode 184/200, Total Reward: -1382.00, Win Rate: 0.56, Wins: 438, Losses: 346, Epsilon: 0.0787, Steps: 36754, Time: 133.84s\n",
      "Ações: Manter=19852, Comprar=8161, Vender=8741\n",
      "Ganhos Totais: 15209.25, Perdas Totais: -16591.25\n",
      "Episode 185/200, Total Reward: 668.00, Win Rate: 0.55, Wins: 439, Losses: 359, Epsilon: 0.0779, Steps: 36754, Time: 133.63s\n",
      "Ações: Manter=18085, Comprar=10085, Vender=8584\n",
      "Ganhos Totais: 15227.50, Perdas Totais: -14559.50\n",
      "Episode 186/200, Total Reward: 1311.00, Win Rate: 0.57, Wins: 485, Losses: 369, Epsilon: 0.0771, Steps: 36754, Time: 133.71s\n",
      "Ações: Manter=14248, Comprar=10711, Vender=11795\n",
      "Ganhos Totais: 16742.75, Perdas Totais: -15431.75\n",
      "Episode 187/200, Total Reward: -1398.25, Win Rate: 0.54, Wins: 450, Losses: 376, Epsilon: 0.0763, Steps: 36754, Time: 133.56s\n",
      "Ações: Manter=17665, Comprar=10192, Vender=8897\n",
      "Ganhos Totais: 13082.00, Perdas Totais: -14480.25\n",
      "Episode 188/200, Total Reward: 2492.75, Win Rate: 0.58, Wins: 515, Losses: 374, Epsilon: 0.0756, Steps: 36754, Time: 133.21s\n",
      "Ações: Manter=15285, Comprar=11183, Vender=10286\n",
      "Ganhos Totais: 15985.75, Perdas Totais: -13493.00\n",
      "Modelo e log do episódio 188 salvos em: 4.9.1\\model_episode_188.pth e 4.9.1\\log_episode_188.csv\n",
      "\n",
      "Episode 189/200, Total Reward: 1664.00, Win Rate: 0.57, Wins: 480, Losses: 361, Epsilon: 0.0748, Steps: 36754, Time: 133.70s\n",
      "Ações: Manter=16967, Comprar=13497, Vender=6290\n",
      "Ganhos Totais: 17071.00, Perdas Totais: -15407.00\n",
      "Episode 190/200, Total Reward: 2177.75, Win Rate: 0.56, Wins: 455, Losses: 363, Epsilon: 0.0741, Steps: 36754, Time: 133.56s\n",
      "Ações: Manter=15624, Comprar=9993, Vender=11137\n",
      "Ganhos Totais: 15136.00, Perdas Totais: -12958.25\n",
      "Episode 191/200, Total Reward: 2923.75, Win Rate: 0.57, Wins: 456, Losses: 351, Epsilon: 0.0733, Steps: 36754, Time: 133.23s\n",
      "Ações: Manter=18440, Comprar=10149, Vender=8165\n",
      "Ganhos Totais: 16302.50, Perdas Totais: -13378.75\n",
      "Modelo e log do episódio 191 salvos em: 4.9.1\\model_episode_191.pth e 4.9.1\\log_episode_191.csv\n",
      "\n",
      "Episode 192/200, Total Reward: 1083.50, Win Rate: 0.54, Wins: 422, Losses: 355, Epsilon: 0.0726, Steps: 36754, Time: 133.67s\n",
      "Ações: Manter=18870, Comprar=8642, Vender=9242\n",
      "Ganhos Totais: 16515.25, Perdas Totais: -15431.75\n",
      "Episode 193/200, Total Reward: 3076.00, Win Rate: 0.55, Wins: 443, Losses: 367, Epsilon: 0.0719, Steps: 36754, Time: 133.83s\n",
      "Ações: Manter=18641, Comprar=8458, Vender=9655\n",
      "Ganhos Totais: 16360.75, Perdas Totais: -13284.75\n",
      "Modelo e log do episódio 193 salvos em: 4.9.1\\model_episode_193.pth e 4.9.1\\log_episode_193.csv\n",
      "\n",
      "Episode 194/200, Total Reward: 201.75, Win Rate: 0.55, Wins: 443, Losses: 356, Epsilon: 0.0712, Steps: 36754, Time: 133.50s\n",
      "Ações: Manter=15788, Comprar=13970, Vender=6996\n",
      "Ganhos Totais: 17417.50, Perdas Totais: -17215.75\n",
      "Episode 195/200, Total Reward: 1468.50, Win Rate: 0.58, Wins: 488, Losses: 358, Epsilon: 0.0704, Steps: 36754, Time: 133.98s\n",
      "Ações: Manter=20125, Comprar=9781, Vender=6848\n",
      "Ganhos Totais: 15795.50, Perdas Totais: -14327.00\n",
      "Episode 196/200, Total Reward: -3876.75, Win Rate: 0.57, Wins: 493, Losses: 365, Epsilon: 0.0697, Steps: 36754, Time: 133.62s\n",
      "Ações: Manter=18820, Comprar=9026, Vender=8908\n",
      "Ganhos Totais: 15200.25, Perdas Totais: -19077.00\n",
      "Episode 197/200, Total Reward: 2319.50, Win Rate: 0.55, Wins: 447, Losses: 361, Epsilon: 0.0690, Steps: 36754, Time: 133.32s\n",
      "Ações: Manter=18486, Comprar=9808, Vender=8460\n",
      "Ganhos Totais: 16338.50, Perdas Totais: -14019.00\n",
      "Episode 198/200, Total Reward: -256.25, Win Rate: 0.53, Wins: 408, Losses: 356, Epsilon: 0.0684, Steps: 36754, Time: 133.73s\n",
      "Ações: Manter=19976, Comprar=10741, Vender=6037\n",
      "Ganhos Totais: 16421.00, Perdas Totais: -16677.25\n",
      "Episode 199/200, Total Reward: -420.00, Win Rate: 0.55, Wins: 431, Losses: 347, Epsilon: 0.0677, Steps: 36754, Time: 134.31s\n",
      "Ações: Manter=16135, Comprar=11821, Vender=8798\n",
      "Ganhos Totais: 16993.75, Perdas Totais: -17413.75\n",
      "Episode 200/200, Total Reward: -1823.00, Win Rate: 0.55, Wins: 437, Losses: 353, Epsilon: 0.0670, Steps: 36754, Time: 137.38s\n",
      "Ações: Manter=16589, Comprar=12833, Vender=7332\n",
      "Ganhos Totais: 14946.75, Perdas Totais: -16769.75\n",
      "\n",
      "Treinamento finalizado.\n",
      "Top 10 Melhores Episódios:\n",
      "Rank 1: Episode 180, Total Reward: 4553.00, Win Rate: 0.57, Wins: 465, Losses: 350, Ações: {0: 18081, 1: 9378, 2: 9295}, Steps: 36754, Time: 134.63s\n",
      "Rank 2: Episode 113, Total Reward: 3253.25, Win Rate: 0.53, Wins: 422, Losses: 375, Ações: {0: 13222, 1: 14194, 2: 9338}, Steps: 36754, Time: 131.29s\n",
      "Rank 3: Episode 193, Total Reward: 3076.00, Win Rate: 0.55, Wins: 443, Losses: 367, Ações: {0: 18641, 1: 8458, 2: 9655}, Steps: 36754, Time: 133.83s\n",
      "Rank 4: Episode 191, Total Reward: 2923.75, Win Rate: 0.57, Wins: 456, Losses: 351, Ações: {0: 18440, 1: 10149, 2: 8165}, Steps: 36754, Time: 133.23s\n",
      "Rank 5: Episode 110, Total Reward: 2750.50, Win Rate: 0.58, Wins: 522, Losses: 371, Ações: {0: 12718, 1: 14459, 2: 9577}, Steps: 36754, Time: 131.81s\n",
      "Rank 6: Episode 160, Total Reward: 2696.50, Win Rate: 0.55, Wins: 422, Losses: 351, Ações: {0: 18012, 1: 12532, 2: 6210}, Steps: 36754, Time: 135.24s\n",
      "Rank 7: Episode 142, Total Reward: 2601.25, Win Rate: 0.54, Wins: 440, Losses: 370, Ações: {0: 17378, 1: 12332, 2: 7044}, Steps: 36754, Time: 132.51s\n",
      "Rank 8: Episode 188, Total Reward: 2492.75, Win Rate: 0.58, Wins: 515, Losses: 374, Ações: {0: 15285, 1: 11183, 2: 10286}, Steps: 36754, Time: 133.21s\n",
      "Rank 9: Episode 105, Total Reward: 2492.00, Win Rate: 0.54, Wins: 453, Losses: 383, Ações: {0: 10014, 1: 14111, 2: 12629}, Steps: 36754, Time: 131.40s\n",
      "Rank 10: Episode 102, Total Reward: 2431.75, Win Rate: 0.55, Wins: 466, Losses: 377, Ações: {0: 16024, 1: 10856, 2: 9874}, Steps: 36754, Time: 131.55s\n"
     ]
    }
   ],
   "source": [
    "# Bloco 1: Preparar os Dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import os\n",
    "data = pd.read_csv('D:\\\\dados\\\\bar_M15_V02_data_01-01-2023_a_31-08-2024.csv')\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "# filtra o dataframe para pegar apenas o mês de 08 de 2024\n",
    "#data = data[(data['DateTime'] >= '2024-08-01') & (data['DateTime'] <= '2024-08-31')]\n",
    "\n",
    "# Criar a coluna \"Valor\", que é uma cópia de \"Close\" e não será normalizada\n",
    "data['Valor'] = data['Close']\n",
    "\n",
    "# Normalizar as colunas necessárias (exceto \"Valor\" e \"Gatilho\")\n",
    "scaler = MinMaxScaler()\n",
    "cols_to_normalize = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'PavioSuperior', 'PavioInferior',\n",
    "    'Corpo', 'Range','SMA4','SMA8','SMA12','SMA20', 'SMA50', 'SMA100', 'SMA200', 'StochasticoK',\n",
    "    'StochasticoD', 'RSI', 'MACD', 'MACDSignal', 'MACDHistogram','atr8','atr14','atr28'\n",
    "]\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "# Converter todos os valores para tipo float32 para evitar problemas de tipo\n",
    "data = data.astype({col: 'float32' for col in cols_to_normalize + ['Valor']})\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.current_step = 0\n",
    "        self.position = 0  # 0 = neutro, 1 = comprado, -1 = vendido\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None\n",
    "        self.entry_datetime = None  # Novo atributo para armazenar o DateTime de entrada\n",
    "        self.action_space = spaces.Discrete(3)  # 0 = Manter, 1 = Comprar, 2 = Vender\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(len(data.columns) - 3 + 1,), dtype=np.float32\n",
    "        )\n",
    "        self.trades = []  # Lista para armazenar as operações realizadas\n",
    "        self.operation_limit = 0  # Variável de controle para limitar operações após perda\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None\n",
    "        self.entry_datetime = None\n",
    "        self.trades = []\n",
    "        self.operation_limit = 0  # Resetar a limitação de operações ao resetar o ambiente\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = self.data.iloc[self.current_step].drop(['Valor', 'DateTime', 'Gatilho']).values\n",
    "        obs = np.append(obs, self.position)  # Incluir a posição atual na observação\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        done = self.current_step >= len(self.data) - 2  # Ajustado para evitar índice fora do intervalo\n",
    "        reward = 0\n",
    "        info = {}\n",
    "\n",
    "        # Obter o valor atual e o próximo valor\n",
    "        current_price = self.data['Valor'].iloc[self.current_step]\n",
    "        next_price = self.data['Valor'].iloc[self.current_step + 1]\n",
    "        price_change = next_price - current_price\n",
    "\n",
    "        # Obter o valor do gatilho no passo atual\n",
    "        gatilho = int(self.data['Gatilho'].iloc[self.current_step])\n",
    "\n",
    "        # Se o gatilho estiver ativo e o agente não estiver limitado por perda anterior\n",
    "        if gatilho == 1 and self.operation_limit == 0:\n",
    "            if action == 1:  # Comprar\n",
    "                if self.position == 0:\n",
    "                    self.position = 1  # Abrir posição comprada\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step\n",
    "                    self.entry_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime\n",
    "                    }\n",
    "                elif self.position == -1:\n",
    "                    # Fechar posição vendida\n",
    "                    self.exit_price = current_price\n",
    "                    profit = self.entry_price - self.exit_price - 0.25  # Ganho da posição vendida\n",
    "                    self.exit_step = self.current_step\n",
    "                    self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward += profit\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_short',\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime,\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    })\n",
    "                    # Resetar posição\n",
    "                    self.position = 0\n",
    "                    self.entry_step = None\n",
    "                    self.entry_datetime = None\n",
    "\n",
    "                    # Atualizar operation_limit caso a operação tenha dado prejuízo\n",
    "                    if profit < 0:\n",
    "                        self.operation_limit = 1\n",
    "\n",
    "            elif action == 2:  # Vender\n",
    "                if self.position == 0:\n",
    "                    self.position = -1  # Abrir posição vendida\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step\n",
    "                    self.entry_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime\n",
    "                    }\n",
    "                elif self.position == 1:\n",
    "                    # Fechar posição comprada\n",
    "                    self.exit_price = current_price\n",
    "                    profit = self.exit_price - self.entry_price - 0.25  # Ganho da posição comprada\n",
    "                    self.exit_step = self.current_step\n",
    "                    self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward += profit\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_long',\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime,\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    })\n",
    "                    # Resetar posição\n",
    "                    self.position = 0\n",
    "                    self.entry_step = None\n",
    "                    self.entry_datetime = None\n",
    "\n",
    "                    # Atualizar operation_limit caso a operação tenha dado prejuízo\n",
    "                    if profit < 0:\n",
    "                        self.operation_limit = 1\n",
    "        elif gatilho == 0:\n",
    "            # Quando o gatilho for zero, liberar a operação novamente\n",
    "            self.operation_limit = 0\n",
    "\n",
    "            # Fechar qualquer posição aberta\n",
    "            if self.position == 1:  # Fechar posição comprada\n",
    "                self.exit_price = current_price\n",
    "                profit = self.exit_price - self.entry_price - 0.25\n",
    "                self.exit_step = self.current_step\n",
    "                self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                reward += profit\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_long',\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                }\n",
    "                self.trades.append({\n",
    "                    'type': 'buy',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'entry_datetime': self.entry_datetime,\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                })\n",
    "                self.position = 0\n",
    "                self.entry_step = None\n",
    "                self.entry_datetime = None\n",
    "            elif self.position == -1:  # Fechar posição vendida\n",
    "                self.exit_price = current_price\n",
    "                profit = self.entry_price - self.exit_price - 0.25\n",
    "                self.exit_step = self.current_step\n",
    "                self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                reward += profit\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_short',\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                }\n",
    "                self.trades.append({\n",
    "                    'type': 'sell',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'entry_datetime': self.entry_datetime,\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                })\n",
    "                self.position = 0\n",
    "                self.entry_step = None\n",
    "                self.entry_datetime = None\n",
    "\n",
    "        # Atualizar o passo atual\n",
    "        self.current_step += 1\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        return obs, reward, done, info\n",
    "\n",
    "\n",
    "# Bloco 3: Criar o Agente DQN usando PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import random\n",
    "\n",
    "# Configurações do dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Criar o ambiente\n",
    "env = TradingEnv(data)\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Definir a rede DQN\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, obs_size, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(obs_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instanciar a rede\n",
    "q_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "# Definir o otimizador\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Hiperparâmetros para DQN\n",
    "memory_size = 10000\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "epsilon_start = 0.5\n",
    "epsilon_end = 0.05\n",
    "epsilon_decay = 0.99\n",
    "target_update = 10  # Atualizar a rede alvo a cada 10 episódios\n",
    "\n",
    "# Inicializar a memória de replay\n",
    "memory = collections.deque(maxlen=memory_size)\n",
    "\n",
    "# Função para selecionar ação usando epsilon-greedy\n",
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice([0, 1, 2])\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = q_net(state)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "# Bloco 4: Treinamento do Agente DQN com Salvamento dos Melhores Episódios Após Cada Episódio\n",
    "\n",
    "num_episodes = 200  # Defina o número de episódios de treinamento\n",
    "epsilon = epsilon_start\n",
    "best_episodes = []\n",
    "\n",
    "save_dir = \"4.9.1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    start_time = time.time()\n",
    "    obs = env.reset()\n",
    "    obs = torch.FloatTensor(obs).unsqueeze(0).to(device)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    actions_count = {0: 0, 1: 0, 2: 0}\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    win_total = 0\n",
    "    lose_total = 0\n",
    "    trades = []\n",
    "    current_trade = None\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "\n",
    "        # Selecionar ação\n",
    "        action = select_action(obs, epsilon)\n",
    "\n",
    "        # Executar ação no ambiente\n",
    "        obs_next, reward, done, info = env.step(action)\n",
    "        obs_next = torch.FloatTensor(obs_next).unsqueeze(0).to(device)\n",
    "\n",
    "        # Armazenar na memória de replay\n",
    "        memory.append((obs, action, reward, obs_next, done))\n",
    "\n",
    "        # Atualizar o estado\n",
    "        obs = obs_next\n",
    "\n",
    "        # Atualizar contagem de ações\n",
    "        actions_count[action] += 1\n",
    "\n",
    "        # Processar informações de trade\n",
    "        if 'trade' in info:\n",
    "            trade_info = info['trade']\n",
    "            if trade_info['type'] in ['buy', 'sell']:\n",
    "                # Início de uma nova operação\n",
    "                current_trade = {\n",
    "                    'type': trade_info['type'],\n",
    "                    'entry_step': trade_info['entry_step'],\n",
    "                    'entry_price': trade_info['entry_price'],\n",
    "                    'entry_datetime': trade_info['entry_datetime'],\n",
    "                    'exit_step': None,\n",
    "                    'exit_price': None,\n",
    "                    'exit_datetime': None,\n",
    "                    'profit': None\n",
    "                }\n",
    "            elif trade_info['type'] in ['close_long', 'close_short']:\n",
    "                # Fechamento de uma operação existente\n",
    "                current_trade['exit_step'] = trade_info['exit_step']\n",
    "                current_trade['exit_price'] = trade_info['exit_price']\n",
    "                current_trade['exit_datetime'] = trade_info['exit_datetime']\n",
    "                current_trade['profit'] = trade_info['profit']\n",
    "                trades.append(current_trade.copy())\n",
    "                # Atualizar ganhos e perdas\n",
    "                if current_trade['profit'] > 0:\n",
    "                    wins += 1\n",
    "                    win_total += current_trade['profit']\n",
    "                elif current_trade['profit'] < 0:\n",
    "                    losses += 1\n",
    "                    lose_total += current_trade['profit']\n",
    "                # Atualizar recompensa total\n",
    "                total_reward += current_trade['profit']\n",
    "                current_trade = None\n",
    "\n",
    "        # Treinar a rede se a memória tiver tamanho suficiente\n",
    "        if len(memory) >= batch_size:\n",
    "            batch = random.sample(memory, batch_size)\n",
    "            states, actions_batch, rewards_batch, next_states, dones = zip(*batch)\n",
    "\n",
    "            states = torch.cat(states).to(device)\n",
    "            actions_batch = torch.tensor(actions_batch, dtype=torch.long, device=device).unsqueeze(1)\n",
    "            rewards_batch = torch.tensor(rewards_batch, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            next_states = torch.cat(next_states).to(device)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            # Computar Q-valor atual\n",
    "            q_values = q_net(states).gather(1, actions_batch)\n",
    "\n",
    "            # Computar Q-valor alvo usando a rede alvo\n",
    "            with torch.no_grad():\n",
    "                next_q_values = target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "            target_q_values = rewards_batch + gamma * next_q_values * (1 - dones)\n",
    "\n",
    "            # Calcular a perda\n",
    "            loss = nn.MSELoss()(q_values, target_q_values)\n",
    "\n",
    "            # Otimizar a rede\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Decaimento de epsilon\n",
    "    epsilon = max(epsilon_end, epsilon_decay * epsilon)\n",
    "\n",
    "    # Atualizar a rede alvo\n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    # Cálculo do tempo de treinamento do episódio\n",
    "    end_time = time.time()\n",
    "    episode_time = end_time - start_time\n",
    "\n",
    "    win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "    print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward:.2f}, Win Rate: {win_rate:.2f}, \"\n",
    "          f\"Wins: {wins}, Losses: {losses}, Epsilon: {epsilon:.4f}, Steps: {steps}, Time: {episode_time:.2f}s\")\n",
    "    print(f\"Ações: Manter={actions_count[0]}, Comprar={actions_count[1]}, Vender={actions_count[2]}\")\n",
    "    print(f\"Ganhos Totais: {win_total:.2f}, Perdas Totais: {lose_total:.2f}\")\n",
    "\n",
    "    # Salvar informações do episódio\n",
    "    episode_info = {\n",
    "        'episode': episode + 1,\n",
    "        'total_reward': total_reward,\n",
    "        'win_rate': win_rate,\n",
    "        'wins': wins,\n",
    "        'losses': losses,\n",
    "        'actions_count': actions_count.copy(),\n",
    "        'win_total': win_total,\n",
    "        'lose_total': lose_total,\n",
    "        'steps': steps,\n",
    "        'episode_time': episode_time,\n",
    "        'model_state_dict': q_net.state_dict(),\n",
    "        'trades': trades.copy()  # Salvar as operações do episódio\n",
    "    }\n",
    "\n",
    "    # Adicionar o episódio à lista e manter os top 10\n",
    "    best_episodes.append(episode_info)\n",
    "    best_episodes = sorted(best_episodes, key=lambda x: x['total_reward'], reverse=True)[:10]\n",
    "\n",
    "    # Salvar o modelo e log se o episódio for um dos top 10\n",
    "    if episode_info in best_episodes:\n",
    "        model_path = os.path.join(save_dir, f\"model_episode_{episode_info['episode']}.pth\")\n",
    "        torch.save(episode_info['model_state_dict'], model_path)\n",
    "        episode_info['model_path'] = model_path\n",
    "\n",
    "        # Salvar o log completo das operações\n",
    "        log_path = os.path.join(save_dir, f\"log_episode_{episode_info['episode']}.csv\")\n",
    "        trades_df = pd.DataFrame(episode_info['trades'])\n",
    "        trades_df.to_csv(log_path, index=False)\n",
    "        episode_info['log_path'] = log_path\n",
    "\n",
    "        print(f\"Modelo e log do episódio {episode_info['episode']} salvos em: {model_path} e {log_path}\\n\")\n",
    "\n",
    "print(\"\\nTreinamento finalizado.\")\n",
    "print(\"Top 10 Melhores Episódios:\")\n",
    "for idx, ep in enumerate(best_episodes, 1):\n",
    "    print(f\"Rank {idx}: Episode {ep['episode']}, Total Reward: {ep['total_reward']:.2f}, \"\n",
    "          f\"Win Rate: {ep['win_rate']:.2f}, Wins: {ep['wins']}, Losses: {ep['losses']}, \"\n",
    "          f\"Ações: {ep['actions_count']}, Steps: {ep['steps']}, Time: {ep['episode_time']:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
