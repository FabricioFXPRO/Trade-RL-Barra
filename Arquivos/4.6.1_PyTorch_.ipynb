{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/200, Total Reward: -2300.75, Win Rate: 0.33, Wins: 2760, Losses: 5565, Epsilon: 0.4950, Steps: 36754, Time: 123.19s\n",
      "Ações: Manter=12660, Comprar=12475, Vender=11619\n",
      "Ganhos Totais: 44973.00, Perdas Totais: -47273.75\n",
      "\n",
      "Modelo e log do episódio 1 salvos em: 4.6.1\\model_episode_1.pth e 4.6.1\\log_episode_1.csv\n",
      "Episode 2/200, Total Reward: -3083.50, Win Rate: 0.34, Wins: 2778, Losses: 5389, Epsilon: 0.4900, Steps: 36754, Time: 121.96s\n",
      "Ações: Manter=12930, Comprar=12098, Vender=11726\n",
      "Ganhos Totais: 44790.50, Perdas Totais: -47874.00\n",
      "\n",
      "Modelo e log do episódio 2 salvos em: 4.6.1\\model_episode_2.pth e 4.6.1\\log_episode_2.csv\n",
      "Episode 3/200, Total Reward: -2447.50, Win Rate: 0.34, Wins: 2669, Losses: 5246, Epsilon: 0.4851, Steps: 36754, Time: 123.35s\n",
      "Ações: Manter=12497, Comprar=11837, Vender=12420\n",
      "Ganhos Totais: 42241.25, Perdas Totais: -44688.75\n",
      "\n",
      "Modelo e log do episódio 3 salvos em: 4.6.1\\model_episode_3.pth e 4.6.1\\log_episode_3.csv\n",
      "Episode 4/200, Total Reward: -745.25, Win Rate: 0.34, Wins: 2656, Losses: 5091, Epsilon: 0.4803, Steps: 36754, Time: 112.08s\n",
      "Ações: Manter=12961, Comprar=11975, Vender=11818\n",
      "Ganhos Totais: 44791.75, Perdas Totais: -45537.00\n",
      "\n",
      "Modelo e log do episódio 4 salvos em: 4.6.1\\model_episode_4.pth e 4.6.1\\log_episode_4.csv\n",
      "Episode 5/200, Total Reward: 2044.50, Win Rate: 0.35, Wins: 2679, Losses: 5052, Epsilon: 0.4755, Steps: 36754, Time: 111.53s\n",
      "Ações: Manter=12772, Comprar=12082, Vender=11900\n",
      "Ganhos Totais: 45737.00, Perdas Totais: -43692.50\n",
      "\n",
      "Modelo e log do episódio 5 salvos em: 4.6.1\\model_episode_5.pth e 4.6.1\\log_episode_5.csv\n",
      "Episode 6/200, Total Reward: -4010.75, Win Rate: 0.34, Wins: 2611, Losses: 5056, Epsilon: 0.4707, Steps: 36754, Time: 113.48s\n",
      "Ações: Manter=13416, Comprar=12018, Vender=11320\n",
      "Ganhos Totais: 41327.75, Perdas Totais: -45338.50\n",
      "\n",
      "Modelo e log do episódio 6 salvos em: 4.6.1\\model_episode_6.pth e 4.6.1\\log_episode_6.csv\n",
      "Episode 7/200, Total Reward: -2043.75, Win Rate: 0.35, Wins: 2684, Losses: 4989, Epsilon: 0.4660, Steps: 36754, Time: 112.71s\n",
      "Ações: Manter=12892, Comprar=11558, Vender=12304\n",
      "Ganhos Totais: 44500.00, Perdas Totais: -46543.75\n",
      "\n",
      "Modelo e log do episódio 7 salvos em: 4.6.1\\model_episode_7.pth e 4.6.1\\log_episode_7.csv\n",
      "Episode 8/200, Total Reward: -1390.75, Win Rate: 0.34, Wins: 2579, Losses: 5057, Epsilon: 0.4614, Steps: 36754, Time: 111.44s\n",
      "Ações: Manter=12910, Comprar=11702, Vender=12142\n",
      "Ganhos Totais: 42785.25, Perdas Totais: -44176.00\n",
      "\n",
      "Modelo e log do episódio 8 salvos em: 4.6.1\\model_episode_8.pth e 4.6.1\\log_episode_8.csv\n",
      "Episode 9/200, Total Reward: -1365.50, Win Rate: 0.35, Wins: 2578, Losses: 4854, Epsilon: 0.4568, Steps: 36754, Time: 112.89s\n",
      "Ações: Manter=12838, Comprar=12576, Vender=11340\n",
      "Ganhos Totais: 40947.75, Perdas Totais: -42313.25\n",
      "\n",
      "Modelo e log do episódio 9 salvos em: 4.6.1\\model_episode_9.pth e 4.6.1\\log_episode_9.csv\n",
      "Episode 10/200, Total Reward: -2627.50, Win Rate: 0.34, Wins: 2528, Losses: 4932, Epsilon: 0.4522, Steps: 36754, Time: 112.05s\n",
      "Ações: Manter=12752, Comprar=11969, Vender=12033\n",
      "Ganhos Totais: 42162.25, Perdas Totais: -44789.75\n",
      "\n",
      "Modelo e log do episódio 10 salvos em: 4.6.1\\model_episode_10.pth e 4.6.1\\log_episode_10.csv\n",
      "Episode 11/200, Total Reward: 58.25, Win Rate: 0.35, Wins: 2647, Losses: 4827, Epsilon: 0.4477, Steps: 36754, Time: 112.33s\n",
      "Ações: Manter=13241, Comprar=11344, Vender=12169\n",
      "Ganhos Totais: 44960.75, Perdas Totais: -44902.50\n",
      "\n",
      "Modelo e log do episódio 11 salvos em: 4.6.1\\model_episode_11.pth e 4.6.1\\log_episode_11.csv\n",
      "Episode 12/200, Total Reward: -1327.25, Win Rate: 0.33, Wins: 2475, Losses: 4924, Epsilon: 0.4432, Steps: 36754, Time: 112.27s\n",
      "Ações: Manter=11542, Comprar=12248, Vender=12964\n",
      "Ganhos Totais: 40793.00, Perdas Totais: -42120.25\n",
      "\n",
      "Modelo e log do episódio 12 salvos em: 4.6.1\\model_episode_12.pth e 4.6.1\\log_episode_12.csv\n",
      "Episode 13/200, Total Reward: 66.25, Win Rate: 0.34, Wins: 2441, Losses: 4792, Epsilon: 0.4388, Steps: 36754, Time: 112.82s\n",
      "Ações: Manter=11556, Comprar=11347, Vender=13851\n",
      "Ganhos Totais: 41079.75, Perdas Totais: -41013.50\n",
      "\n",
      "Modelo e log do episódio 13 salvos em: 4.6.1\\model_episode_13.pth e 4.6.1\\log_episode_13.csv\n",
      "Episode 14/200, Total Reward: -3190.50, Win Rate: 0.34, Wins: 2428, Losses: 4812, Epsilon: 0.4344, Steps: 36754, Time: 112.39s\n",
      "Ações: Manter=11618, Comprar=12300, Vender=12836\n",
      "Ganhos Totais: 39683.75, Perdas Totais: -42874.25\n",
      "\n",
      "Episode 15/200, Total Reward: -1800.25, Win Rate: 0.34, Wins: 2411, Losses: 4735, Epsilon: 0.4300, Steps: 36754, Time: 111.79s\n",
      "Ações: Manter=11638, Comprar=12078, Vender=13038\n",
      "Ganhos Totais: 39941.50, Perdas Totais: -41741.75\n",
      "\n",
      "Modelo e log do episódio 15 salvos em: 4.6.1\\model_episode_15.pth e 4.6.1\\log_episode_15.csv\n",
      "Episode 16/200, Total Reward: -28.50, Win Rate: 0.34, Wins: 2519, Losses: 4797, Epsilon: 0.4257, Steps: 36754, Time: 112.58s\n",
      "Ações: Manter=12556, Comprar=12837, Vender=11361\n",
      "Ganhos Totais: 41930.00, Perdas Totais: -41958.50\n",
      "\n",
      "Modelo e log do episódio 16 salvos em: 4.6.1\\model_episode_16.pth e 4.6.1\\log_episode_16.csv\n",
      "Episode 17/200, Total Reward: -2189.00, Win Rate: 0.35, Wins: 2510, Losses: 4603, Epsilon: 0.4215, Steps: 36754, Time: 113.13s\n",
      "Ações: Manter=12692, Comprar=12818, Vender=11244\n",
      "Ganhos Totais: 41627.00, Perdas Totais: -43816.00\n",
      "\n",
      "Episode 18/200, Total Reward: -134.75, Win Rate: 0.36, Wins: 2682, Losses: 4718, Epsilon: 0.4173, Steps: 36754, Time: 112.40s\n",
      "Ações: Manter=13382, Comprar=10870, Vender=12502\n",
      "Ganhos Totais: 45928.25, Perdas Totais: -46063.00\n",
      "\n",
      "Modelo e log do episódio 18 salvos em: 4.6.1\\model_episode_18.pth e 4.6.1\\log_episode_18.csv\n",
      "Episode 19/200, Total Reward: -3526.75, Win Rate: 0.34, Wins: 2416, Losses: 4716, Epsilon: 0.4131, Steps: 36754, Time: 112.73s\n",
      "Ações: Manter=11888, Comprar=12103, Vender=12763\n",
      "Ganhos Totais: 39515.00, Perdas Totais: -43041.75\n",
      "\n",
      "Episode 20/200, Total Reward: 386.25, Win Rate: 0.36, Wins: 2638, Losses: 4619, Epsilon: 0.4090, Steps: 36754, Time: 113.45s\n",
      "Ações: Manter=13520, Comprar=12273, Vender=10961\n",
      "Ganhos Totais: 43197.00, Perdas Totais: -42810.75\n",
      "\n",
      "Modelo e log do episódio 20 salvos em: 4.6.1\\model_episode_20.pth e 4.6.1\\log_episode_20.csv\n",
      "Episode 21/200, Total Reward: -854.75, Win Rate: 0.35, Wins: 2422, Losses: 4567, Epsilon: 0.4049, Steps: 36754, Time: 112.73s\n",
      "Ações: Manter=12834, Comprar=11348, Vender=12572\n",
      "Ganhos Totais: 39665.00, Perdas Totais: -40519.75\n",
      "\n",
      "Modelo e log do episódio 21 salvos em: 4.6.1\\model_episode_21.pth e 4.6.1\\log_episode_21.csv\n",
      "Episode 22/200, Total Reward: -4580.00, Win Rate: 0.34, Wins: 2432, Losses: 4730, Epsilon: 0.4008, Steps: 36754, Time: 112.90s\n",
      "Ações: Manter=12315, Comprar=12522, Vender=11917\n",
      "Ganhos Totais: 39817.50, Perdas Totais: -44397.50\n",
      "\n",
      "Episode 23/200, Total Reward: -3847.50, Win Rate: 0.34, Wins: 2488, Losses: 4747, Epsilon: 0.3968, Steps: 36754, Time: 113.17s\n",
      "Ações: Manter=12116, Comprar=11950, Vender=12688\n",
      "Ganhos Totais: 40298.50, Perdas Totais: -44146.00\n",
      "\n",
      "Episode 24/200, Total Reward: -2613.00, Win Rate: 0.34, Wins: 2438, Losses: 4703, Epsilon: 0.3928, Steps: 36754, Time: 112.01s\n",
      "Ações: Manter=12033, Comprar=12120, Vender=12601\n",
      "Ganhos Totais: 41103.25, Perdas Totais: -43716.25\n",
      "\n",
      "Episode 25/200, Total Reward: -3072.00, Win Rate: 0.35, Wins: 2470, Losses: 4612, Epsilon: 0.3889, Steps: 36754, Time: 111.46s\n",
      "Ações: Manter=12570, Comprar=11873, Vender=12311\n",
      "Ganhos Totais: 39906.25, Perdas Totais: -42978.25\n",
      "\n",
      "Episode 26/200, Total Reward: -2892.25, Win Rate: 0.34, Wins: 2251, Losses: 4437, Epsilon: 0.3850, Steps: 36754, Time: 113.67s\n",
      "Ações: Manter=12089, Comprar=12591, Vender=12074\n",
      "Ganhos Totais: 36888.75, Perdas Totais: -39781.00\n",
      "\n",
      "Episode 27/200, Total Reward: -3637.00, Win Rate: 0.35, Wins: 2388, Losses: 4465, Epsilon: 0.3812, Steps: 36754, Time: 113.21s\n",
      "Ações: Manter=11774, Comprar=12415, Vender=12565\n",
      "Ganhos Totais: 37775.75, Perdas Totais: -41412.75\n",
      "\n",
      "Episode 28/200, Total Reward: -1870.25, Win Rate: 0.36, Wins: 2535, Losses: 4554, Epsilon: 0.3774, Steps: 36754, Time: 113.01s\n",
      "Ações: Manter=13395, Comprar=11848, Vender=11511\n",
      "Ganhos Totais: 42126.50, Perdas Totais: -43996.75\n",
      "\n",
      "Episode 29/200, Total Reward: -1399.50, Win Rate: 0.35, Wins: 2464, Losses: 4493, Epsilon: 0.3736, Steps: 36754, Time: 114.63s\n",
      "Ações: Manter=14377, Comprar=10538, Vender=11839\n",
      "Ganhos Totais: 41217.75, Perdas Totais: -42617.25\n",
      "\n",
      "Episode 30/200, Total Reward: -849.75, Win Rate: 0.35, Wins: 2403, Losses: 4531, Epsilon: 0.3699, Steps: 36754, Time: 114.53s\n",
      "Ações: Manter=12376, Comprar=10652, Vender=13726\n",
      "Ganhos Totais: 39771.00, Perdas Totais: -40620.75\n",
      "\n",
      "Modelo e log do episódio 30 salvos em: 4.6.1\\model_episode_30.pth e 4.6.1\\log_episode_30.csv\n",
      "Episode 31/200, Total Reward: -1854.00, Win Rate: 0.36, Wins: 2464, Losses: 4461, Epsilon: 0.3662, Steps: 36754, Time: 114.63s\n",
      "Ações: Manter=12811, Comprar=11315, Vender=12628\n",
      "Ganhos Totais: 40756.00, Perdas Totais: -42610.00\n",
      "\n",
      "Episode 32/200, Total Reward: -675.50, Win Rate: 0.37, Wins: 2586, Losses: 4449, Epsilon: 0.3625, Steps: 36754, Time: 114.19s\n",
      "Ações: Manter=13891, Comprar=10553, Vender=12310\n",
      "Ganhos Totais: 43101.00, Perdas Totais: -43776.50\n",
      "\n",
      "Modelo e log do episódio 32 salvos em: 4.6.1\\model_episode_32.pth e 4.6.1\\log_episode_32.csv\n",
      "Episode 33/200, Total Reward: -2617.75, Win Rate: 0.36, Wins: 2477, Losses: 4499, Epsilon: 0.3589, Steps: 36754, Time: 114.89s\n",
      "Ações: Manter=13206, Comprar=11544, Vender=12004\n",
      "Ganhos Totais: 40019.25, Perdas Totais: -42637.00\n",
      "\n",
      "Episode 34/200, Total Reward: -1065.75, Win Rate: 0.36, Wins: 2469, Losses: 4450, Epsilon: 0.3553, Steps: 36754, Time: 114.19s\n",
      "Ações: Manter=13940, Comprar=11999, Vender=10815\n",
      "Ganhos Totais: 41177.00, Perdas Totais: -42242.75\n",
      "\n",
      "Episode 35/200, Total Reward: -2236.75, Win Rate: 0.36, Wins: 2482, Losses: 4494, Epsilon: 0.3517, Steps: 36754, Time: 116.13s\n",
      "Ações: Manter=13220, Comprar=12072, Vender=11462\n",
      "Ganhos Totais: 40513.75, Perdas Totais: -42750.50\n",
      "\n",
      "Episode 36/200, Total Reward: 343.75, Win Rate: 0.36, Wins: 2519, Losses: 4451, Epsilon: 0.3482, Steps: 36754, Time: 113.84s\n",
      "Ações: Manter=12645, Comprar=12155, Vender=11954\n",
      "Ganhos Totais: 42355.00, Perdas Totais: -42011.25\n",
      "\n",
      "Modelo e log do episódio 36 salvos em: 4.6.1\\model_episode_36.pth e 4.6.1\\log_episode_36.csv\n",
      "Episode 37/200, Total Reward: -2573.50, Win Rate: 0.35, Wins: 2379, Losses: 4339, Epsilon: 0.3447, Steps: 36754, Time: 112.13s\n",
      "Ações: Manter=13178, Comprar=13304, Vender=10272\n",
      "Ganhos Totais: 39965.00, Perdas Totais: -42538.50\n",
      "\n",
      "Episode 38/200, Total Reward: -1810.50, Win Rate: 0.34, Wins: 2363, Losses: 4579, Epsilon: 0.3413, Steps: 36754, Time: 112.66s\n",
      "Ações: Manter=12387, Comprar=12226, Vender=12141\n",
      "Ganhos Totais: 39533.75, Perdas Totais: -41344.25\n",
      "\n",
      "Episode 39/200, Total Reward: -2939.75, Win Rate: 0.34, Wins: 2342, Losses: 4572, Epsilon: 0.3379, Steps: 36754, Time: 112.56s\n",
      "Ações: Manter=11943, Comprar=11349, Vender=13462\n",
      "Ganhos Totais: 40017.75, Perdas Totais: -42957.50\n",
      "\n",
      "Episode 40/200, Total Reward: 360.75, Win Rate: 0.36, Wins: 2569, Losses: 4496, Epsilon: 0.3345, Steps: 36754, Time: 111.58s\n",
      "Ações: Manter=13827, Comprar=11104, Vender=11823\n",
      "Ganhos Totais: 44088.50, Perdas Totais: -43727.75\n",
      "\n",
      "Modelo e log do episódio 40 salvos em: 4.6.1\\model_episode_40.pth e 4.6.1\\log_episode_40.csv\n",
      "Episode 41/200, Total Reward: -1398.25, Win Rate: 0.35, Wins: 2356, Losses: 4382, Epsilon: 0.3311, Steps: 36754, Time: 111.24s\n",
      "Ações: Manter=12458, Comprar=10555, Vender=13741\n",
      "Ganhos Totais: 39874.25, Perdas Totais: -41272.50\n",
      "\n",
      "Episode 42/200, Total Reward: -1608.50, Win Rate: 0.36, Wins: 2467, Losses: 4339, Epsilon: 0.3278, Steps: 36754, Time: 111.35s\n",
      "Ações: Manter=12898, Comprar=11574, Vender=12282\n",
      "Ganhos Totais: 39842.75, Perdas Totais: -41451.25\n",
      "\n",
      "Episode 43/200, Total Reward: 1040.25, Win Rate: 0.36, Wins: 2390, Losses: 4183, Epsilon: 0.3246, Steps: 36754, Time: 112.30s\n",
      "Ações: Manter=13188, Comprar=12101, Vender=11465\n",
      "Ganhos Totais: 40274.25, Perdas Totais: -39234.00\n",
      "\n",
      "Modelo e log do episódio 43 salvos em: 4.6.1\\model_episode_43.pth e 4.6.1\\log_episode_43.csv\n",
      "Episode 44/200, Total Reward: -131.75, Win Rate: 0.34, Wins: 2201, Losses: 4231, Epsilon: 0.3213, Steps: 36754, Time: 111.76s\n",
      "Ações: Manter=11904, Comprar=12359, Vender=12491\n",
      "Ganhos Totais: 35046.50, Perdas Totais: -35178.25\n",
      "\n",
      "Modelo e log do episódio 44 salvos em: 4.6.1\\model_episode_44.pth e 4.6.1\\log_episode_44.csv\n",
      "Episode 45/200, Total Reward: -2081.50, Win Rate: 0.36, Wins: 2360, Losses: 4272, Epsilon: 0.3181, Steps: 36754, Time: 111.11s\n",
      "Ações: Manter=12478, Comprar=11956, Vender=12320\n",
      "Ganhos Totais: 38985.75, Perdas Totais: -41067.25\n",
      "\n",
      "Episode 46/200, Total Reward: -1286.00, Win Rate: 0.37, Wins: 2358, Losses: 4019, Epsilon: 0.3149, Steps: 36754, Time: 111.63s\n",
      "Ações: Manter=12443, Comprar=13401, Vender=10910\n",
      "Ganhos Totais: 37790.75, Perdas Totais: -39076.75\n",
      "\n",
      "Episode 47/200, Total Reward: 797.00, Win Rate: 0.38, Wins: 2480, Losses: 4130, Epsilon: 0.3118, Steps: 36754, Time: 111.69s\n",
      "Ações: Manter=13999, Comprar=12116, Vender=10639\n",
      "Ganhos Totais: 40275.25, Perdas Totais: -39478.25\n",
      "\n",
      "Modelo e log do episódio 47 salvos em: 4.6.1\\model_episode_47.pth e 4.6.1\\log_episode_47.csv\n",
      "Episode 48/200, Total Reward: -1264.75, Win Rate: 0.36, Wins: 2347, Losses: 4110, Epsilon: 0.3086, Steps: 36754, Time: 111.46s\n",
      "Ações: Manter=13282, Comprar=11106, Vender=12366\n",
      "Ganhos Totais: 38465.75, Perdas Totais: -39730.50\n",
      "\n",
      "Episode 49/200, Total Reward: -2527.50, Win Rate: 0.35, Wins: 2237, Losses: 4109, Epsilon: 0.3056, Steps: 36754, Time: 112.04s\n",
      "Ações: Manter=10729, Comprar=15042, Vender=10983\n",
      "Ganhos Totais: 36184.25, Perdas Totais: -38711.75\n",
      "\n",
      "Episode 50/200, Total Reward: -953.25, Win Rate: 0.36, Wins: 2350, Losses: 4112, Epsilon: 0.3025, Steps: 36754, Time: 114.09s\n",
      "Ações: Manter=11653, Comprar=12953, Vender=12148\n",
      "Ganhos Totais: 38622.00, Perdas Totais: -39575.25\n",
      "\n",
      "Episode 51/200, Total Reward: 1631.50, Win Rate: 0.39, Wins: 2587, Losses: 4119, Epsilon: 0.2995, Steps: 36754, Time: 114.14s\n",
      "Ações: Manter=14062, Comprar=12011, Vender=10681\n",
      "Ganhos Totais: 43137.75, Perdas Totais: -41506.25\n",
      "\n",
      "Modelo e log do episódio 51 salvos em: 4.6.1\\model_episode_51.pth e 4.6.1\\log_episode_51.csv\n",
      "Episode 52/200, Total Reward: 428.50, Win Rate: 0.36, Wins: 2410, Losses: 4202, Epsilon: 0.2965, Steps: 36754, Time: 112.67s\n",
      "Ações: Manter=13612, Comprar=11527, Vender=11615\n",
      "Ganhos Totais: 40923.25, Perdas Totais: -40494.75\n",
      "\n",
      "Modelo e log do episódio 52 salvos em: 4.6.1\\model_episode_52.pth e 4.6.1\\log_episode_52.csv\n",
      "Episode 53/200, Total Reward: 787.25, Win Rate: 0.35, Wins: 2136, Losses: 3901, Epsilon: 0.2935, Steps: 36754, Time: 112.63s\n",
      "Ações: Manter=10832, Comprar=14115, Vender=11807\n",
      "Ganhos Totais: 35035.75, Perdas Totais: -34248.50\n",
      "\n",
      "Modelo e log do episódio 53 salvos em: 4.6.1\\model_episode_53.pth e 4.6.1\\log_episode_53.csv\n",
      "Episode 54/200, Total Reward: 294.25, Win Rate: 0.36, Wins: 2233, Losses: 4026, Epsilon: 0.2906, Steps: 36754, Time: 112.09s\n",
      "Ações: Manter=12980, Comprar=10853, Vender=12921\n",
      "Ganhos Totais: 36999.00, Perdas Totais: -36704.75\n",
      "\n",
      "Modelo e log do episódio 54 salvos em: 4.6.1\\model_episode_54.pth e 4.6.1\\log_episode_54.csv\n",
      "Episode 55/200, Total Reward: 578.00, Win Rate: 0.38, Wins: 2532, Losses: 4051, Epsilon: 0.2877, Steps: 36754, Time: 111.73s\n",
      "Ações: Manter=14260, Comprar=11875, Vender=10619\n",
      "Ganhos Totais: 42867.75, Perdas Totais: -42289.75\n",
      "\n",
      "Modelo e log do episódio 55 salvos em: 4.6.1\\model_episode_55.pth e 4.6.1\\log_episode_55.csv\n",
      "Episode 56/200, Total Reward: -612.25, Win Rate: 0.35, Wins: 2212, Losses: 4031, Epsilon: 0.2848, Steps: 36754, Time: 112.29s\n",
      "Ações: Manter=13191, Comprar=10991, Vender=12572\n",
      "Ganhos Totais: 36709.00, Perdas Totais: -37321.25\n",
      "\n",
      "Episode 57/200, Total Reward: -1073.00, Win Rate: 0.35, Wins: 2098, Losses: 3911, Epsilon: 0.2820, Steps: 36754, Time: 112.40s\n",
      "Ações: Manter=11887, Comprar=10116, Vender=14751\n",
      "Ganhos Totais: 36253.00, Perdas Totais: -37326.00\n",
      "\n",
      "Episode 58/200, Total Reward: 16.75, Win Rate: 0.38, Wins: 2484, Losses: 4074, Epsilon: 0.2791, Steps: 36754, Time: 111.71s\n",
      "Ações: Manter=15280, Comprar=11491, Vender=9983\n",
      "Ganhos Totais: 41998.00, Perdas Totais: -41981.25\n",
      "\n",
      "Episode 59/200, Total Reward: 1766.75, Win Rate: 0.38, Wins: 2545, Losses: 4110, Epsilon: 0.2763, Steps: 36754, Time: 112.72s\n",
      "Ações: Manter=15238, Comprar=11337, Vender=10179\n",
      "Ganhos Totais: 43959.50, Perdas Totais: -42192.75\n",
      "\n",
      "Modelo e log do episódio 59 salvos em: 4.6.1\\model_episode_59.pth e 4.6.1\\log_episode_59.csv\n",
      "Episode 60/200, Total Reward: -2260.75, Win Rate: 0.35, Wins: 2210, Losses: 4072, Epsilon: 0.2736, Steps: 36754, Time: 112.50s\n",
      "Ações: Manter=10667, Comprar=11493, Vender=14594\n",
      "Ganhos Totais: 36815.00, Perdas Totais: -39075.75\n",
      "\n",
      "Episode 61/200, Total Reward: -1948.75, Win Rate: 0.36, Wins: 2243, Losses: 3972, Epsilon: 0.2708, Steps: 36754, Time: 112.34s\n",
      "Ações: Manter=12983, Comprar=12024, Vender=11747\n",
      "Ganhos Totais: 37114.50, Perdas Totais: -39063.25\n",
      "\n",
      "Episode 62/200, Total Reward: -1186.50, Win Rate: 0.37, Wins: 2295, Losses: 3897, Epsilon: 0.2681, Steps: 36754, Time: 114.31s\n",
      "Ações: Manter=10657, Comprar=12169, Vender=13928\n",
      "Ganhos Totais: 36551.25, Perdas Totais: -37737.75\n",
      "\n",
      "Episode 63/200, Total Reward: -430.50, Win Rate: 0.36, Wins: 2113, Losses: 3833, Epsilon: 0.2655, Steps: 36754, Time: 113.17s\n",
      "Ações: Manter=12055, Comprar=13936, Vender=10763\n",
      "Ganhos Totais: 34719.00, Perdas Totais: -35149.50\n",
      "\n",
      "Episode 64/200, Total Reward: -274.50, Win Rate: 0.37, Wins: 2372, Losses: 4111, Epsilon: 0.2628, Steps: 36754, Time: 114.73s\n",
      "Ações: Manter=14387, Comprar=11850, Vender=10517\n",
      "Ganhos Totais: 39392.00, Perdas Totais: -39666.50\n",
      "\n",
      "Episode 65/200, Total Reward: -2666.50, Win Rate: 0.37, Wins: 2438, Losses: 4090, Epsilon: 0.2602, Steps: 36754, Time: 113.19s\n",
      "Ações: Manter=14347, Comprar=12668, Vender=9739\n",
      "Ganhos Totais: 38457.50, Perdas Totais: -41124.00\n",
      "\n",
      "Episode 66/200, Total Reward: -358.00, Win Rate: 0.36, Wins: 2336, Losses: 4083, Epsilon: 0.2576, Steps: 36754, Time: 112.81s\n",
      "Ações: Manter=13664, Comprar=11887, Vender=11203\n",
      "Ganhos Totais: 38446.50, Perdas Totais: -38804.50\n",
      "\n",
      "Episode 67/200, Total Reward: 2795.75, Win Rate: 0.38, Wins: 2312, Losses: 3843, Epsilon: 0.2550, Steps: 36754, Time: 112.63s\n",
      "Ações: Manter=13634, Comprar=11897, Vender=11223\n",
      "Ganhos Totais: 40775.25, Perdas Totais: -37979.50\n",
      "\n",
      "Modelo e log do episódio 67 salvos em: 4.6.1\\model_episode_67.pth e 4.6.1\\log_episode_67.csv\n",
      "Episode 68/200, Total Reward: -43.25, Win Rate: 0.38, Wins: 2485, Losses: 4131, Epsilon: 0.2524, Steps: 36754, Time: 112.33s\n",
      "Ações: Manter=14540, Comprar=12601, Vender=9613\n",
      "Ganhos Totais: 40939.50, Perdas Totais: -40982.75\n",
      "\n",
      "Episode 69/200, Total Reward: -1636.25, Win Rate: 0.36, Wins: 2315, Losses: 4156, Epsilon: 0.2499, Steps: 36754, Time: 112.18s\n",
      "Ações: Manter=13463, Comprar=11802, Vender=11489\n",
      "Ganhos Totais: 38186.50, Perdas Totais: -39822.75\n",
      "\n",
      "Episode 70/200, Total Reward: -725.00, Win Rate: 0.36, Wins: 2188, Losses: 3859, Epsilon: 0.2474, Steps: 36754, Time: 112.75s\n",
      "Ações: Manter=11214, Comprar=13998, Vender=11542\n",
      "Ganhos Totais: 36810.00, Perdas Totais: -37535.00\n",
      "\n",
      "Episode 71/200, Total Reward: 1836.25, Win Rate: 0.38, Wins: 2387, Losses: 3897, Epsilon: 0.2449, Steps: 36754, Time: 113.82s\n",
      "Ações: Manter=12305, Comprar=13367, Vender=11082\n",
      "Ganhos Totais: 40719.25, Perdas Totais: -38883.00\n",
      "\n",
      "Modelo e log do episódio 71 salvos em: 4.6.1\\model_episode_71.pth e 4.6.1\\log_episode_71.csv\n",
      "Episode 72/200, Total Reward: 304.75, Win Rate: 0.37, Wins: 2230, Losses: 3850, Epsilon: 0.2425, Steps: 36754, Time: 113.13s\n",
      "Ações: Manter=11870, Comprar=14365, Vender=10519\n",
      "Ganhos Totais: 36739.75, Perdas Totais: -36435.00\n",
      "\n",
      "Episode 73/200, Total Reward: 1126.25, Win Rate: 0.38, Wins: 2342, Losses: 3828, Epsilon: 0.2401, Steps: 36754, Time: 113.52s\n",
      "Ações: Manter=14758, Comprar=12570, Vender=9426\n",
      "Ganhos Totais: 38778.50, Perdas Totais: -37652.25\n",
      "\n",
      "Modelo e log do episódio 73 salvos em: 4.6.1\\model_episode_73.pth e 4.6.1\\log_episode_73.csv\n",
      "Episode 74/200, Total Reward: -3034.25, Win Rate: 0.35, Wins: 2000, Losses: 3716, Epsilon: 0.2377, Steps: 36754, Time: 112.64s\n",
      "Ações: Manter=10622, Comprar=15402, Vender=10730\n",
      "Ganhos Totais: 32907.50, Perdas Totais: -35941.75\n",
      "\n",
      "Episode 75/200, Total Reward: -3530.50, Win Rate: 0.35, Wins: 2023, Losses: 3713, Epsilon: 0.2353, Steps: 36754, Time: 112.60s\n",
      "Ações: Manter=10651, Comprar=15145, Vender=10958\n",
      "Ganhos Totais: 32822.25, Perdas Totais: -36352.75\n",
      "\n",
      "Episode 76/200, Total Reward: -1470.50, Win Rate: 0.35, Wins: 2068, Losses: 3824, Epsilon: 0.2329, Steps: 36754, Time: 113.26s\n",
      "Ações: Manter=11534, Comprar=16717, Vender=8503\n",
      "Ganhos Totais: 34137.25, Perdas Totais: -35607.75\n",
      "\n",
      "Episode 77/200, Total Reward: -4697.50, Win Rate: 0.34, Wins: 1991, Losses: 3917, Epsilon: 0.2306, Steps: 36754, Time: 113.66s\n",
      "Ações: Manter=11094, Comprar=13474, Vender=12186\n",
      "Ganhos Totais: 32866.00, Perdas Totais: -37563.50\n",
      "\n",
      "Episode 78/200, Total Reward: -476.75, Win Rate: 0.36, Wins: 2030, Losses: 3612, Epsilon: 0.2283, Steps: 36754, Time: 112.88s\n",
      "Ações: Manter=11296, Comprar=12639, Vender=12819\n",
      "Ganhos Totais: 33821.00, Perdas Totais: -34297.75\n",
      "\n",
      "Episode 79/200, Total Reward: 597.75, Win Rate: 0.37, Wins: 2237, Losses: 3855, Epsilon: 0.2260, Steps: 36754, Time: 112.51s\n",
      "Ações: Manter=12994, Comprar=10692, Vender=13068\n",
      "Ganhos Totais: 37042.00, Perdas Totais: -36444.25\n",
      "\n",
      "Modelo e log do episódio 79 salvos em: 4.6.1\\model_episode_79.pth e 4.6.1\\log_episode_79.csv\n",
      "Episode 80/200, Total Reward: -2259.00, Win Rate: 0.36, Wins: 2127, Losses: 3838, Epsilon: 0.2238, Steps: 36754, Time: 113.13s\n",
      "Ações: Manter=12376, Comprar=12225, Vender=12153\n",
      "Ganhos Totais: 35084.00, Perdas Totais: -37343.00\n",
      "\n",
      "Episode 81/200, Total Reward: 736.50, Win Rate: 0.39, Wins: 2464, Losses: 3820, Epsilon: 0.2215, Steps: 36754, Time: 113.28s\n",
      "Ações: Manter=15580, Comprar=12162, Vender=9012\n",
      "Ganhos Totais: 41492.75, Perdas Totais: -40756.25\n",
      "\n",
      "Modelo e log do episódio 81 salvos em: 4.6.1\\model_episode_81.pth e 4.6.1\\log_episode_81.csv\n",
      "Episode 82/200, Total Reward: -2212.50, Win Rate: 0.36, Wins: 2007, Losses: 3641, Epsilon: 0.2193, Steps: 36754, Time: 112.52s\n",
      "Ações: Manter=9905, Comprar=13790, Vender=13059\n",
      "Ganhos Totais: 34291.50, Perdas Totais: -36504.00\n",
      "\n",
      "Episode 83/200, Total Reward: 542.50, Win Rate: 0.37, Wins: 2236, Losses: 3813, Epsilon: 0.2171, Steps: 36754, Time: 113.08s\n",
      "Ações: Manter=13256, Comprar=13247, Vender=10251\n",
      "Ganhos Totais: 38542.50, Perdas Totais: -38000.00\n",
      "\n",
      "Episode 84/200, Total Reward: 362.50, Win Rate: 0.37, Wins: 2136, Losses: 3672, Epsilon: 0.2149, Steps: 36754, Time: 114.02s\n",
      "Ações: Manter=13291, Comprar=10879, Vender=12584\n",
      "Ganhos Totais: 37165.75, Perdas Totais: -36803.25\n",
      "\n",
      "Episode 85/200, Total Reward: -1645.00, Win Rate: 0.36, Wins: 2042, Losses: 3691, Epsilon: 0.2128, Steps: 36754, Time: 112.64s\n",
      "Ações: Manter=11213, Comprar=12366, Vender=13175\n",
      "Ganhos Totais: 34095.75, Perdas Totais: -35740.75\n",
      "\n",
      "Episode 86/200, Total Reward: 1762.75, Win Rate: 0.37, Wins: 2114, Losses: 3645, Epsilon: 0.2107, Steps: 36754, Time: 113.21s\n",
      "Ações: Manter=11614, Comprar=12430, Vender=12710\n",
      "Ganhos Totais: 35930.25, Perdas Totais: -34167.50\n",
      "\n",
      "Modelo e log do episódio 86 salvos em: 4.6.1\\model_episode_86.pth e 4.6.1\\log_episode_86.csv\n",
      "Episode 87/200, Total Reward: 793.00, Win Rate: 0.36, Wins: 2065, Losses: 3614, Epsilon: 0.2086, Steps: 36754, Time: 112.95s\n",
      "Ações: Manter=11156, Comprar=15400, Vender=10198\n",
      "Ganhos Totais: 37116.00, Perdas Totais: -36323.00\n",
      "\n",
      "Modelo e log do episódio 87 salvos em: 4.6.1\\model_episode_87.pth e 4.6.1\\log_episode_87.csv\n",
      "Episode 88/200, Total Reward: -947.00, Win Rate: 0.36, Wins: 2067, Losses: 3659, Epsilon: 0.2065, Steps: 36754, Time: 112.64s\n",
      "Ações: Manter=12270, Comprar=12789, Vender=11695\n",
      "Ganhos Totais: 36433.00, Perdas Totais: -37380.00\n",
      "\n",
      "Episode 89/200, Total Reward: -1.25, Win Rate: 0.36, Wins: 2015, Losses: 3552, Epsilon: 0.2044, Steps: 36754, Time: 113.17s\n",
      "Ações: Manter=11619, Comprar=13071, Vender=12064\n",
      "Ganhos Totais: 33833.50, Perdas Totais: -33834.75\n",
      "\n",
      "Episode 90/200, Total Reward: -1390.25, Win Rate: 0.37, Wins: 2164, Losses: 3739, Epsilon: 0.2024, Steps: 36754, Time: 113.63s\n",
      "Ações: Manter=12506, Comprar=10219, Vender=14029\n",
      "Ganhos Totais: 38644.50, Perdas Totais: -40034.75\n",
      "\n",
      "Episode 91/200, Total Reward: -2355.00, Win Rate: 0.35, Wins: 1906, Losses: 3486, Epsilon: 0.2003, Steps: 36754, Time: 113.15s\n",
      "Ações: Manter=11267, Comprar=10987, Vender=14500\n",
      "Ganhos Totais: 33844.50, Perdas Totais: -36199.50\n",
      "\n",
      "Episode 92/200, Total Reward: -408.25, Win Rate: 0.39, Wins: 2326, Losses: 3683, Epsilon: 0.1983, Steps: 36754, Time: 113.68s\n",
      "Ações: Manter=14937, Comprar=10459, Vender=11358\n",
      "Ganhos Totais: 41536.25, Perdas Totais: -41944.50\n",
      "\n",
      "Episode 93/200, Total Reward: 58.75, Win Rate: 0.37, Wins: 2159, Losses: 3649, Epsilon: 0.1964, Steps: 36754, Time: 113.50s\n",
      "Ações: Manter=11692, Comprar=12868, Vender=12194\n",
      "Ganhos Totais: 37885.25, Perdas Totais: -37826.50\n",
      "\n",
      "Episode 94/200, Total Reward: -3072.50, Win Rate: 0.36, Wins: 1934, Losses: 3512, Epsilon: 0.1944, Steps: 36754, Time: 113.92s\n",
      "Ações: Manter=10781, Comprar=10394, Vender=15579\n",
      "Ganhos Totais: 32602.00, Perdas Totais: -35674.50\n",
      "\n",
      "Episode 95/200, Total Reward: 658.00, Win Rate: 0.37, Wins: 2045, Losses: 3445, Epsilon: 0.1924, Steps: 36754, Time: 113.85s\n",
      "Ações: Manter=11935, Comprar=12633, Vender=12186\n",
      "Ganhos Totais: 34660.00, Perdas Totais: -34002.00\n",
      "\n",
      "Episode 96/200, Total Reward: 1352.50, Win Rate: 0.37, Wins: 2039, Losses: 3468, Epsilon: 0.1905, Steps: 36754, Time: 113.69s\n",
      "Ações: Manter=12439, Comprar=12124, Vender=12191\n",
      "Ganhos Totais: 35385.75, Perdas Totais: -34033.25\n",
      "\n",
      "Modelo e log do episódio 96 salvos em: 4.6.1\\model_episode_96.pth e 4.6.1\\log_episode_96.csv\n",
      "Episode 97/200, Total Reward: -261.50, Win Rate: 0.38, Wins: 2109, Losses: 3400, Epsilon: 0.1886, Steps: 36754, Time: 114.72s\n",
      "Ações: Manter=12835, Comprar=11759, Vender=12160\n",
      "Ganhos Totais: 34769.00, Perdas Totais: -35030.50\n",
      "\n",
      "Episode 98/200, Total Reward: 2098.00, Win Rate: 0.39, Wins: 2206, Losses: 3418, Epsilon: 0.1867, Steps: 36754, Time: 113.26s\n",
      "Ações: Manter=15070, Comprar=12594, Vender=9090\n",
      "Ganhos Totais: 38160.25, Perdas Totais: -36062.25\n",
      "\n",
      "Modelo e log do episódio 98 salvos em: 4.6.1\\model_episode_98.pth e 4.6.1\\log_episode_98.csv\n",
      "Episode 99/200, Total Reward: -200.75, Win Rate: 0.37, Wins: 2017, Losses: 3385, Epsilon: 0.1849, Steps: 36754, Time: 113.69s\n",
      "Ações: Manter=12300, Comprar=12571, Vender=11883\n",
      "Ganhos Totais: 34140.25, Perdas Totais: -34341.00\n",
      "\n",
      "Episode 100/200, Total Reward: 3427.25, Win Rate: 0.39, Wins: 2228, Losses: 3478, Epsilon: 0.1830, Steps: 36754, Time: 113.82s\n",
      "Ações: Manter=13361, Comprar=12094, Vender=11299\n",
      "Ganhos Totais: 39101.25, Perdas Totais: -35674.00\n",
      "\n",
      "Modelo e log do episódio 100 salvos em: 4.6.1\\model_episode_100.pth e 4.6.1\\log_episode_100.csv\n",
      "Episode 101/200, Total Reward: -3263.00, Win Rate: 0.34, Wins: 1719, Losses: 3298, Epsilon: 0.1812, Steps: 36754, Time: 113.18s\n",
      "Ações: Manter=9294, Comprar=12972, Vender=14488\n",
      "Ganhos Totais: 28555.25, Perdas Totais: -31818.25\n",
      "\n",
      "Episode 102/200, Total Reward: -900.25, Win Rate: 0.37, Wins: 2112, Losses: 3606, Epsilon: 0.1794, Steps: 36754, Time: 113.15s\n",
      "Ações: Manter=12883, Comprar=11805, Vender=12066\n",
      "Ganhos Totais: 35473.00, Perdas Totais: -36373.25\n",
      "\n",
      "Episode 103/200, Total Reward: 2778.75, Win Rate: 0.38, Wins: 2136, Losses: 3414, Epsilon: 0.1776, Steps: 36754, Time: 114.22s\n",
      "Ações: Manter=13268, Comprar=13656, Vender=9830\n",
      "Ganhos Totais: 36516.75, Perdas Totais: -33738.00\n",
      "\n",
      "Modelo e log do episódio 103 salvos em: 4.6.1\\model_episode_103.pth e 4.6.1\\log_episode_103.csv\n",
      "Episode 104/200, Total Reward: 50.00, Win Rate: 0.38, Wins: 2200, Losses: 3610, Epsilon: 0.1758, Steps: 36754, Time: 113.79s\n",
      "Ações: Manter=13583, Comprar=10719, Vender=12452\n",
      "Ganhos Totais: 37744.00, Perdas Totais: -37694.00\n",
      "\n",
      "Episode 105/200, Total Reward: 2044.50, Win Rate: 0.38, Wins: 2160, Losses: 3535, Epsilon: 0.1740, Steps: 36754, Time: 114.47s\n",
      "Ações: Manter=14190, Comprar=11123, Vender=11441\n",
      "Ganhos Totais: 37486.75, Perdas Totais: -35442.25\n",
      "\n",
      "Modelo e log do episódio 105 salvos em: 4.6.1\\model_episode_105.pth e 4.6.1\\log_episode_105.csv\n",
      "Episode 106/200, Total Reward: 1120.00, Win Rate: 0.38, Wins: 2225, Losses: 3597, Epsilon: 0.1723, Steps: 36754, Time: 113.66s\n",
      "Ações: Manter=12334, Comprar=12476, Vender=11944\n",
      "Ganhos Totais: 36085.75, Perdas Totais: -34965.75\n",
      "\n",
      "Episode 107/200, Total Reward: 453.00, Win Rate: 0.37, Wins: 2038, Losses: 3410, Epsilon: 0.1706, Steps: 36754, Time: 114.12s\n",
      "Ações: Manter=11888, Comprar=13108, Vender=11758\n",
      "Ganhos Totais: 34445.00, Perdas Totais: -33992.00\n",
      "\n",
      "Episode 108/200, Total Reward: -2372.00, Win Rate: 0.37, Wins: 1938, Losses: 3325, Epsilon: 0.1689, Steps: 36754, Time: 113.89s\n",
      "Ações: Manter=12124, Comprar=13392, Vender=11238\n",
      "Ganhos Totais: 33016.25, Perdas Totais: -35388.25\n",
      "\n",
      "Episode 109/200, Total Reward: 37.00, Win Rate: 0.39, Wins: 2223, Losses: 3490, Epsilon: 0.1672, Steps: 36754, Time: 114.52s\n",
      "Ações: Manter=15341, Comprar=9440, Vender=11973\n",
      "Ganhos Totais: 37551.00, Perdas Totais: -37514.00\n",
      "\n",
      "Episode 110/200, Total Reward: 2862.75, Win Rate: 0.40, Wins: 2218, Losses: 3353, Epsilon: 0.1655, Steps: 36754, Time: 114.30s\n",
      "Ações: Manter=13924, Comprar=14406, Vender=8424\n",
      "Ganhos Totais: 38489.75, Perdas Totais: -35627.00\n",
      "\n",
      "Modelo e log do episódio 110 salvos em: 4.6.1\\model_episode_110.pth e 4.6.1\\log_episode_110.csv\n",
      "Episode 111/200, Total Reward: -363.25, Win Rate: 0.38, Wins: 1974, Losses: 3270, Epsilon: 0.1639, Steps: 36754, Time: 114.09s\n",
      "Ações: Manter=12057, Comprar=11630, Vender=13067\n",
      "Ganhos Totais: 33430.25, Perdas Totais: -33793.50\n",
      "\n",
      "Episode 112/200, Total Reward: -1476.50, Win Rate: 0.38, Wins: 2139, Losses: 3423, Epsilon: 0.1622, Steps: 36754, Time: 113.61s\n",
      "Ações: Manter=13729, Comprar=12675, Vender=10350\n",
      "Ganhos Totais: 35942.50, Perdas Totais: -37419.00\n",
      "\n",
      "Episode 113/200, Total Reward: -22.25, Win Rate: 0.39, Wins: 2131, Losses: 3379, Epsilon: 0.1606, Steps: 36754, Time: 115.95s\n",
      "Ações: Manter=13524, Comprar=12390, Vender=10840\n",
      "Ganhos Totais: 38410.75, Perdas Totais: -38433.00\n",
      "\n",
      "Episode 114/200, Total Reward: -194.75, Win Rate: 0.38, Wins: 2168, Losses: 3483, Epsilon: 0.1590, Steps: 36754, Time: 113.43s\n",
      "Ações: Manter=14111, Comprar=13960, Vender=8683\n",
      "Ganhos Totais: 38166.00, Perdas Totais: -38360.75\n",
      "\n",
      "Episode 115/200, Total Reward: -4552.75, Win Rate: 0.35, Wins: 1689, Losses: 3081, Epsilon: 0.1574, Steps: 36754, Time: 113.64s\n",
      "Ações: Manter=8287, Comprar=17358, Vender=11109\n",
      "Ganhos Totais: 26737.75, Perdas Totais: -31290.50\n",
      "\n",
      "Episode 116/200, Total Reward: -1011.75, Win Rate: 0.37, Wins: 1866, Losses: 3185, Epsilon: 0.1558, Steps: 36754, Time: 113.82s\n",
      "Ações: Manter=11587, Comprar=12490, Vender=12677\n",
      "Ganhos Totais: 32102.50, Perdas Totais: -33114.25\n",
      "\n",
      "Episode 117/200, Total Reward: -179.25, Win Rate: 0.39, Wins: 2109, Losses: 3346, Epsilon: 0.1543, Steps: 36754, Time: 113.97s\n",
      "Ações: Manter=13148, Comprar=12197, Vender=11409\n",
      "Ganhos Totais: 35086.50, Perdas Totais: -35265.75\n",
      "\n",
      "Episode 118/200, Total Reward: -2307.25, Win Rate: 0.37, Wins: 1837, Losses: 3178, Epsilon: 0.1527, Steps: 36754, Time: 114.21s\n",
      "Ações: Manter=10957, Comprar=11302, Vender=14495\n",
      "Ganhos Totais: 32107.00, Perdas Totais: -34414.25\n",
      "\n",
      "Episode 119/200, Total Reward: 2227.25, Win Rate: 0.39, Wins: 2244, Losses: 3451, Epsilon: 0.1512, Steps: 36754, Time: 113.72s\n",
      "Ações: Manter=14204, Comprar=13896, Vender=8654\n",
      "Ganhos Totais: 41357.00, Perdas Totais: -39129.75\n",
      "\n",
      "Modelo e log do episódio 119 salvos em: 4.6.1\\model_episode_119.pth e 4.6.1\\log_episode_119.csv\n",
      "Episode 120/200, Total Reward: 159.25, Win Rate: 0.38, Wins: 2034, Losses: 3372, Epsilon: 0.1497, Steps: 36754, Time: 114.54s\n",
      "Ações: Manter=12543, Comprar=12411, Vender=11800\n",
      "Ganhos Totais: 34682.50, Perdas Totais: -34523.25\n",
      "\n",
      "Episode 121/200, Total Reward: -602.75, Win Rate: 0.38, Wins: 2015, Losses: 3274, Epsilon: 0.1482, Steps: 36754, Time: 113.97s\n",
      "Ações: Manter=11772, Comprar=12974, Vender=12008\n",
      "Ganhos Totais: 33907.25, Perdas Totais: -34510.00\n",
      "\n",
      "Episode 122/200, Total Reward: -672.75, Win Rate: 0.38, Wins: 1856, Losses: 2979, Epsilon: 0.1467, Steps: 36754, Time: 113.86s\n",
      "Ações: Manter=11929, Comprar=14419, Vender=10406\n",
      "Ganhos Totais: 31246.75, Perdas Totais: -31919.50\n",
      "\n",
      "Episode 123/200, Total Reward: 290.00, Win Rate: 0.39, Wins: 2024, Losses: 3228, Epsilon: 0.1452, Steps: 36754, Time: 114.50s\n",
      "Ações: Manter=13136, Comprar=12772, Vender=10846\n",
      "Ganhos Totais: 34886.25, Perdas Totais: -34596.25\n",
      "\n",
      "Episode 124/200, Total Reward: 671.50, Win Rate: 0.39, Wins: 2206, Losses: 3415, Epsilon: 0.1438, Steps: 36754, Time: 114.66s\n",
      "Ações: Manter=14727, Comprar=13622, Vender=8405\n",
      "Ganhos Totais: 37953.25, Perdas Totais: -37281.75\n",
      "\n",
      "Episode 125/200, Total Reward: -181.25, Win Rate: 0.38, Wins: 2059, Losses: 3321, Epsilon: 0.1424, Steps: 36754, Time: 113.30s\n",
      "Ações: Manter=13576, Comprar=12736, Vender=10442\n",
      "Ganhos Totais: 35114.25, Perdas Totais: -35295.50\n",
      "\n",
      "Episode 126/200, Total Reward: -1047.25, Win Rate: 0.38, Wins: 2001, Losses: 3280, Epsilon: 0.1409, Steps: 36754, Time: 114.54s\n",
      "Ações: Manter=13643, Comprar=11326, Vender=11785\n",
      "Ganhos Totais: 35340.50, Perdas Totais: -36387.75\n",
      "\n",
      "Episode 127/200, Total Reward: 2098.00, Win Rate: 0.39, Wins: 2196, Losses: 3408, Epsilon: 0.1395, Steps: 36754, Time: 114.05s\n",
      "Ações: Manter=14358, Comprar=12598, Vender=9798\n",
      "Ganhos Totais: 39875.50, Perdas Totais: -37777.50\n",
      "\n",
      "Modelo e log do episódio 127 salvos em: 4.6.1\\model_episode_127.pth e 4.6.1\\log_episode_127.csv\n",
      "Episode 128/200, Total Reward: -848.00, Win Rate: 0.38, Wins: 1960, Losses: 3132, Epsilon: 0.1381, Steps: 36754, Time: 117.64s\n",
      "Ações: Manter=12329, Comprar=12651, Vender=11774\n",
      "Ganhos Totais: 33314.25, Perdas Totais: -34162.25\n",
      "\n",
      "Episode 129/200, Total Reward: 154.25, Win Rate: 0.37, Wins: 1912, Losses: 3255, Epsilon: 0.1367, Steps: 36754, Time: 114.34s\n",
      "Ações: Manter=12195, Comprar=11714, Vender=12845\n",
      "Ganhos Totais: 34245.00, Perdas Totais: -34090.75\n",
      "\n",
      "Episode 130/200, Total Reward: -2265.75, Win Rate: 0.39, Wins: 2126, Losses: 3325, Epsilon: 0.1354, Steps: 36754, Time: 114.67s\n",
      "Ações: Manter=15011, Comprar=10923, Vender=10820\n",
      "Ganhos Totais: 35367.75, Perdas Totais: -37633.50\n",
      "\n",
      "Episode 131/200, Total Reward: -111.75, Win Rate: 0.39, Wins: 2045, Losses: 3264, Epsilon: 0.1340, Steps: 36754, Time: 113.62s\n",
      "Ações: Manter=14163, Comprar=10848, Vender=11743\n",
      "Ganhos Totais: 35644.75, Perdas Totais: -35756.50\n",
      "\n",
      "Episode 132/200, Total Reward: -396.00, Win Rate: 0.41, Wins: 2364, Losses: 3376, Epsilon: 0.1327, Steps: 36754, Time: 113.83s\n",
      "Ações: Manter=14570, Comprar=12865, Vender=9319\n",
      "Ganhos Totais: 41261.25, Perdas Totais: -41657.25\n",
      "\n",
      "Episode 133/200, Total Reward: -414.00, Win Rate: 0.39, Wins: 2119, Losses: 3295, Epsilon: 0.1314, Steps: 36754, Time: 114.12s\n",
      "Ações: Manter=13013, Comprar=14475, Vender=9266\n",
      "Ganhos Totais: 35673.50, Perdas Totais: -36087.50\n",
      "\n",
      "Episode 134/200, Total Reward: 1562.75, Win Rate: 0.39, Wins: 2088, Losses: 3218, Epsilon: 0.1300, Steps: 36754, Time: 115.01s\n",
      "Ações: Manter=12622, Comprar=13381, Vender=10751\n",
      "Ganhos Totais: 36719.00, Perdas Totais: -35156.25\n",
      "\n",
      "Episode 135/200, Total Reward: -933.25, Win Rate: 0.38, Wins: 1981, Losses: 3244, Epsilon: 0.1287, Steps: 36754, Time: 115.05s\n",
      "Ações: Manter=11547, Comprar=12873, Vender=12334\n",
      "Ganhos Totais: 35445.00, Perdas Totais: -36378.25\n",
      "\n",
      "Episode 136/200, Total Reward: -2045.00, Win Rate: 0.38, Wins: 2066, Losses: 3322, Epsilon: 0.1275, Steps: 36754, Time: 115.02s\n",
      "Ações: Manter=12421, Comprar=14756, Vender=9577\n",
      "Ganhos Totais: 36461.00, Perdas Totais: -38506.00\n",
      "\n",
      "Episode 137/200, Total Reward: 3177.00, Win Rate: 0.40, Wins: 2100, Losses: 3117, Epsilon: 0.1262, Steps: 36754, Time: 114.85s\n",
      "Ações: Manter=14045, Comprar=11716, Vender=10993\n",
      "Ganhos Totais: 36908.25, Perdas Totais: -33731.25\n",
      "\n",
      "Modelo e log do episódio 137 salvos em: 4.6.1\\model_episode_137.pth e 4.6.1\\log_episode_137.csv\n",
      "Episode 138/200, Total Reward: -1445.00, Win Rate: 0.41, Wins: 2228, Losses: 3269, Epsilon: 0.1249, Steps: 36754, Time: 113.96s\n",
      "Ações: Manter=15368, Comprar=10598, Vender=10788\n",
      "Ganhos Totais: 37582.00, Perdas Totais: -39027.00\n",
      "\n",
      "Episode 139/200, Total Reward: 1891.75, Win Rate: 0.40, Wins: 2231, Losses: 3315, Epsilon: 0.1237, Steps: 36754, Time: 114.57s\n",
      "Ações: Manter=14375, Comprar=12494, Vender=9885\n",
      "Ganhos Totais: 41643.75, Perdas Totais: -39752.00\n",
      "\n",
      "Episode 140/200, Total Reward: 1485.00, Win Rate: 0.42, Wins: 2419, Losses: 3387, Epsilon: 0.1224, Steps: 36754, Time: 114.98s\n",
      "Ações: Manter=17482, Comprar=8707, Vender=10565\n",
      "Ganhos Totais: 42445.25, Perdas Totais: -40960.25\n",
      "\n",
      "Episode 141/200, Total Reward: -2660.25, Win Rate: 0.35, Wins: 1770, Losses: 3239, Epsilon: 0.1212, Steps: 36754, Time: 114.11s\n",
      "Ações: Manter=10151, Comprar=11747, Vender=14856\n",
      "Ganhos Totais: 30375.50, Perdas Totais: -33035.75\n",
      "\n",
      "Episode 142/200, Total Reward: -925.25, Win Rate: 0.39, Wins: 1957, Losses: 3098, Epsilon: 0.1200, Steps: 36754, Time: 114.43s\n",
      "Ações: Manter=12833, Comprar=13837, Vender=10084\n",
      "Ganhos Totais: 34252.25, Perdas Totais: -35177.50\n",
      "\n",
      "Episode 143/200, Total Reward: -1024.25, Win Rate: 0.39, Wins: 2012, Losses: 3113, Epsilon: 0.1188, Steps: 36754, Time: 114.51s\n",
      "Ações: Manter=12048, Comprar=12309, Vender=12397\n",
      "Ganhos Totais: 34831.00, Perdas Totais: -35855.25\n",
      "\n",
      "Episode 144/200, Total Reward: 93.50, Win Rate: 0.38, Wins: 1913, Losses: 3083, Epsilon: 0.1176, Steps: 36754, Time: 114.86s\n",
      "Ações: Manter=12298, Comprar=12262, Vender=12194\n",
      "Ganhos Totais: 32709.75, Perdas Totais: -32616.25\n",
      "\n",
      "Episode 145/200, Total Reward: -2182.25, Win Rate: 0.36, Wins: 1654, Losses: 2969, Epsilon: 0.1164, Steps: 36754, Time: 114.67s\n",
      "Ações: Manter=10659, Comprar=13191, Vender=12904\n",
      "Ganhos Totais: 27443.50, Perdas Totais: -29625.75\n",
      "\n",
      "Episode 146/200, Total Reward: 1386.50, Win Rate: 0.39, Wins: 1904, Losses: 3040, Epsilon: 0.1153, Steps: 36754, Time: 114.60s\n",
      "Ações: Manter=13234, Comprar=12687, Vender=10833\n",
      "Ganhos Totais: 33216.75, Perdas Totais: -31830.25\n",
      "\n",
      "Episode 147/200, Total Reward: -2411.00, Win Rate: 0.39, Wins: 1886, Losses: 3009, Epsilon: 0.1141, Steps: 36754, Time: 115.05s\n",
      "Ações: Manter=11127, Comprar=13146, Vender=12481\n",
      "Ganhos Totais: 30590.50, Perdas Totais: -33001.50\n",
      "\n",
      "Episode 148/200, Total Reward: 719.50, Win Rate: 0.38, Wins: 1902, Losses: 3088, Epsilon: 0.1130, Steps: 36754, Time: 114.51s\n",
      "Ações: Manter=10116, Comprar=14893, Vender=11745\n",
      "Ganhos Totais: 33364.00, Perdas Totais: -32644.50\n",
      "\n",
      "Episode 149/200, Total Reward: -2329.50, Win Rate: 0.39, Wins: 2047, Losses: 3148, Epsilon: 0.1118, Steps: 36754, Time: 115.46s\n",
      "Ações: Manter=12225, Comprar=15403, Vender=9126\n",
      "Ganhos Totais: 35890.00, Perdas Totais: -38219.50\n",
      "\n",
      "Episode 150/200, Total Reward: 2220.25, Win Rate: 0.39, Wins: 1974, Losses: 3051, Epsilon: 0.1107, Steps: 36754, Time: 114.38s\n",
      "Ações: Manter=12743, Comprar=15490, Vender=8521\n",
      "Ganhos Totais: 36431.25, Perdas Totais: -34211.00\n",
      "\n",
      "Modelo e log do episódio 150 salvos em: 4.6.1\\model_episode_150.pth e 4.6.1\\log_episode_150.csv\n",
      "Episode 151/200, Total Reward: -1961.75, Win Rate: 0.39, Wins: 2100, Losses: 3279, Epsilon: 0.1096, Steps: 36754, Time: 114.42s\n",
      "Ações: Manter=14453, Comprar=11427, Vender=10874\n",
      "Ganhos Totais: 36889.25, Perdas Totais: -38851.00\n",
      "\n",
      "Episode 152/200, Total Reward: -2220.00, Win Rate: 0.38, Wins: 1955, Losses: 3188, Epsilon: 0.1085, Steps: 36754, Time: 114.71s\n",
      "Ações: Manter=12015, Comprar=11939, Vender=12800\n",
      "Ganhos Totais: 33907.75, Perdas Totais: -36127.75\n",
      "\n",
      "Episode 153/200, Total Reward: -2445.25, Win Rate: 0.40, Wins: 2180, Losses: 3326, Epsilon: 0.1074, Steps: 36754, Time: 114.91s\n",
      "Ações: Manter=15339, Comprar=10706, Vender=10709\n",
      "Ganhos Totais: 39597.75, Perdas Totais: -42043.00\n",
      "\n",
      "Episode 154/200, Total Reward: -77.75, Win Rate: 0.40, Wins: 2046, Losses: 3133, Epsilon: 0.1064, Steps: 36754, Time: 114.27s\n",
      "Ações: Manter=14468, Comprar=13169, Vender=9117\n",
      "Ganhos Totais: 36598.75, Perdas Totais: -36676.50\n",
      "\n",
      "Episode 155/200, Total Reward: 1129.50, Win Rate: 0.38, Wins: 1860, Losses: 2987, Epsilon: 0.1053, Steps: 36754, Time: 114.28s\n",
      "Ações: Manter=12384, Comprar=11035, Vender=13335\n",
      "Ganhos Totais: 33366.50, Perdas Totais: -32237.00\n",
      "\n",
      "Episode 156/200, Total Reward: -311.75, Win Rate: 0.39, Wins: 1956, Losses: 3017, Epsilon: 0.1042, Steps: 36754, Time: 115.19s\n",
      "Ações: Manter=13880, Comprar=13661, Vender=9213\n",
      "Ganhos Totais: 33062.50, Perdas Totais: -33374.25\n",
      "\n",
      "Episode 157/200, Total Reward: 2945.00, Win Rate: 0.40, Wins: 1988, Losses: 2959, Epsilon: 0.1032, Steps: 36754, Time: 115.27s\n",
      "Ações: Manter=13633, Comprar=13222, Vender=9899\n",
      "Ganhos Totais: 35916.50, Perdas Totais: -32971.50\n",
      "\n",
      "Modelo e log do episódio 157 salvos em: 4.6.1\\model_episode_157.pth e 4.6.1\\log_episode_157.csv\n",
      "Episode 158/200, Total Reward: 824.25, Win Rate: 0.40, Wins: 1998, Losses: 3022, Epsilon: 0.1022, Steps: 36754, Time: 114.86s\n",
      "Ações: Manter=14026, Comprar=12216, Vender=10512\n",
      "Ganhos Totais: 34007.25, Perdas Totais: -33183.00\n",
      "\n",
      "Episode 159/200, Total Reward: -1748.50, Win Rate: 0.37, Wins: 1693, Losses: 2876, Epsilon: 0.1012, Steps: 36754, Time: 115.10s\n",
      "Ações: Manter=11641, Comprar=11767, Vender=13346\n",
      "Ganhos Totais: 29194.50, Perdas Totais: -30943.00\n",
      "\n",
      "Episode 160/200, Total Reward: 56.00, Win Rate: 0.38, Wins: 1822, Losses: 2918, Epsilon: 0.1001, Steps: 36754, Time: 115.43s\n",
      "Ações: Manter=11866, Comprar=12512, Vender=12376\n",
      "Ganhos Totais: 30894.50, Perdas Totais: -30838.50\n",
      "\n",
      "Episode 161/200, Total Reward: -2250.50, Win Rate: 0.37, Wins: 1676, Losses: 2882, Epsilon: 0.0991, Steps: 36754, Time: 114.59s\n",
      "Ações: Manter=10786, Comprar=15703, Vender=10265\n",
      "Ganhos Totais: 29791.75, Perdas Totais: -32042.25\n",
      "\n",
      "Episode 162/200, Total Reward: -1271.00, Win Rate: 0.37, Wins: 1612, Losses: 2772, Epsilon: 0.0981, Steps: 36754, Time: 114.94s\n",
      "Ações: Manter=10770, Comprar=16854, Vender=9130\n",
      "Ganhos Totais: 29315.25, Perdas Totais: -30586.25\n",
      "\n",
      "Episode 163/200, Total Reward: -612.75, Win Rate: 0.37, Wins: 1830, Losses: 3077, Epsilon: 0.0972, Steps: 36754, Time: 115.20s\n",
      "Ações: Manter=10133, Comprar=11106, Vender=15515\n",
      "Ganhos Totais: 33066.00, Perdas Totais: -33678.75\n",
      "\n",
      "Episode 164/200, Total Reward: -1752.00, Win Rate: 0.38, Wins: 1763, Losses: 2878, Epsilon: 0.0962, Steps: 36754, Time: 114.46s\n",
      "Ações: Manter=11810, Comprar=13828, Vender=11116\n",
      "Ganhos Totais: 30626.00, Perdas Totais: -32378.00\n",
      "\n",
      "Episode 165/200, Total Reward: -3259.00, Win Rate: 0.38, Wins: 1885, Losses: 3123, Epsilon: 0.0952, Steps: 36754, Time: 115.17s\n",
      "Ações: Manter=10756, Comprar=12573, Vender=13425\n",
      "Ganhos Totais: 34635.25, Perdas Totais: -37894.25\n",
      "\n",
      "Episode 166/200, Total Reward: -1224.50, Win Rate: 0.40, Wins: 2025, Losses: 3069, Epsilon: 0.0943, Steps: 36754, Time: 115.75s\n",
      "Ações: Manter=13404, Comprar=12315, Vender=11035\n",
      "Ganhos Totais: 33919.25, Perdas Totais: -35143.75\n",
      "\n",
      "Episode 167/200, Total Reward: 418.50, Win Rate: 0.38, Wins: 1961, Losses: 3148, Epsilon: 0.0933, Steps: 36754, Time: 115.53s\n",
      "Ações: Manter=13116, Comprar=10774, Vender=12864\n",
      "Ganhos Totais: 36646.25, Perdas Totais: -36227.75\n",
      "\n",
      "Episode 168/200, Total Reward: -3127.75, Win Rate: 0.38, Wins: 1845, Losses: 3039, Epsilon: 0.0924, Steps: 36754, Time: 115.18s\n",
      "Ações: Manter=13114, Comprar=12351, Vender=11289\n",
      "Ganhos Totais: 31299.25, Perdas Totais: -34427.00\n",
      "\n",
      "Episode 169/200, Total Reward: -2378.75, Win Rate: 0.38, Wins: 1787, Losses: 2932, Epsilon: 0.0915, Steps: 36754, Time: 115.57s\n",
      "Ações: Manter=11702, Comprar=14374, Vender=10678\n",
      "Ganhos Totais: 30615.50, Perdas Totais: -32994.25\n",
      "\n",
      "Episode 170/200, Total Reward: -2093.75, Win Rate: 0.35, Wins: 1473, Losses: 2685, Epsilon: 0.0906, Steps: 36754, Time: 117.20s\n",
      "Ações: Manter=10184, Comprar=12636, Vender=13934\n",
      "Ganhos Totais: 25201.75, Perdas Totais: -27295.50\n",
      "\n",
      "Episode 171/200, Total Reward: 107.50, Win Rate: 0.38, Wins: 1663, Losses: 2768, Epsilon: 0.0897, Steps: 36754, Time: 115.61s\n",
      "Ações: Manter=11895, Comprar=12653, Vender=12206\n",
      "Ganhos Totais: 29767.00, Perdas Totais: -29659.50\n",
      "\n",
      "Episode 172/200, Total Reward: -656.00, Win Rate: 0.41, Wins: 2042, Losses: 2971, Epsilon: 0.0888, Steps: 36754, Time: 116.11s\n",
      "Ações: Manter=12983, Comprar=16007, Vender=7764\n",
      "Ganhos Totais: 36443.00, Perdas Totais: -37099.00\n",
      "\n",
      "Episode 173/200, Total Reward: 275.50, Win Rate: 0.39, Wins: 1868, Losses: 2981, Epsilon: 0.0879, Steps: 36754, Time: 115.53s\n",
      "Ações: Manter=12606, Comprar=13510, Vender=10638\n",
      "Ganhos Totais: 34304.25, Perdas Totais: -34028.75\n",
      "\n",
      "Episode 174/200, Total Reward: 160.75, Win Rate: 0.41, Wins: 2144, Losses: 3074, Epsilon: 0.0870, Steps: 36754, Time: 115.28s\n",
      "Ações: Manter=14347, Comprar=14033, Vender=8374\n",
      "Ganhos Totais: 38084.75, Perdas Totais: -37924.00\n",
      "\n",
      "Episode 175/200, Total Reward: -2148.50, Win Rate: 0.38, Wins: 1750, Losses: 2898, Epsilon: 0.0861, Steps: 36754, Time: 115.70s\n",
      "Ações: Manter=13496, Comprar=11052, Vender=12206\n",
      "Ganhos Totais: 30880.75, Perdas Totais: -33029.25\n",
      "\n",
      "Episode 176/200, Total Reward: -1704.50, Win Rate: 0.40, Wins: 2092, Losses: 3165, Epsilon: 0.0853, Steps: 36754, Time: 115.30s\n",
      "Ações: Manter=13666, Comprar=13069, Vender=10019\n",
      "Ganhos Totais: 35078.00, Perdas Totais: -36782.50\n",
      "\n",
      "Episode 177/200, Total Reward: 313.50, Win Rate: 0.40, Wins: 1912, Losses: 2848, Epsilon: 0.0844, Steps: 36754, Time: 114.81s\n",
      "Ações: Manter=13070, Comprar=16831, Vender=6853\n",
      "Ganhos Totais: 32515.00, Perdas Totais: -32201.50\n",
      "\n",
      "Episode 178/200, Total Reward: -1694.75, Win Rate: 0.37, Wins: 1551, Losses: 2670, Epsilon: 0.0836, Steps: 36754, Time: 115.62s\n",
      "Ações: Manter=9713, Comprar=17591, Vender=9450\n",
      "Ganhos Totais: 26126.50, Perdas Totais: -27821.25\n",
      "\n",
      "Episode 179/200, Total Reward: 1135.50, Win Rate: 0.38, Wins: 1685, Losses: 2756, Epsilon: 0.0827, Steps: 36754, Time: 115.73s\n",
      "Ações: Manter=12727, Comprar=14120, Vender=9907\n",
      "Ganhos Totais: 29254.25, Perdas Totais: -28118.75\n",
      "\n",
      "Episode 180/200, Total Reward: -2420.00, Win Rate: 0.39, Wins: 1917, Losses: 3015, Epsilon: 0.0819, Steps: 36754, Time: 115.60s\n",
      "Ações: Manter=11839, Comprar=15912, Vender=9003\n",
      "Ganhos Totais: 32312.00, Perdas Totais: -34732.00\n",
      "\n",
      "Episode 181/200, Total Reward: 876.00, Win Rate: 0.37, Wins: 1651, Losses: 2757, Epsilon: 0.0811, Steps: 36754, Time: 115.34s\n",
      "Ações: Manter=9765, Comprar=12895, Vender=14094\n",
      "Ganhos Totais: 28703.75, Perdas Totais: -27827.75\n",
      "\n",
      "Episode 182/200, Total Reward: 1341.00, Win Rate: 0.41, Wins: 2207, Losses: 3133, Epsilon: 0.0803, Steps: 36754, Time: 116.04s\n",
      "Ações: Manter=16012, Comprar=12706, Vender=8036\n",
      "Ganhos Totais: 40047.75, Perdas Totais: -38706.75\n",
      "\n",
      "Episode 183/200, Total Reward: 894.25, Win Rate: 0.42, Wins: 2124, Losses: 2934, Epsilon: 0.0795, Steps: 36754, Time: 115.81s\n",
      "Ações: Manter=14064, Comprar=15580, Vender=7110\n",
      "Ganhos Totais: 36351.75, Perdas Totais: -35457.50\n",
      "\n",
      "Episode 184/200, Total Reward: -575.75, Win Rate: 0.41, Wins: 2103, Losses: 3041, Epsilon: 0.0787, Steps: 36754, Time: 115.95s\n",
      "Ações: Manter=14070, Comprar=13330, Vender=9354\n",
      "Ganhos Totais: 39597.00, Perdas Totais: -40172.75\n",
      "\n",
      "Episode 185/200, Total Reward: -963.75, Win Rate: 0.42, Wins: 2180, Losses: 3000, Epsilon: 0.0779, Steps: 36754, Time: 116.26s\n",
      "Ações: Manter=16183, Comprar=12616, Vender=7955\n",
      "Ganhos Totais: 38667.00, Perdas Totais: -39630.75\n",
      "\n",
      "Episode 186/200, Total Reward: -1199.00, Win Rate: 0.41, Wins: 2147, Losses: 3113, Epsilon: 0.0771, Steps: 36754, Time: 116.08s\n",
      "Ações: Manter=16643, Comprar=13099, Vender=7012\n",
      "Ganhos Totais: 38386.00, Perdas Totais: -39585.00\n",
      "\n",
      "Episode 187/200, Total Reward: -114.00, Win Rate: 0.38, Wins: 1618, Losses: 2670, Epsilon: 0.0763, Steps: 36754, Time: 114.97s\n",
      "Ações: Manter=10918, Comprar=13506, Vender=12330\n",
      "Ganhos Totais: 27627.25, Perdas Totais: -27741.25\n",
      "\n",
      "Episode 188/200, Total Reward: -1295.00, Win Rate: 0.38, Wins: 1812, Losses: 2906, Epsilon: 0.0756, Steps: 36754, Time: 115.31s\n",
      "Ações: Manter=12065, Comprar=11537, Vender=13152\n",
      "Ganhos Totais: 31273.75, Perdas Totais: -32568.75\n",
      "\n",
      "Episode 189/200, Total Reward: 406.25, Win Rate: 0.42, Wins: 2282, Losses: 3196, Epsilon: 0.0748, Steps: 36754, Time: 116.69s\n",
      "Ações: Manter=16221, Comprar=10553, Vender=9980\n",
      "Ganhos Totais: 42125.00, Perdas Totais: -41718.75\n",
      "\n",
      "Episode 190/200, Total Reward: -925.25, Win Rate: 0.36, Wins: 1530, Losses: 2754, Epsilon: 0.0741, Steps: 36754, Time: 115.34s\n",
      "Ações: Manter=9073, Comprar=16395, Vender=11286\n",
      "Ganhos Totais: 27895.75, Perdas Totais: -28821.00\n",
      "\n",
      "Episode 191/200, Total Reward: 50.75, Win Rate: 0.42, Wins: 2372, Losses: 3281, Epsilon: 0.0733, Steps: 36754, Time: 116.59s\n",
      "Ações: Manter=17988, Comprar=10257, Vender=8509\n",
      "Ganhos Totais: 42924.75, Perdas Totais: -42874.00\n",
      "\n",
      "Episode 192/200, Total Reward: -1844.25, Win Rate: 0.38, Wins: 1701, Losses: 2804, Epsilon: 0.0726, Steps: 36754, Time: 115.67s\n",
      "Ações: Manter=12786, Comprar=13914, Vender=10054\n",
      "Ganhos Totais: 28467.75, Perdas Totais: -30312.00\n",
      "\n",
      "Episode 193/200, Total Reward: 732.00, Win Rate: 0.42, Wins: 1989, Losses: 2755, Epsilon: 0.0719, Steps: 36754, Time: 116.08s\n",
      "Ações: Manter=16605, Comprar=14560, Vender=5589\n",
      "Ganhos Totais: 32902.25, Perdas Totais: -32170.25\n",
      "\n",
      "Episode 194/200, Total Reward: 1454.25, Win Rate: 0.39, Wins: 1731, Losses: 2762, Epsilon: 0.0712, Steps: 36754, Time: 115.29s\n",
      "Ações: Manter=13003, Comprar=14374, Vender=9377\n",
      "Ganhos Totais: 32082.25, Perdas Totais: -30628.00\n",
      "\n",
      "Episode 195/200, Total Reward: -1612.25, Win Rate: 0.42, Wins: 2252, Losses: 3141, Epsilon: 0.0704, Steps: 36754, Time: 115.88s\n",
      "Ações: Manter=15652, Comprar=13136, Vender=7966\n",
      "Ganhos Totais: 41228.50, Perdas Totais: -42840.75\n",
      "\n",
      "Episode 196/200, Total Reward: 74.25, Win Rate: 0.39, Wins: 1761, Losses: 2798, Epsilon: 0.0697, Steps: 36754, Time: 115.74s\n",
      "Ações: Manter=12400, Comprar=14592, Vender=9762\n",
      "Ganhos Totais: 31710.25, Perdas Totais: -31636.00\n",
      "\n",
      "Episode 197/200, Total Reward: 678.00, Win Rate: 0.38, Wins: 1653, Losses: 2661, Epsilon: 0.0690, Steps: 36754, Time: 116.39s\n",
      "Ações: Manter=12927, Comprar=13307, Vender=10520\n",
      "Ganhos Totais: 27941.50, Perdas Totais: -27263.50\n",
      "\n",
      "Episode 198/200, Total Reward: -1282.00, Win Rate: 0.40, Wins: 1890, Losses: 2821, Epsilon: 0.0684, Steps: 36754, Time: 115.76s\n",
      "Ações: Manter=15355, Comprar=12245, Vender=9154\n",
      "Ganhos Totais: 34320.75, Perdas Totais: -35602.75\n",
      "\n",
      "Episode 199/200, Total Reward: -297.75, Win Rate: 0.40, Wins: 1825, Losses: 2722, Epsilon: 0.0677, Steps: 36754, Time: 116.73s\n",
      "Ações: Manter=12577, Comprar=17469, Vender=6708\n",
      "Ganhos Totais: 32445.00, Perdas Totais: -32742.75\n",
      "\n",
      "Episode 200/200, Total Reward: -677.00, Win Rate: 0.38, Wins: 1710, Losses: 2747, Epsilon: 0.0670, Steps: 36754, Time: 114.35s\n",
      "Ações: Manter=11019, Comprar=15692, Vender=10043\n",
      "Ganhos Totais: 29589.75, Perdas Totais: -30266.75\n",
      "\n",
      "\n",
      "Treinamento finalizado.\n",
      "Top 10 Melhores Episódios:\n",
      "Rank 1: Episode 100, Total Reward: 3427.25, Win Rate: 0.39, Wins: 2228, Losses: 3478, Ações: {0: 13361, 1: 12094, 2: 11299}, Steps: 36754, Time: 113.82s\n",
      "Rank 2: Episode 137, Total Reward: 3177.00, Win Rate: 0.40, Wins: 2100, Losses: 3117, Ações: {0: 14045, 1: 11716, 2: 10993}, Steps: 36754, Time: 114.85s\n",
      "Rank 3: Episode 157, Total Reward: 2945.00, Win Rate: 0.40, Wins: 1988, Losses: 2959, Ações: {0: 13633, 1: 13222, 2: 9899}, Steps: 36754, Time: 115.27s\n",
      "Rank 4: Episode 110, Total Reward: 2862.75, Win Rate: 0.40, Wins: 2218, Losses: 3353, Ações: {0: 13924, 1: 14406, 2: 8424}, Steps: 36754, Time: 114.30s\n",
      "Rank 5: Episode 67, Total Reward: 2795.75, Win Rate: 0.38, Wins: 2312, Losses: 3843, Ações: {0: 13634, 1: 11897, 2: 11223}, Steps: 36754, Time: 112.63s\n",
      "Rank 6: Episode 103, Total Reward: 2778.75, Win Rate: 0.38, Wins: 2136, Losses: 3414, Ações: {0: 13268, 1: 13656, 2: 9830}, Steps: 36754, Time: 114.22s\n",
      "Rank 7: Episode 119, Total Reward: 2227.25, Win Rate: 0.39, Wins: 2244, Losses: 3451, Ações: {0: 14204, 1: 13896, 2: 8654}, Steps: 36754, Time: 113.72s\n",
      "Rank 8: Episode 150, Total Reward: 2220.25, Win Rate: 0.39, Wins: 1974, Losses: 3051, Ações: {0: 12743, 1: 15490, 2: 8521}, Steps: 36754, Time: 114.38s\n",
      "Rank 9: Episode 98, Total Reward: 2098.00, Win Rate: 0.39, Wins: 2206, Losses: 3418, Ações: {0: 15070, 1: 12594, 2: 9090}, Steps: 36754, Time: 113.26s\n",
      "Rank 10: Episode 127, Total Reward: 2098.00, Win Rate: 0.39, Wins: 2196, Losses: 3408, Ações: {0: 14358, 1: 12598, 2: 9798}, Steps: 36754, Time: 114.05s\n"
     ]
    }
   ],
   "source": [
    "# Bloco 1: Preparar os Dados\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Carregar o dataset\n",
    "data = pd.read_csv('D:\\\\dados\\\\bar_M15_V02_data_01-01-2023_a_31-08-2024.csv')\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "\n",
    "# Criar a coluna \"Valor\", que é uma cópia de \"Close\" e não será normalizada\n",
    "data['Valor'] = data['Close']\n",
    "\n",
    "# Normalizar as colunas necessárias (exceto \"Valor\" e \"Gatilho\")\n",
    "scaler = MinMaxScaler()\n",
    "cols_to_normalize = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'PavioSuperior', 'PavioInferior',\n",
    "    'Corpo', 'Range','SMA8','SMA20', 'SMA200', 'StochasticoK',\n",
    "    'StochasticoD', 'RSI'\n",
    "]\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "# Converter todos os valores para tipo float32 para evitar problemas de tipo\n",
    "data = data.astype({col: 'float32' for col in cols_to_normalize + ['Valor']})\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.current_step = 0\n",
    "        self.position = 0  # 0 = neutro, 1 = comprado, -1 = vendido\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None  # Inicializar entry_step\n",
    "        self.action_space = spaces.Discrete(3)  # 0 = Manter, 1 = Comprar, 2 = Vender\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(len(data.columns) - 3 + 1,), dtype=np.float32\n",
    "        )\n",
    "        self.trades = []  # Lista para armazenar as operações realizadas\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None  # Resetar entry_step\n",
    "        self.trades = []\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = self.data.iloc[self.current_step].drop(['Valor', 'DateTime', 'Gatilho']).values\n",
    "        obs = np.append(obs, self.position)  # Incluir a posição atual na observação\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        done = self.current_step >= len(self.data) - 2  # Ajustado para evitar índice fora do intervalo\n",
    "        reward = 0\n",
    "        info = {}\n",
    "\n",
    "        # Obter o valor atual e o próximo valor\n",
    "        current_price = self.data['Valor'].iloc[self.current_step]\n",
    "        next_price = self.data['Valor'].iloc[self.current_step + 1]\n",
    "        price_change = next_price - current_price\n",
    "\n",
    "        # Obter o valor do gatilho no passo atual\n",
    "        gatilho = int(self.data['Gatilho'].iloc[self.current_step])\n",
    "\n",
    "        # Se o gatilho estiver ativo, o agente pode executar todas as ações\n",
    "        if gatilho == 1:\n",
    "            if action == 1:  # Comprar\n",
    "                if self.position == 0:\n",
    "                    self.position = 1  # Abrir posição comprada\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step  # Registrar o passo de entrada\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price\n",
    "                    }\n",
    "                elif self.position == -1:\n",
    "                    # Fechar posição vendida\n",
    "                    self.position = 0\n",
    "                    self.exit_price = current_price\n",
    "                    reward += -price_change - 0.25  # Ganho da posição vendida\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_short',\n",
    "                        'exit_step': self.current_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'profit': -price_change - 0.25\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'short',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'exit_step': self.current_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'profit': -price_change - 0.25\n",
    "                    })\n",
    "                    # Resetar entry_step após fechar a posição\n",
    "                    self.entry_step = None\n",
    "            elif action == 2:  # Vender\n",
    "                if self.position == 0:\n",
    "                    self.position = -1  # Abrir posição vendida\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step  # Registrar o passo de entrada\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price\n",
    "                    }\n",
    "                elif self.position == 1:\n",
    "                    # Fechar posição comprada\n",
    "                    self.position = 0\n",
    "                    self.exit_price = current_price\n",
    "                    reward += price_change - 0.25  # Ganho da posição comprada\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_long',\n",
    "                        'exit_step': self.current_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'profit': price_change - 0.25\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'long',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'exit_step': self.current_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'profit': price_change - 0.25\n",
    "                    })\n",
    "                    # Resetar entry_step após fechar a posição\n",
    "                    self.entry_step = None\n",
    "            else:  # Manter\n",
    "                if self.position == 1:\n",
    "                    reward += price_change  # Ganho da posição comprada\n",
    "                elif self.position == -1:\n",
    "                    reward += -price_change  # Ganho da posição vendida\n",
    "\n",
    "        else:  # Gatilho == 0, nenhuma posição deve ser mantida\n",
    "            # Se há uma posição aberta, fechá-la\n",
    "            if self.position == 1:  # Fechar posição comprada\n",
    "                self.exit_price = current_price\n",
    "                reward += price_change - 0.25  # Ganho da posição comprada\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_long',\n",
    "                    'exit_step': self.current_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'profit': price_change - 0.25\n",
    "                }\n",
    "                # Registrar a operação\n",
    "                self.trades.append({\n",
    "                    'type': 'long',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'exit_step': self.current_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'profit': price_change - 0.25\n",
    "                })\n",
    "                # Resetar entry_step após fechar a posição\n",
    "                self.entry_step = None\n",
    "                self.position = 0  # Fechar a posição\n",
    "\n",
    "            elif self.position == -1:  # Fechar posição vendida\n",
    "                self.exit_price = current_price\n",
    "                reward += -price_change - 0.25  # Ganho da posição vendida\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_short',\n",
    "                    'exit_step': self.current_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'profit': -price_change - 0.25\n",
    "                }\n",
    "                # Registrar a operação\n",
    "                self.trades.append({\n",
    "                    'type': 'short',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'exit_step': self.current_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'profit': -price_change - 0.25\n",
    "                })\n",
    "                # Resetar entry_step após fechar a posição\n",
    "                self.entry_step = None\n",
    "                self.position = 0  # Fechar a posição\n",
    "\n",
    "        # Atualizar o passo atual\n",
    "        self.current_step += 1\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        return obs, reward, done, info\n",
    "\n",
    "\n",
    "# Bloco 3: Criar o Agente DQN usando PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import random\n",
    "\n",
    "# Configurações do dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Criar o ambiente\n",
    "env = TradingEnv(data)\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Definir a rede DQN\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, obs_size, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(obs_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instanciar a rede\n",
    "q_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "# Definir o otimizador\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Hiperparâmetros para DQN\n",
    "memory_size = 10000\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "epsilon_start = 0.5 # Valor inicial de epsilon, mais baixo para menos ações aleatórias no início\n",
    "epsilon_end = 0.05 # Valor final de epsilon, mais alto para mais exploração\n",
    "epsilon_decay = 0.99 # Decaimento mais rápido para o agente confiar mais nas ações aprendidas\n",
    "target_update = 10  # Atualizar a rede alvo a cada 10 episódios\n",
    "\n",
    "# Inicializar a memória de replay\n",
    "memory = collections.deque(maxlen=memory_size)\n",
    "\n",
    "# Função para selecionar ação usando epsilon-greedy\n",
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice([0, 1, 2])\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = q_net(state)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "# Bloco 4: Treinamento do Agente DQN com Salvamento dos Melhores Episódios Após Cada Episódio\n",
    "\n",
    "num_episodes = 200  # Defina o número de episódios de treinamento\n",
    "epsilon = epsilon_start\n",
    "best_episodes = []\n",
    "\n",
    "save_dir = \"4.6.1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    start_time = time.time()\n",
    "    obs = env.reset()\n",
    "    obs = torch.FloatTensor(obs).unsqueeze(0).to(device)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    actions_count = {0: 0, 1: 0, 2: 0}\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    win_total = 0\n",
    "    lose_total = 0\n",
    "    trades = []  # Lista para armazenar as operações do episódio atual\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "\n",
    "        # Selecionar ação\n",
    "        action = select_action(obs, epsilon)\n",
    "\n",
    "        # Executar ação no ambiente\n",
    "        obs_next, reward, done, info = env.step(action)\n",
    "        obs_next = torch.FloatTensor(obs_next).unsqueeze(0).to(device)\n",
    "\n",
    "        # Armazenar na memória de replay\n",
    "        memory.append((obs, action, reward, obs_next, done))\n",
    "\n",
    "        # Atualizar o estado\n",
    "        obs = obs_next\n",
    "        total_reward += reward\n",
    "\n",
    "        # Atualizar contagem de ações\n",
    "        actions_count[action] += 1\n",
    "\n",
    "        # Atualizar ganhos e perdas\n",
    "        if reward > 0:\n",
    "            wins += 1\n",
    "            win_total += reward\n",
    "        elif reward < 0:\n",
    "            losses += 1\n",
    "            lose_total += reward\n",
    "\n",
    "        # Registrar a operação se houver uma\n",
    "        if 'trade' in info:\n",
    "            trade_info = info['trade']\n",
    "            if trade_info['type'] in ['buy', 'sell']:\n",
    "                # Início de uma nova operação\n",
    "                current_trade = {\n",
    "                    'type': trade_info['type'],\n",
    "                    'entry_step': trade_info['entry_step'],\n",
    "                    'entry_price': trade_info['entry_price'],\n",
    "                    'exit_step': None,\n",
    "                    'exit_price': None,\n",
    "                    'profit': None\n",
    "                }\n",
    "            else:\n",
    "                # Fechamento de uma operação existente\n",
    "                current_trade['exit_step'] = trade_info['exit_step']\n",
    "                current_trade['exit_price'] = trade_info['exit_price']\n",
    "                current_trade['profit'] = trade_info['profit']\n",
    "                trades.append(current_trade)\n",
    "                current_trade = None  # Resetar a operação atual\n",
    "\n",
    "        # Treinar a rede se a memória tiver tamanho suficiente\n",
    "        if len(memory) >= batch_size:\n",
    "            batch = random.sample(memory, batch_size)\n",
    "            states, actions_batch, rewards_batch, next_states, dones = zip(*batch)\n",
    "\n",
    "            states = torch.cat(states).to(device)\n",
    "            actions_batch = torch.tensor(actions_batch, dtype=torch.long, device=device).unsqueeze(1)\n",
    "            rewards_batch = torch.tensor(rewards_batch, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            next_states = torch.cat(next_states).to(device)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            # Computar Q-valor atual\n",
    "            q_values = q_net(states).gather(1, actions_batch)\n",
    "\n",
    "            # Computar Q-valor alvo usando a rede alvo\n",
    "            with torch.no_grad():\n",
    "                next_q_values = target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "            target_q_values = rewards_batch + gamma * next_q_values * (1 - dones)\n",
    "\n",
    "            # Calcular a perda\n",
    "            loss = nn.MSELoss()(q_values, target_q_values)\n",
    "\n",
    "            # Otimizar a rede\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Decaimento de epsilon\n",
    "    epsilon = max(epsilon_end, epsilon_decay * epsilon)\n",
    "\n",
    "    # Atualizar a rede alvo\n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    # Cálculo do tempo de treinamento do episódio\n",
    "    end_time = time.time()\n",
    "    episode_time = end_time - start_time\n",
    "\n",
    "    win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "    print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward:.2f}, Win Rate: {win_rate:.2f}, \"\n",
    "          f\"Wins: {wins}, Losses: {losses}, Epsilon: {epsilon:.4f}, Steps: {steps}, Time: {episode_time:.2f}s\")\n",
    "    print(f\"Ações: Manter={actions_count[0]}, Comprar={actions_count[1]}, Vender={actions_count[2]}\")\n",
    "    print(f\"Ganhos Totais: {win_total:.2f}, Perdas Totais: {lose_total:.2f}\\n\")\n",
    "\n",
    "    # Salvar informações do episódio\n",
    "    episode_info = {\n",
    "        'episode': episode + 1,\n",
    "        'total_reward': total_reward,\n",
    "        'win_rate': win_rate,\n",
    "        'wins': wins,\n",
    "        'losses': losses,\n",
    "        'actions_count': actions_count.copy(),\n",
    "        'win_total': win_total,\n",
    "        'lose_total': lose_total,\n",
    "        'steps': steps,\n",
    "        'episode_time': episode_time,\n",
    "        'model_state_dict': q_net.state_dict(),\n",
    "        'trades': trades.copy()  # Salvar as operações do episódio\n",
    "    }\n",
    "\n",
    "    # Adicionar o episódio à lista e manter os top 10\n",
    "    best_episodes.append(episode_info)\n",
    "    best_episodes = sorted(best_episodes, key=lambda x: x['total_reward'], reverse=True)[:10]\n",
    "\n",
    "    # Salvar o modelo e log se o episódio for um dos top 10\n",
    "    if episode_info in best_episodes:\n",
    "        model_path = os.path.join(save_dir, f\"model_episode_{episode_info['episode']}.pth\")\n",
    "        torch.save(episode_info['model_state_dict'], model_path)\n",
    "        episode_info['model_path'] = model_path\n",
    "\n",
    "        # Salvar o log completo das operações\n",
    "        log_path = os.path.join(save_dir, f\"log_episode_{episode_info['episode']}.csv\")\n",
    "        trades_df = pd.DataFrame(episode_info['trades'])\n",
    "        trades_df.to_csv(log_path, index=False)\n",
    "        episode_info['log_path'] = log_path\n",
    "\n",
    "        print(f\"Modelo e log do episódio {episode_info['episode']} salvos em: {model_path} e {log_path}\")\n",
    "\n",
    "print(\"\\nTreinamento finalizado.\")\n",
    "print(\"Top 10 Melhores Episódios:\")\n",
    "for idx, ep in enumerate(best_episodes, 1):\n",
    "    print(f\"Rank {idx}: Episode {ep['episode']}, Total Reward: {ep['total_reward']:.2f}, \"\n",
    "          f\"Win Rate: {ep['win_rate']:.2f}, Wins: {ep['wins']}, Losses: {ep['losses']}, \"\n",
    "          f\"Ações: {ep['actions_count']}, Steps: {ep['steps']}, Time: {ep['episode_time']:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
