{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Normalização\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Bibliotecas de RL e ambiente\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "# Construção do modelo\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Agente de RL\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "# Callbacks e salvamento de modelos\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Utilitários do sistema\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento, preparação e Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>PavioSuperior</th>\n",
       "      <th>PavioInferior</th>\n",
       "      <th>Corpo</th>\n",
       "      <th>Range</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA100</th>\n",
       "      <th>SMA200</th>\n",
       "      <th>StochasticoK</th>\n",
       "      <th>StochasticoD</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACDSignal</th>\n",
       "      <th>MACDHistogram</th>\n",
       "      <th>Gatilho</th>\n",
       "      <th>Close_Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-20 22:01:00</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.019047</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.581175</td>\n",
       "      <td>0.044670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149275</td>\n",
       "      <td>0.679894</td>\n",
       "      <td>0.322707</td>\n",
       "      <td>0.526869</td>\n",
       "      <td>0.531171</td>\n",
       "      <td>0.481194</td>\n",
       "      <td>0</td>\n",
       "      <td>14018.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-20 22:02:00</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.031348</td>\n",
       "      <td>0.015695</td>\n",
       "      <td>0.603285</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.198658</td>\n",
       "      <td>0.635562</td>\n",
       "      <td>0.311794</td>\n",
       "      <td>0.522256</td>\n",
       "      <td>0.529060</td>\n",
       "      <td>0.474715</td>\n",
       "      <td>0</td>\n",
       "      <td>14017.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-20 22:03:00</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.595704</td>\n",
       "      <td>0.023350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.115503</td>\n",
       "      <td>0.585678</td>\n",
       "      <td>0.265733</td>\n",
       "      <td>0.517060</td>\n",
       "      <td>0.526206</td>\n",
       "      <td>0.468425</td>\n",
       "      <td>0</td>\n",
       "      <td>14013.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-20 22:04:00</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011211</td>\n",
       "      <td>0.606443</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.200449</td>\n",
       "      <td>0.546011</td>\n",
       "      <td>0.295303</td>\n",
       "      <td>0.513491</td>\n",
       "      <td>0.523122</td>\n",
       "      <td>0.466481</td>\n",
       "      <td>0</td>\n",
       "      <td>14014.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-20 22:05:00</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>0.007391</td>\n",
       "      <td>0.007621</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610865</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.470511</td>\n",
       "      <td>0.520501</td>\n",
       "      <td>0.376686</td>\n",
       "      <td>0.512138</td>\n",
       "      <td>0.520351</td>\n",
       "      <td>0.469130</td>\n",
       "      <td>0</td>\n",
       "      <td>14017.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482873</th>\n",
       "      <td>2024-08-30 17:56:00</td>\n",
       "      <td>0.809504</td>\n",
       "      <td>0.808626</td>\n",
       "      <td>0.810326</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020179</td>\n",
       "      <td>0.597599</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814601</td>\n",
       "      <td>0.809405</td>\n",
       "      <td>0.246966</td>\n",
       "      <td>0.439103</td>\n",
       "      <td>0.359597</td>\n",
       "      <td>0.513443</td>\n",
       "      <td>0.514129</td>\n",
       "      <td>0.485388</td>\n",
       "      <td>0</td>\n",
       "      <td>19829.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482874</th>\n",
       "      <td>2024-08-30 17:57:00</td>\n",
       "      <td>0.809228</td>\n",
       "      <td>0.808798</td>\n",
       "      <td>0.810568</td>\n",
       "      <td>0.809511</td>\n",
       "      <td>0.006480</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.608339</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814706</td>\n",
       "      <td>0.809487</td>\n",
       "      <td>0.467062</td>\n",
       "      <td>0.442631</td>\n",
       "      <td>0.426988</td>\n",
       "      <td>0.513505</td>\n",
       "      <td>0.513463</td>\n",
       "      <td>0.486942</td>\n",
       "      <td>0</td>\n",
       "      <td>19831.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482875</th>\n",
       "      <td>2024-08-30 17:58:00</td>\n",
       "      <td>0.809539</td>\n",
       "      <td>0.808867</td>\n",
       "      <td>0.810637</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.598863</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814810</td>\n",
       "      <td>0.809572</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.463263</td>\n",
       "      <td>0.395352</td>\n",
       "      <td>0.512971</td>\n",
       "      <td>0.512811</td>\n",
       "      <td>0.487054</td>\n",
       "      <td>0</td>\n",
       "      <td>19829.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482876</th>\n",
       "      <td>2024-08-30 17:59:00</td>\n",
       "      <td>0.809366</td>\n",
       "      <td>0.808626</td>\n",
       "      <td>0.810326</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.020179</td>\n",
       "      <td>0.600126</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814914</td>\n",
       "      <td>0.809656</td>\n",
       "      <td>0.564394</td>\n",
       "      <td>0.465122</td>\n",
       "      <td>0.380055</td>\n",
       "      <td>0.512314</td>\n",
       "      <td>0.512142</td>\n",
       "      <td>0.486910</td>\n",
       "      <td>0</td>\n",
       "      <td>19829.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482877</th>\n",
       "      <td>2024-08-30 18:00:00</td>\n",
       "      <td>0.809194</td>\n",
       "      <td>0.808660</td>\n",
       "      <td>0.810603</td>\n",
       "      <td>0.809269</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604548</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.809746</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.451692</td>\n",
       "      <td>0.395920</td>\n",
       "      <td>0.512130</td>\n",
       "      <td>0.511565</td>\n",
       "      <td>0.487693</td>\n",
       "      <td>0</td>\n",
       "      <td>19829.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482878 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DateTime      Open      High       Low     Close    Volume  \\\n",
       "0      2023-03-20 22:01:00  0.008828  0.008309  0.007667  0.007655  0.019047   \n",
       "1      2023-03-20 22:02:00  0.007518  0.007240  0.007494  0.007552  0.006545   \n",
       "2      2023-03-20 22:03:00  0.007449  0.006999  0.007080  0.007069  0.005564   \n",
       "3      2023-03-20 22:04:00  0.007000  0.006550  0.007045  0.007207  0.003076   \n",
       "4      2023-03-20 22:05:00  0.007173  0.006964  0.007391  0.007621  0.002422   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "482873 2024-08-30 17:56:00  0.809504  0.808626  0.810326  0.809200  0.007789   \n",
       "482874 2024-08-30 17:57:00  0.809228  0.808798  0.810568  0.809511  0.006480   \n",
       "482875 2024-08-30 17:58:00  0.809539  0.808867  0.810637  0.809304  0.007200   \n",
       "482876 2024-08-30 17:59:00  0.809366  0.808626  0.810326  0.809200  0.005367   \n",
       "482877 2024-08-30 18:00:00  0.809194  0.808660  0.810603  0.809269  0.006873   \n",
       "\n",
       "        PavioSuperior  PavioInferior     Corpo     Range  ...    SMA100  \\\n",
       "0            0.012539       0.013453  0.581175  0.044670  ...  0.001983   \n",
       "1            0.031348       0.015695  0.603285  0.018274  ...  0.002045   \n",
       "2            0.018809       0.013453  0.595704  0.023350  ...  0.002099   \n",
       "3            0.000000       0.011211  0.606443  0.011168  ...  0.002153   \n",
       "4            0.000000       0.000000  0.610865  0.013198  ...  0.002204   \n",
       "...               ...            ...       ...       ...  ...       ...   \n",
       "482873       0.000000       0.020179  0.597599  0.017259  ...  0.814601   \n",
       "482874       0.012539       0.004484  0.608339  0.015228  ...  0.814706   \n",
       "482875       0.018809       0.006726  0.598863  0.015228  ...  0.814810   \n",
       "482876       0.012539       0.020179  0.600126  0.017259  ...  0.814914   \n",
       "482877       0.021944       0.000000  0.604548  0.010152  ...  0.815014   \n",
       "\n",
       "          SMA200  StochasticoK  StochasticoD       RSI      MACD  MACDSignal  \\\n",
       "0       0.000000      0.149275      0.679894  0.322707  0.526869    0.531171   \n",
       "1       0.000056      0.198658      0.635562  0.311794  0.522256    0.529060   \n",
       "2       0.000109      0.115503      0.585678  0.265733  0.517060    0.526206   \n",
       "3       0.000169      0.200449      0.546011  0.295303  0.513491    0.523122   \n",
       "4       0.000229      0.470511      0.520501  0.376686  0.512138    0.520351   \n",
       "...          ...           ...           ...       ...       ...         ...   \n",
       "482873  0.809405      0.246966      0.439103  0.359597  0.513443    0.514129   \n",
       "482874  0.809487      0.467062      0.442631  0.426988  0.513505    0.513463   \n",
       "482875  0.809572      0.575758      0.463263  0.395352  0.512971    0.512811   \n",
       "482876  0.809656      0.564394      0.465122  0.380055  0.512314    0.512142   \n",
       "482877  0.809746      0.444444      0.451692  0.395920  0.512130    0.511565   \n",
       "\n",
       "        MACDHistogram  Gatilho  Close_Original  \n",
       "0            0.481194        0        14018.00  \n",
       "1            0.474715        0        14017.25  \n",
       "2            0.468425        0        14013.75  \n",
       "3            0.466481        0        14014.75  \n",
       "4            0.469130        0        14017.75  \n",
       "...               ...      ...             ...  \n",
       "482873       0.485388        0        19829.00  \n",
       "482874       0.486942        0        19831.25  \n",
       "482875       0.487054        0        19829.75  \n",
       "482876       0.486910        0        19829.00  \n",
       "482877       0.487693        0        19829.50  \n",
       "\n",
       "[482878 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar os dados\n",
    "data = pd.read_csv('D:\\\\dados\\\\bar_M1_data_20-03-2023_a_31-08-2024.csv', parse_dates=['DateTime'])\n",
    "\n",
    "# Criar uma cópia da coluna 'Close' original\n",
    "data['Close_Original'] = data['Close']\n",
    "\n",
    "# Lista de features para normalização\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'PavioSuperior', 'PavioInferior', 'Corpo', 'Range',\n",
    "            'D_Open', 'D_High', 'D_Low', 'D_Close', 'D_PavSup', 'D_PavInf', 'D_Corpo',\n",
    "            'SMA4', 'SMA8', 'SMA12', 'SMA20', 'SMA50', 'SMA100', 'SMA200',\n",
    "            'StochasticoK', 'StochasticoD', 'RSI', 'MACD', 'MACDSignal', 'MACDHistogram']\n",
    "\n",
    "# Inicializar o scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplicar a normalização\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Criação do Ambiente de Aprendizado por Reforço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Definição da Classe do Ambiente\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.current_step = 0\n",
    "        self.total_steps = len(self.data) - 1\n",
    "        self.position = 0  # 0: sem posição, 1: comprado, -1: vendido\n",
    "        self.balance = 0\n",
    "        self.entry_price = 0\n",
    "        self.real_rewards = []\n",
    "\n",
    "        # Espaço de ação: 0 - manter/não fazer nada, 1 - comprar, 2 - vender, 3 - fechar posição\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        # Espaço de observação: vetor das features normalizadas\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(len(features),), dtype=np.float32)\n",
    "\n",
    "        # Variáveis para recompensas e penalidades\n",
    "        self.recent_trades = []\n",
    "        self.max_recent_trades = 10\n",
    "        self.balance_factor = 1.0  # Fator de balanceamento ajustável\n",
    "\n",
    "        # Variáveis para métricas\n",
    "        self.total_profit = 0\n",
    "        self.num_correct_trades = 0\n",
    "        self.num_incorrect_trades = 0\n",
    "        self.max_consecutive_wins = 0\n",
    "        self.max_consecutive_losses = 0\n",
    "        self.current_consecutive_wins = 0\n",
    "        self.current_consecutive_losses = 0\n",
    "        self.balance_over_time = []\n",
    "        self.max_balance = 0\n",
    "        self.drawdown = 0\n",
    "\n",
    "#Explicação:\n",
    "#self.data: DataFrame contendo os dados de mercado.\n",
    "#self.current_step: Índice atual na sequência de dados.\n",
    "#self.position: Posição atual (0 = sem posição, 1 = comprado, -1 = vendido).\n",
    "#self.action_space: Define as ações que o agente pode tomar.\n",
    "#self.observation_space: Define a forma das observações que o agente recebe.\n",
    "#Variáveis para métricas: Usadas para rastrear o desempenho do agente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Implementação dos Métodos Principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinicia o ambiente para um novo episódio.\n",
    "def reset(self):\n",
    "    self.current_step = 0\n",
    "    self.position = 0\n",
    "    self.balance = 0\n",
    "    self.entry_price = 0\n",
    "    self.recent_trades = []\n",
    "    self.real_rewards = []\n",
    "\n",
    "    # Resetar métricas\n",
    "    self.reset_metrics()\n",
    "\n",
    "    return self._next_observation()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Método _next_observation\n",
    "Retorna a próxima observação (estado) para o agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _next_observation(self):\n",
    "    obs = self.data.loc[self.current_step, features].values\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Método step\n",
    "Executa uma ação e avança o ambiente para o próximo estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, action):\n",
    "    done = False\n",
    "    reward = 0\n",
    "\n",
    "    # Obter o gatilho atual\n",
    "    gatilho = self.data.loc[self.current_step, 'Gatilho']\n",
    "\n",
    "    # Preço de fechamento atual e próximo (usando 'Close_Original')\n",
    "    current_price = self.data.loc[self.current_step, 'Close_Original']\n",
    "    if self.current_step < self.total_steps:\n",
    "        next_price = self.data.loc[self.current_step + 1, 'Close_Original']\n",
    "    else:\n",
    "        next_price = current_price\n",
    "\n",
    "    # Lógica de ações\n",
    "    if gatilho == 1:\n",
    "        if action == 1 and self.position == 0:\n",
    "            # Comprar\n",
    "            self.position = 1\n",
    "            self.entry_price = current_price\n",
    "        elif action == 2 and self.position == 0:\n",
    "            # Vender\n",
    "            self.position = -1\n",
    "            self.entry_price = current_price\n",
    "        elif action == 3 and self.position != 0:\n",
    "            # Fechar posição\n",
    "            profit = (next_price - self.entry_price) * self.position\n",
    "            reward = self._calculate_reward(profit)\n",
    "            self.balance += profit\n",
    "            self.total_profit += profit\n",
    "\n",
    "            # Atualizar métricas de trades\n",
    "            self._update_trade_metrics(profit)\n",
    "\n",
    "            self.position = 0\n",
    "            self.entry_price = 0\n",
    "            self.recent_trades.append(1 if profit > 0 else -1)\n",
    "            self.real_rewards.append(profit)\n",
    "        else:\n",
    "            # Manter posição ou não fazer nada\n",
    "            pass\n",
    "    else:\n",
    "        # Gatilho é 0, fechar qualquer posição aberta\n",
    "        if self.position != 0:\n",
    "            # Fechar posição\n",
    "            profit = (next_price - self.entry_price) * self.position\n",
    "            reward = self._calculate_reward(profit)\n",
    "            self.balance += profit\n",
    "            self.total_profit += profit\n",
    "\n",
    "            # Atualizar métricas de trades\n",
    "            self._update_trade_metrics(profit)\n",
    "\n",
    "            self.position = 0\n",
    "            self.entry_price = 0\n",
    "            self.recent_trades.append(1 if profit > 0 else -1)\n",
    "            self.real_rewards.append(profit)\n",
    "        done = True  # O episódio termina aqui\n",
    "\n",
    "    # Limitar o tamanho da lista de trades recentes\n",
    "    if len(self.recent_trades) > self.max_recent_trades:\n",
    "        self.recent_trades.pop(0)\n",
    "\n",
    "    # Atualizar saldo ao longo do tempo\n",
    "    self.balance_over_time.append(self.balance)\n",
    "\n",
    "    # Atualizar drawdown\n",
    "    if self.balance > self.max_balance:\n",
    "        self.max_balance = self.balance\n",
    "    drawdown = self.max_balance - self.balance\n",
    "    if drawdown > self.drawdown:\n",
    "        self.drawdown = drawdown\n",
    "\n",
    "    # Próxima observação\n",
    "    self.current_step += 1\n",
    "    if self.current_step >= self.total_steps:\n",
    "        done = True\n",
    "\n",
    "    obs = self._next_observation()\n",
    "\n",
    "    return obs, reward, done, {}\n",
    "#Explicação:\n",
    "#Action Handling: Define como o ambiente reage às ações do agente.\n",
    "#Recompensas e Métricas: Calcula as recompensas e atualiza as métricas após cada operação.\n",
    "#Finalização do Episódio: O episódio termina quando o gatilho é 0 e não há mais dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Implementação do Sistema de Recompensas\n",
    "Calcula a recompensa baseada no lucro/prejuízo e nas regras de assertividade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_reward(self, profit):\n",
    "    base_reward = profit\n",
    "    accuracy = self.recent_trades.count(1) / len(self.recent_trades) if self.recent_trades else 0\n",
    "\n",
    "    # Recompensa extra por alta assertividade\n",
    "    consecutive_wins = self._check_consecutive_trades(1)\n",
    "    if consecutive_wins >= 3:\n",
    "        base_reward += self.balance_factor * consecutive_wins\n",
    "\n",
    "    # Penalidade por perdas consecutivas\n",
    "    consecutive_losses = self._check_consecutive_trades(-1)\n",
    "    if consecutive_losses >= 3:\n",
    "        base_reward -= self.balance_factor * consecutive_losses\n",
    "\n",
    "    return base_reward\n",
    "#Explicação:\n",
    "#base_reward: Inicia com o lucro ou prejuízo da operação.\n",
    "#Recompensas Extras: Adiciona recompensas adicionais para acertos consecutivos.\n",
    "#Penalidades: Subtrai penalidades para erros consecutivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Método _check_consecutive_trades\n",
    "Verifica o número de trades consecutivos de um determinado tipo (acertos ou erros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_consecutive_trades(self, trade_type):\n",
    "    count = 0\n",
    "    for trade in reversed(self.recent_trades):\n",
    "        if trade == trade_type:\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Implementação das Métricas de Performance\n",
    "### 3.4.1 Método _update_trade_metrics\n",
    "Atualiza as métricas relacionadas às operações após cada trade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_trade_metrics(self, profit):\n",
    "    if profit > 0:\n",
    "        self.num_correct_trades += 1\n",
    "        self.current_consecutive_wins += 1\n",
    "        self.current_consecutive_losses = 0\n",
    "        if self.current_consecutive_wins > self.max_consecutive_wins:\n",
    "            self.max_consecutive_wins = self.current_consecutive_wins\n",
    "    elif profit < 0:\n",
    "        self.num_incorrect_trades += 1\n",
    "        self.current_consecutive_losses += 1\n",
    "        self.current_consecutive_wins = 0\n",
    "        if self.current_consecutive_losses > self.max_consecutive_losses:\n",
    "            self.max_consecutive_losses = self.current_consecutive_losses\n",
    "    else:\n",
    "        # Trade neutro (sem lucro ou prejuízo)\n",
    "        self.current_consecutive_wins = 0\n",
    "        self.current_consecutive_losses = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Método reset_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_metrics(self):\n",
    "    self.total_profit = 0\n",
    "    self.num_correct_trades = 0\n",
    "    self.num_incorrect_trades = 0\n",
    "    self.max_consecutive_wins = 0\n",
    "    self.max_consecutive_losses = 0\n",
    "    self.current_consecutive_wins = 0\n",
    "    self.current_consecutive_losses = 0\n",
    "    self.balance_over_time = []\n",
    "    self.max_balance = 0\n",
    "    self.drawdown = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuração do Agente de Aprendizado por Reforço\n",
    "### 4.1 Divisão dos Dados para Treinamento e Teste\n",
    "Dividimos os dados em conjuntos de treinamento e teste, mantendo a ordem temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em treinamento (80%) e teste (20%)\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:].reset_index(drop=True)\n",
    "\n",
    "# Criar ambientes para treinamento e teste\n",
    "train_env = TradingEnv(train_data)\n",
    "test_env = TradingEnv(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Construção do Modelo Neural com Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 29)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3840      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,868\n",
      "Trainable params: 20,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Obter o número de ações e a forma de observação do ambiente\n",
    "nb_actions = train_env.action_space.n\n",
    "obs_shape = train_env.observation_space.shape\n",
    "\n",
    "# Construir o modelo\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + obs_shape))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_actions, activation='linear'))\n",
    "\n",
    "# Resumo do modelo\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Configuração do Agente DQN\n",
    "Configuramos o agente usando o algoritmo Deep Q-Network (DQN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m policy \u001b[38;5;241m=\u001b[39m BoltzmannQPolicy()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Criar o agente DQN\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dqn \u001b[38;5;241m=\u001b[39m \u001b[43mDQNAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_steps_warmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtarget_model_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m dqn\u001b[38;5;241m.\u001b[39mcompile(Adam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rl\\agents\\dqn.py:108\u001b[0m, in \u001b[0;36mDQNAgent.__init__\u001b[1;34m(self, model, policy, test_policy, enable_double_dqn, enable_dueling_network, dueling_type, *args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28msuper\u001b[39m(DQNAgent, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Validate (important) input.\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model\u001b[38;5;241m.\u001b[39moutput, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__len__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m has more than one output. DQN expects a model that has a single output.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model))\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39m_keras_shape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_actions):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\keras_tensor.py:244\u001b[0m, in \u001b[0;36mKerasTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras symbolic inputs/outputs do not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimplement `__len__`. You may be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrying to pass Keras symbolic inputs/outputs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto a TF API that does not register dispatching, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreventing Keras from automatically \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverting the API call to a lambda layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the Functional Model. This error will also get raised \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif you try asserting a symbolic input/output directly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly."
     ]
    }
   ],
   "source": [
    "# Configurar a memória e a política\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "\n",
    "# Criar o agente DQN\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=500,\n",
    "               target_model_update=1e-2, policy=policy, gamma=0.99)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementação dos Callbacks para Salvamento e Logging\n",
    "### 5.1 Callback para Salvar os Melhores Modelos\n",
    "Criamos um callback personalizado para salvar os 10 melhores modelos durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório para salvar os modelos\n",
    "save_dir = 'model_checkpoints'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "class SaveBestModels(Callback):\n",
    "    def __init__(self, save_dir, top_n=10):\n",
    "        super(SaveBestModels, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "        self.top_n = top_n\n",
    "        self.best_models = []\n",
    "\n",
    "    def on_episode_end(self, episode, logs={}):\n",
    "        total_reward = logs.get('episode_reward')\n",
    "        if total_reward is not None:\n",
    "            # Salvar o modelo se estiver entre os top_n\n",
    "            self.best_models.append((total_reward, episode))\n",
    "            self.best_models.sort(key=lambda x: x[0], reverse=True)\n",
    "            self.best_models = self.best_models[:self.top_n]\n",
    "\n",
    "            # Salvar o modelo atual se estiver entre os melhores\n",
    "            if any(episode == ep for _, ep in self.best_models):\n",
    "                filepath = os.path.join(self.save_dir, f'model_episode_{episode}_reward_{total_reward:.2f}.h5f')\n",
    "                self.model.save_weights(filepath)\n",
    "                print(f\"Modelo salvo: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Callback para Logging das Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsLogger(Callback):\n",
    "    def __init__(self, env):\n",
    "        super(MetricsLogger, self).__init__()\n",
    "        self.env = env  # Ambiente de treinamento\n",
    "        self.episode = 0\n",
    "\n",
    "    def on_episode_end(self, episode, logs={}):\n",
    "        self.episode += 1\n",
    "        total_profit = self.env.total_profit\n",
    "        num_correct_trades = self.env.num_correct_trades\n",
    "        num_incorrect_trades = self.env.num_incorrect_trades\n",
    "        max_consecutive_wins = self.env.max_consecutive_wins\n",
    "        max_consecutive_losses = self.env.max_consecutive_losses\n",
    "        drawdown = self.env.drawdown\n",
    "\n",
    "        print(f\"--- Episódio {self.episode} ---\")\n",
    "        print(f\"Ganho Real Total: {total_profit:.2f}\")\n",
    "        print(f\"Número de Operações Acertadas: {num_correct_trades}\")\n",
    "        print(f\"Número de Operações Erradas: {num_incorrect_trades}\")\n",
    "        print(f\"Maior Número de Acertos Consecutivos: {max_consecutive_wins}\")\n",
    "        print(f\"Maior Número de Erros Consecutivos: {max_consecutive_losses}\")\n",
    "        print(f\"Drawdown Máximo: {drawdown:.2f}\")\n",
    "        print(\"----------------------------\")\n",
    "\n",
    "        # Resetar métricas no ambiente\n",
    "        self.env.reset_metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Treinamento do Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar instâncias dos callbacks\n",
    "save_best_models = SaveBestModels(save_dir=save_dir, top_n=10)\n",
    "metrics_logger = MetricsLogger(env=train_env)\n",
    "\n",
    "# Lista de callbacks\n",
    "callbacks_list = [save_best_models, metrics_logger]\n",
    "\n",
    "# Treinar o agente\n",
    "dqn.fit(train_env, nb_steps=50000, visualize=False, verbose=0, callbacks=callbacks_list)\n",
    "#Explicação:\n",
    "#callbacks_list: Lista de callbacks a serem usados durante o treinamento.\n",
    "#nb_steps=50000: Número total de passos de treinamento.\n",
    "#verbose=0: Define o nível de verbosidade (0 = silencioso)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Avaliação do Agente\n",
    "### 7.1 Carregamento e Teste dos Modelos Salvos\n",
    "Carregamos um dos melhores modelos salvos e avaliamos no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar os modelos salvos\n",
    "model_files = glob.glob(os.path.join(save_dir, '*.h5f'))\n",
    "model_files.sort()\n",
    "print(\"Modelos salvos:\")\n",
    "for file in model_files:\n",
    "    print(file)\n",
    "\n",
    "# Selecionar o melhor modelo (por exemplo, o primeiro da lista)\n",
    "best_model_path = model_files[0]\n",
    "\n",
    "# Carregar os pesos do modelo\n",
    "dqn.load_weights(best_model_path)\n",
    "\n",
    "# Testar o agente no ambiente de teste\n",
    "dqn.test(test_env, nb_episodes=1, visualize=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Análise das Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessar as métricas do ambiente de teste\n",
    "print(f\"Ganho Real Total no Teste: {test_env.total_profit:.2f}\")\n",
    "print(f\"Número de Operações Acertadas no Teste: {test_env.num_correct_trades}\")\n",
    "print(f\"Número de Operações Erradas no Teste: {test_env.num_incorrect_trades}\")\n",
    "print(f\"Maior Número de Acertos Consecutivos no Teste: {test_env.max_consecutive_wins}\")\n",
    "print(f\"Maior Número de Erros Consecutivos no Teste: {test_env.max_consecutive_losses}\")\n",
    "print(f\"Drawdown Máximo no Teste: {test_env.drawdown:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Aplicação do Modelo em Novos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar novos dados\n",
    "new_data = pd.read_csv('novo_arquivo.csv', parse_dates=['DateTime'])\n",
    "\n",
    "# Manter a coluna 'Close' original\n",
    "new_data['Close_Original'] = new_data['Close']\n",
    "\n",
    "# Normalizar as features\n",
    "new_data[features] = scaler.transform(new_data[features])\n",
    "\n",
    "# Criar um novo ambiente\n",
    "new_env = TradingEnv(new_data)\n",
    "\n",
    "# Testar o agente no novo ambiente\n",
    "dqn.test(new_env, nb_episodes=1, visualize=False)\n",
    "\n",
    "# Analisar as métricas no novo ambiente\n",
    "print(f\"Ganho Real Total nos Novos Dados: {new_env.total_profit:.2f}\")\n",
    "# ... (restante das métricas) ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
