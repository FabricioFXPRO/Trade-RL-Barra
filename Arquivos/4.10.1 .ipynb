{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/200, Total Reward: -2912.25, Win Rate: 0.44, Wins: 335, Losses: 426, Epsilon: 0.4950, Steps: 36754, Time: 146.54s\n",
      "Ações: Manter=11296, Comprar=12805, Vender=12653\n",
      "Ganhos Totais: 6927.00, Perdas Totais: -9839.25\n",
      "Modelo e log do episódio 1 salvos em: 4.10.1\\model_episode_1.pth e 4.10.1\\log_episode_1.csv\n",
      "\n",
      "Episode 2/200, Total Reward: -1120.25, Win Rate: 0.50, Wins: 416, Losses: 419, Epsilon: 0.4900, Steps: 36754, Time: 156.99s\n",
      "Ações: Manter=10926, Comprar=13151, Vender=12677\n",
      "Ganhos Totais: 8764.25, Perdas Totais: -9884.50\n",
      "Modelo e log do episódio 2 salvos em: 4.10.1\\model_episode_2.pth e 4.10.1\\log_episode_2.csv\n",
      "\n",
      "Episode 3/200, Total Reward: -1949.00, Win Rate: 0.47, Wins: 372, Losses: 416, Epsilon: 0.4851, Steps: 36754, Time: 161.25s\n",
      "Ações: Manter=12479, Comprar=11786, Vender=12489\n",
      "Ganhos Totais: 7964.00, Perdas Totais: -9913.00\n",
      "Modelo e log do episódio 3 salvos em: 4.10.1\\model_episode_3.pth e 4.10.1\\log_episode_3.csv\n",
      "\n",
      "Episode 4/200, Total Reward: 252.75, Win Rate: 0.50, Wins: 413, Losses: 419, Epsilon: 0.4803, Steps: 36754, Time: 184.72s\n",
      "Ações: Manter=11198, Comprar=12457, Vender=13099\n",
      "Ganhos Totais: 9367.75, Perdas Totais: -9115.00\n",
      "Modelo e log do episódio 4 salvos em: 4.10.1\\model_episode_4.pth e 4.10.1\\log_episode_4.csv\n",
      "\n",
      "Episode 5/200, Total Reward: -1069.25, Win Rate: 0.51, Wins: 436, Losses: 413, Epsilon: 0.4755, Steps: 36754, Time: 185.09s\n",
      "Ações: Manter=12364, Comprar=12189, Vender=12201\n",
      "Ganhos Totais: 9345.00, Perdas Totais: -10414.25\n",
      "Modelo e log do episódio 5 salvos em: 4.10.1\\model_episode_5.pth e 4.10.1\\log_episode_5.csv\n",
      "\n",
      "Episode 6/200, Total Reward: -152.25, Win Rate: 0.52, Wins: 451, Losses: 416, Epsilon: 0.4707, Steps: 36754, Time: 201.16s\n",
      "Ações: Manter=11723, Comprar=12532, Vender=12499\n",
      "Ganhos Totais: 9255.00, Perdas Totais: -9407.25\n",
      "Modelo e log do episódio 6 salvos em: 4.10.1\\model_episode_6.pth e 4.10.1\\log_episode_6.csv\n",
      "\n",
      "Episode 7/200, Total Reward: -1738.75, Win Rate: 0.46, Wins: 364, Losses: 420, Epsilon: 0.4660, Steps: 36754, Time: 177.83s\n",
      "Ações: Manter=12687, Comprar=11719, Vender=12348\n",
      "Ganhos Totais: 8041.00, Perdas Totais: -9779.75\n",
      "Modelo e log do episódio 7 salvos em: 4.10.1\\model_episode_7.pth e 4.10.1\\log_episode_7.csv\n",
      "\n",
      "Episode 8/200, Total Reward: 1200.75, Win Rate: 0.50, Wins: 422, Losses: 418, Epsilon: 0.4614, Steps: 36754, Time: 174.19s\n",
      "Ações: Manter=12070, Comprar=12942, Vender=11742\n",
      "Ganhos Totais: 9329.00, Perdas Totais: -8128.25\n",
      "Modelo e log do episódio 8 salvos em: 4.10.1\\model_episode_8.pth e 4.10.1\\log_episode_8.csv\n",
      "\n",
      "Episode 9/200, Total Reward: -352.00, Win Rate: 0.51, Wins: 441, Losses: 422, Epsilon: 0.4568, Steps: 36754, Time: 174.72s\n",
      "Ações: Manter=12436, Comprar=12569, Vender=11749\n",
      "Ganhos Totais: 8800.00, Perdas Totais: -9152.00\n",
      "Modelo e log do episódio 9 salvos em: 4.10.1\\model_episode_9.pth e 4.10.1\\log_episode_9.csv\n",
      "\n",
      "Episode 10/200, Total Reward: -1235.00, Win Rate: 0.49, Wins: 407, Losses: 422, Epsilon: 0.4522, Steps: 36754, Time: 175.09s\n",
      "Ações: Manter=11707, Comprar=13309, Vender=11738\n",
      "Ganhos Totais: 7625.25, Perdas Totais: -8860.25\n",
      "Modelo e log do episódio 10 salvos em: 4.10.1\\model_episode_10.pth e 4.10.1\\log_episode_10.csv\n",
      "\n",
      "Episode 11/200, Total Reward: -167.00, Win Rate: 0.49, Wins: 402, Losses: 421, Epsilon: 0.4477, Steps: 36754, Time: 174.13s\n",
      "Ações: Manter=12675, Comprar=11638, Vender=12441\n",
      "Ganhos Totais: 8097.75, Perdas Totais: -8264.75\n",
      "Modelo e log do episódio 11 salvos em: 4.10.1\\model_episode_11.pth e 4.10.1\\log_episode_11.csv\n",
      "\n",
      "Episode 12/200, Total Reward: -455.50, Win Rate: 0.50, Wins: 409, Losses: 413, Epsilon: 0.4432, Steps: 36754, Time: 175.87s\n",
      "Ações: Manter=12093, Comprar=11568, Vender=13093\n",
      "Ganhos Totais: 7941.75, Perdas Totais: -8397.25\n",
      "Modelo e log do episódio 12 salvos em: 4.10.1\\model_episode_12.pth e 4.10.1\\log_episode_12.csv\n",
      "\n",
      "Episode 13/200, Total Reward: 565.75, Win Rate: 0.51, Wins: 434, Losses: 420, Epsilon: 0.4388, Steps: 36754, Time: 177.11s\n",
      "Ações: Manter=12955, Comprar=11404, Vender=12395\n",
      "Ganhos Totais: 9092.50, Perdas Totais: -8526.75\n",
      "Modelo e log do episódio 13 salvos em: 4.10.1\\model_episode_13.pth e 4.10.1\\log_episode_13.csv\n",
      "\n",
      "Episode 14/200, Total Reward: -990.75, Win Rate: 0.49, Wins: 396, Losses: 420, Epsilon: 0.4344, Steps: 36754, Time: 161.87s\n",
      "Ações: Manter=12326, Comprar=11023, Vender=13405\n",
      "Ganhos Totais: 8276.75, Perdas Totais: -9267.50\n",
      "Modelo e log do episódio 14 salvos em: 4.10.1\\model_episode_14.pth e 4.10.1\\log_episode_14.csv\n",
      "\n",
      "Episode 15/200, Total Reward: -3012.00, Win Rate: 0.49, Wins: 404, Losses: 425, Epsilon: 0.4300, Steps: 36754, Time: 148.07s\n",
      "Ações: Manter=11462, Comprar=11779, Vender=13513\n",
      "Ganhos Totais: 7389.75, Perdas Totais: -10401.75\n",
      "Episode 16/200, Total Reward: -426.00, Win Rate: 0.51, Wins: 438, Losses: 418, Epsilon: 0.4257, Steps: 36754, Time: 145.97s\n",
      "Ações: Manter=11912, Comprar=11841, Vender=13001\n",
      "Ganhos Totais: 8614.75, Perdas Totais: -9040.75\n",
      "Modelo e log do episódio 16 salvos em: 4.10.1\\model_episode_16.pth e 4.10.1\\log_episode_16.csv\n",
      "\n",
      "Episode 17/200, Total Reward: -1144.50, Win Rate: 0.49, Wins: 400, Losses: 423, Epsilon: 0.4215, Steps: 36754, Time: 145.64s\n",
      "Ações: Manter=11270, Comprar=12208, Vender=13276\n",
      "Ganhos Totais: 8911.75, Perdas Totais: -10056.25\n",
      "Episode 18/200, Total Reward: -2970.00, Win Rate: 0.48, Wins: 384, Losses: 418, Epsilon: 0.4173, Steps: 36754, Time: 145.93s\n",
      "Ações: Manter=11320, Comprar=12021, Vender=13413\n",
      "Ganhos Totais: 6811.25, Perdas Totais: -9781.25\n",
      "Episode 19/200, Total Reward: -1926.25, Win Rate: 0.48, Wins: 382, Losses: 415, Epsilon: 0.4131, Steps: 36754, Time: 146.29s\n",
      "Ações: Manter=12156, Comprar=12545, Vender=12053\n",
      "Ganhos Totais: 7836.50, Perdas Totais: -9762.75\n",
      "Episode 20/200, Total Reward: 638.75, Win Rate: 0.49, Wins: 397, Losses: 418, Epsilon: 0.4090, Steps: 36754, Time: 146.12s\n",
      "Ações: Manter=13010, Comprar=11562, Vender=12182\n",
      "Ganhos Totais: 9607.25, Perdas Totais: -8968.50\n",
      "Modelo e log do episódio 20 salvos em: 4.10.1\\model_episode_20.pth e 4.10.1\\log_episode_20.csv\n",
      "\n",
      "Episode 21/200, Total Reward: -375.00, Win Rate: 0.51, Wins: 435, Losses: 419, Epsilon: 0.4049, Steps: 36754, Time: 146.72s\n",
      "Ações: Manter=12043, Comprar=12164, Vender=12547\n",
      "Ganhos Totais: 10020.00, Perdas Totais: -10395.00\n",
      "Modelo e log do episódio 21 salvos em: 4.10.1\\model_episode_21.pth e 4.10.1\\log_episode_21.csv\n",
      "\n",
      "Episode 22/200, Total Reward: 1338.50, Win Rate: 0.51, Wins: 430, Losses: 409, Epsilon: 0.4008, Steps: 36754, Time: 146.91s\n",
      "Ações: Manter=11536, Comprar=13250, Vender=11968\n",
      "Ganhos Totais: 10392.25, Perdas Totais: -9053.75\n",
      "Modelo e log do episódio 22 salvos em: 4.10.1\\model_episode_22.pth e 4.10.1\\log_episode_22.csv\n",
      "\n",
      "Episode 23/200, Total Reward: -206.00, Win Rate: 0.51, Wins: 427, Losses: 409, Epsilon: 0.3968, Steps: 36754, Time: 147.54s\n",
      "Ações: Manter=12322, Comprar=11786, Vender=12646\n",
      "Ganhos Totais: 9484.25, Perdas Totais: -9690.25\n",
      "Modelo e log do episódio 23 salvos em: 4.10.1\\model_episode_23.pth e 4.10.1\\log_episode_23.csv\n",
      "\n",
      "Episode 24/200, Total Reward: -2010.75, Win Rate: 0.50, Wins: 417, Losses: 419, Epsilon: 0.3928, Steps: 36754, Time: 146.39s\n",
      "Ações: Manter=11720, Comprar=13440, Vender=11594\n",
      "Ganhos Totais: 9131.75, Perdas Totais: -11142.50\n",
      "Episode 25/200, Total Reward: -2781.75, Win Rate: 0.45, Wins: 345, Losses: 418, Epsilon: 0.3889, Steps: 36754, Time: 146.44s\n",
      "Ações: Manter=12823, Comprar=12988, Vender=10943\n",
      "Ganhos Totais: 7361.25, Perdas Totais: -10143.00\n",
      "Episode 26/200, Total Reward: -975.50, Win Rate: 0.48, Wins: 389, Losses: 417, Epsilon: 0.3850, Steps: 36754, Time: 146.75s\n",
      "Ações: Manter=12441, Comprar=12756, Vender=11557\n",
      "Ganhos Totais: 8994.25, Perdas Totais: -9969.75\n",
      "Episode 27/200, Total Reward: -1761.25, Win Rate: 0.51, Wins: 423, Losses: 412, Epsilon: 0.3812, Steps: 36754, Time: 146.67s\n",
      "Ações: Manter=11351, Comprar=11867, Vender=13536\n",
      "Ganhos Totais: 9028.50, Perdas Totais: -10789.75\n",
      "Episode 28/200, Total Reward: 53.50, Win Rate: 0.51, Wins: 431, Losses: 419, Epsilon: 0.3774, Steps: 36754, Time: 146.87s\n",
      "Ações: Manter=10580, Comprar=11915, Vender=14259\n",
      "Ganhos Totais: 8502.75, Perdas Totais: -8449.25\n",
      "Modelo e log do episódio 28 salvos em: 4.10.1\\model_episode_28.pth e 4.10.1\\log_episode_28.csv\n",
      "\n",
      "Episode 29/200, Total Reward: 604.25, Win Rate: 0.54, Wins: 467, Losses: 404, Epsilon: 0.3736, Steps: 36754, Time: 146.89s\n",
      "Ações: Manter=13067, Comprar=11981, Vender=11706\n",
      "Ganhos Totais: 11761.25, Perdas Totais: -11157.00\n",
      "Modelo e log do episódio 29 salvos em: 4.10.1\\model_episode_29.pth e 4.10.1\\log_episode_29.csv\n",
      "\n",
      "Episode 30/200, Total Reward: 1501.75, Win Rate: 0.54, Wins: 466, Losses: 405, Epsilon: 0.3699, Steps: 36754, Time: 146.97s\n",
      "Ações: Manter=11551, Comprar=11768, Vender=13435\n",
      "Ganhos Totais: 12184.50, Perdas Totais: -10682.75\n",
      "Modelo e log do episódio 30 salvos em: 4.10.1\\model_episode_30.pth e 4.10.1\\log_episode_30.csv\n",
      "\n",
      "Episode 31/200, Total Reward: 59.00, Win Rate: 0.53, Wins: 459, Losses: 412, Epsilon: 0.3662, Steps: 36754, Time: 147.01s\n",
      "Ações: Manter=12594, Comprar=10873, Vender=13287\n",
      "Ganhos Totais: 9917.25, Perdas Totais: -9858.25\n",
      "Modelo e log do episódio 31 salvos em: 4.10.1\\model_episode_31.pth e 4.10.1\\log_episode_31.csv\n",
      "\n",
      "Episode 32/200, Total Reward: 2448.75, Win Rate: 0.53, Wins: 467, Losses: 410, Epsilon: 0.3625, Steps: 36754, Time: 147.30s\n",
      "Ações: Manter=11944, Comprar=13110, Vender=11700\n",
      "Ganhos Totais: 11457.75, Perdas Totais: -9009.00\n",
      "Modelo e log do episódio 32 salvos em: 4.10.1\\model_episode_32.pth e 4.10.1\\log_episode_32.csv\n",
      "\n",
      "Episode 33/200, Total Reward: -1676.50, Win Rate: 0.49, Wins: 401, Losses: 414, Epsilon: 0.3589, Steps: 36754, Time: 147.41s\n",
      "Ações: Manter=11433, Comprar=11906, Vender=13415\n",
      "Ganhos Totais: 8770.25, Perdas Totais: -10446.75\n",
      "Episode 34/200, Total Reward: -633.00, Win Rate: 0.47, Wins: 377, Losses: 424, Epsilon: 0.3553, Steps: 36754, Time: 148.17s\n",
      "Ações: Manter=11538, Comprar=12609, Vender=12607\n",
      "Ganhos Totais: 8435.75, Perdas Totais: -9068.75\n",
      "Episode 35/200, Total Reward: 1098.75, Win Rate: 0.53, Wins: 468, Losses: 412, Epsilon: 0.3517, Steps: 36754, Time: 147.30s\n",
      "Ações: Manter=12875, Comprar=11717, Vender=12162\n",
      "Ganhos Totais: 10925.25, Perdas Totais: -9826.50\n",
      "Modelo e log do episódio 35 salvos em: 4.10.1\\model_episode_35.pth e 4.10.1\\log_episode_35.csv\n",
      "\n",
      "Episode 36/200, Total Reward: -1540.25, Win Rate: 0.50, Wins: 405, Losses: 412, Epsilon: 0.3482, Steps: 36754, Time: 147.62s\n",
      "Ações: Manter=11521, Comprar=11427, Vender=13806\n",
      "Ganhos Totais: 9031.25, Perdas Totais: -10571.50\n",
      "Episode 37/200, Total Reward: -1821.75, Win Rate: 0.50, Wins: 414, Losses: 411, Epsilon: 0.3447, Steps: 36754, Time: 147.61s\n",
      "Ações: Manter=10986, Comprar=12263, Vender=13505\n",
      "Ganhos Totais: 8711.75, Perdas Totais: -10533.50\n",
      "Episode 38/200, Total Reward: -338.00, Win Rate: 0.51, Wins: 420, Losses: 408, Epsilon: 0.3413, Steps: 36754, Time: 147.46s\n",
      "Ações: Manter=12327, Comprar=13430, Vender=10997\n",
      "Ganhos Totais: 9510.00, Perdas Totais: -9848.00\n",
      "Episode 39/200, Total Reward: -629.00, Win Rate: 0.50, Wins: 414, Losses: 412, Epsilon: 0.3379, Steps: 36754, Time: 147.89s\n",
      "Ações: Manter=13676, Comprar=9887, Vender=13191\n",
      "Ganhos Totais: 9579.25, Perdas Totais: -10208.25\n",
      "Episode 40/200, Total Reward: -755.75, Win Rate: 0.51, Wins: 432, Losses: 417, Epsilon: 0.3345, Steps: 36754, Time: 147.84s\n",
      "Ações: Manter=12713, Comprar=10324, Vender=13717\n",
      "Ganhos Totais: 9568.75, Perdas Totais: -10324.50\n",
      "Episode 41/200, Total Reward: -1089.50, Win Rate: 0.50, Wins: 421, Losses: 413, Epsilon: 0.3311, Steps: 36754, Time: 147.91s\n",
      "Ações: Manter=10751, Comprar=12020, Vender=13983\n",
      "Ganhos Totais: 9844.00, Perdas Totais: -10933.50\n",
      "Episode 42/200, Total Reward: -74.50, Win Rate: 0.48, Wins: 382, Losses: 412, Epsilon: 0.3278, Steps: 36754, Time: 148.27s\n",
      "Ações: Manter=12408, Comprar=11734, Vender=12612\n",
      "Ganhos Totais: 10572.50, Perdas Totais: -10647.00\n",
      "Episode 43/200, Total Reward: -679.50, Win Rate: 0.51, Wins: 435, Losses: 412, Epsilon: 0.3246, Steps: 36754, Time: 147.59s\n",
      "Ações: Manter=13973, Comprar=11941, Vender=10840\n",
      "Ganhos Totais: 10715.50, Perdas Totais: -11395.00\n",
      "Episode 44/200, Total Reward: -254.75, Win Rate: 0.50, Wins: 407, Losses: 412, Epsilon: 0.3213, Steps: 36754, Time: 147.93s\n",
      "Ações: Manter=11803, Comprar=12144, Vender=12807\n",
      "Ganhos Totais: 9218.00, Perdas Totais: -9472.75\n",
      "Episode 45/200, Total Reward: -877.25, Win Rate: 0.50, Wins: 416, Losses: 415, Epsilon: 0.3181, Steps: 36754, Time: 148.23s\n",
      "Ações: Manter=12252, Comprar=10704, Vender=13798\n",
      "Ganhos Totais: 10660.25, Perdas Totais: -11537.50\n",
      "Episode 46/200, Total Reward: 1496.50, Win Rate: 0.51, Wins: 424, Losses: 406, Epsilon: 0.3149, Steps: 36754, Time: 148.28s\n",
      "Ações: Manter=15254, Comprar=10542, Vender=10958\n",
      "Ganhos Totais: 12206.00, Perdas Totais: -10709.50\n",
      "Modelo e log do episódio 46 salvos em: 4.10.1\\model_episode_46.pth e 4.10.1\\log_episode_46.csv\n",
      "\n",
      "Episode 47/200, Total Reward: -898.25, Win Rate: 0.51, Wins: 418, Losses: 406, Epsilon: 0.3118, Steps: 36754, Time: 148.41s\n",
      "Ações: Manter=12086, Comprar=13211, Vender=11457\n",
      "Ganhos Totais: 9830.25, Perdas Totais: -10728.50\n",
      "Episode 48/200, Total Reward: 155.00, Win Rate: 0.50, Wins: 403, Losses: 406, Epsilon: 0.3086, Steps: 36754, Time: 149.48s\n",
      "Ações: Manter=14223, Comprar=10284, Vender=12247\n",
      "Ganhos Totais: 11787.00, Perdas Totais: -11632.00\n",
      "Episode 49/200, Total Reward: -32.75, Win Rate: 0.52, Wins: 441, Losses: 412, Epsilon: 0.3056, Steps: 36754, Time: 148.99s\n",
      "Ações: Manter=12373, Comprar=12192, Vender=12189\n",
      "Ganhos Totais: 10198.50, Perdas Totais: -10231.25\n",
      "Episode 50/200, Total Reward: -697.00, Win Rate: 0.50, Wins: 408, Losses: 410, Epsilon: 0.3025, Steps: 36754, Time: 148.61s\n",
      "Ações: Manter=14163, Comprar=10679, Vender=11912\n",
      "Ganhos Totais: 9525.75, Perdas Totais: -10222.75\n",
      "Episode 51/200, Total Reward: 533.50, Win Rate: 0.52, Wins: 447, Losses: 405, Epsilon: 0.2995, Steps: 36754, Time: 148.74s\n",
      "Ações: Manter=11943, Comprar=13028, Vender=11783\n",
      "Ganhos Totais: 9852.00, Perdas Totais: -9318.50\n",
      "Modelo e log do episódio 51 salvos em: 4.10.1\\model_episode_51.pth e 4.10.1\\log_episode_51.csv\n",
      "\n",
      "Episode 52/200, Total Reward: -3011.25, Win Rate: 0.50, Wins: 404, Losses: 406, Epsilon: 0.2965, Steps: 36754, Time: 148.93s\n",
      "Ações: Manter=13828, Comprar=12667, Vender=10259\n",
      "Ganhos Totais: 9042.50, Perdas Totais: -12053.75\n",
      "Episode 53/200, Total Reward: 518.75, Win Rate: 0.50, Wins: 412, Losses: 411, Epsilon: 0.2935, Steps: 36754, Time: 149.62s\n",
      "Ações: Manter=11881, Comprar=11524, Vender=13349\n",
      "Ganhos Totais: 10440.50, Perdas Totais: -9921.75\n",
      "Episode 54/200, Total Reward: -117.75, Win Rate: 0.50, Wins: 417, Losses: 410, Epsilon: 0.2906, Steps: 36754, Time: 149.36s\n",
      "Ações: Manter=14083, Comprar=10956, Vender=11715\n",
      "Ganhos Totais: 10301.25, Perdas Totais: -10419.00\n",
      "Episode 55/200, Total Reward: -387.00, Win Rate: 0.48, Wins: 377, Losses: 408, Epsilon: 0.2877, Steps: 36754, Time: 149.41s\n",
      "Ações: Manter=12444, Comprar=12121, Vender=12189\n",
      "Ganhos Totais: 10094.00, Perdas Totais: -10481.00\n",
      "Episode 56/200, Total Reward: -985.50, Win Rate: 0.52, Wins: 429, Losses: 397, Epsilon: 0.2848, Steps: 36754, Time: 149.12s\n",
      "Ações: Manter=13525, Comprar=12967, Vender=10262\n",
      "Ganhos Totais: 10108.25, Perdas Totais: -11093.75\n",
      "Episode 57/200, Total Reward: -360.25, Win Rate: 0.49, Wins: 397, Losses: 412, Epsilon: 0.2820, Steps: 36754, Time: 148.66s\n",
      "Ações: Manter=12582, Comprar=12702, Vender=11470\n",
      "Ganhos Totais: 8949.50, Perdas Totais: -9309.75\n",
      "Episode 58/200, Total Reward: -108.25, Win Rate: 0.50, Wins: 416, Losses: 415, Epsilon: 0.2791, Steps: 36754, Time: 149.26s\n",
      "Ações: Manter=12502, Comprar=12130, Vender=12122\n",
      "Ganhos Totais: 8597.50, Perdas Totais: -8705.75\n",
      "Episode 59/200, Total Reward: -1932.50, Win Rate: 0.48, Wins: 386, Losses: 413, Epsilon: 0.2763, Steps: 36754, Time: 149.24s\n",
      "Ações: Manter=12043, Comprar=12728, Vender=11983\n",
      "Ganhos Totais: 8456.75, Perdas Totais: -10389.25\n",
      "Episode 60/200, Total Reward: 1606.75, Win Rate: 0.53, Wins: 444, Losses: 386, Epsilon: 0.2736, Steps: 36754, Time: 149.39s\n",
      "Ações: Manter=14036, Comprar=12584, Vender=10134\n",
      "Ganhos Totais: 12006.00, Perdas Totais: -10399.25\n",
      "Modelo e log do episódio 60 salvos em: 4.10.1\\model_episode_60.pth e 4.10.1\\log_episode_60.csv\n",
      "\n",
      "Episode 61/200, Total Reward: -215.25, Win Rate: 0.54, Wins: 473, Losses: 405, Epsilon: 0.2708, Steps: 36754, Time: 149.17s\n",
      "Ações: Manter=11471, Comprar=12817, Vender=12466\n",
      "Ganhos Totais: 10999.25, Perdas Totais: -11214.50\n",
      "Episode 62/200, Total Reward: 701.00, Win Rate: 0.53, Wins: 457, Losses: 400, Epsilon: 0.2681, Steps: 36754, Time: 149.80s\n",
      "Ações: Manter=13159, Comprar=12160, Vender=11435\n",
      "Ganhos Totais: 11066.25, Perdas Totais: -10365.25\n",
      "Modelo e log do episódio 62 salvos em: 4.10.1\\model_episode_62.pth e 4.10.1\\log_episode_62.csv\n",
      "\n",
      "Episode 63/200, Total Reward: -16.50, Win Rate: 0.51, Wins: 427, Losses: 415, Epsilon: 0.2655, Steps: 36754, Time: 149.53s\n",
      "Ações: Manter=11531, Comprar=14577, Vender=10646\n",
      "Ganhos Totais: 10439.75, Perdas Totais: -10456.25\n",
      "Episode 64/200, Total Reward: -1723.75, Win Rate: 0.49, Wins: 389, Losses: 409, Epsilon: 0.2628, Steps: 36754, Time: 149.50s\n",
      "Ações: Manter=13241, Comprar=13746, Vender=9767\n",
      "Ganhos Totais: 9386.00, Perdas Totais: -11109.75\n",
      "Episode 65/200, Total Reward: -508.50, Win Rate: 0.50, Wins: 401, Losses: 409, Epsilon: 0.2602, Steps: 36754, Time: 149.92s\n",
      "Ações: Manter=14304, Comprar=9967, Vender=12483\n",
      "Ganhos Totais: 10738.75, Perdas Totais: -11247.25\n",
      "Episode 66/200, Total Reward: 2672.00, Win Rate: 0.54, Wins: 476, Losses: 410, Epsilon: 0.2576, Steps: 36754, Time: 150.15s\n",
      "Ações: Manter=12327, Comprar=13114, Vender=11313\n",
      "Ganhos Totais: 12549.75, Perdas Totais: -9877.75\n",
      "Modelo e log do episódio 66 salvos em: 4.10.1\\model_episode_66.pth e 4.10.1\\log_episode_66.csv\n",
      "\n",
      "Episode 67/200, Total Reward: 1243.25, Win Rate: 0.53, Wins: 464, Losses: 409, Epsilon: 0.2550, Steps: 36754, Time: 149.76s\n",
      "Ações: Manter=10625, Comprar=13654, Vender=12475\n",
      "Ganhos Totais: 10424.00, Perdas Totais: -9180.75\n",
      "Modelo e log do episódio 67 salvos em: 4.10.1\\model_episode_67.pth e 4.10.1\\log_episode_67.csv\n",
      "\n",
      "Episode 68/200, Total Reward: 1792.00, Win Rate: 0.50, Wins: 413, Losses: 411, Epsilon: 0.2524, Steps: 36754, Time: 150.18s\n",
      "Ações: Manter=11955, Comprar=10287, Vender=14512\n",
      "Ganhos Totais: 11444.00, Perdas Totais: -9652.00\n",
      "Modelo e log do episódio 68 salvos em: 4.10.1\\model_episode_68.pth e 4.10.1\\log_episode_68.csv\n",
      "\n",
      "Episode 69/200, Total Reward: 416.75, Win Rate: 0.51, Wins: 425, Losses: 405, Epsilon: 0.2499, Steps: 36754, Time: 149.75s\n",
      "Ações: Manter=11033, Comprar=12157, Vender=13564\n",
      "Ganhos Totais: 10291.75, Perdas Totais: -9875.00\n",
      "Episode 70/200, Total Reward: 76.25, Win Rate: 0.53, Wins: 454, Losses: 407, Epsilon: 0.2474, Steps: 36754, Time: 149.81s\n",
      "Ações: Manter=13449, Comprar=12731, Vender=10574\n",
      "Ganhos Totais: 11670.25, Perdas Totais: -11594.00\n",
      "Episode 71/200, Total Reward: 2158.25, Win Rate: 0.53, Wins: 461, Losses: 402, Epsilon: 0.2449, Steps: 36754, Time: 149.73s\n",
      "Ações: Manter=12989, Comprar=10995, Vender=12770\n",
      "Ganhos Totais: 12008.25, Perdas Totais: -9850.00\n",
      "Modelo e log do episódio 71 salvos em: 4.10.1\\model_episode_71.pth e 4.10.1\\log_episode_71.csv\n",
      "\n",
      "Episode 72/200, Total Reward: -772.75, Win Rate: 0.54, Wins: 480, Losses: 405, Epsilon: 0.2425, Steps: 36754, Time: 150.84s\n",
      "Ações: Manter=13919, Comprar=11190, Vender=11645\n",
      "Ganhos Totais: 11561.50, Perdas Totais: -12334.25\n",
      "Episode 73/200, Total Reward: -334.50, Win Rate: 0.49, Wins: 384, Losses: 399, Epsilon: 0.2401, Steps: 36754, Time: 150.53s\n",
      "Ações: Manter=14372, Comprar=11446, Vender=10936\n",
      "Ganhos Totais: 11445.00, Perdas Totais: -11779.50\n",
      "Episode 74/200, Total Reward: 1270.00, Win Rate: 0.54, Wins: 456, Losses: 396, Epsilon: 0.2377, Steps: 36754, Time: 149.94s\n",
      "Ações: Manter=12731, Comprar=12127, Vender=11896\n",
      "Ganhos Totais: 11968.75, Perdas Totais: -10698.75\n",
      "Modelo e log do episódio 74 salvos em: 4.10.1\\model_episode_74.pth e 4.10.1\\log_episode_74.csv\n",
      "\n",
      "Episode 75/200, Total Reward: -262.50, Win Rate: 0.51, Wins: 426, Losses: 409, Epsilon: 0.2353, Steps: 36754, Time: 150.08s\n",
      "Ações: Manter=10875, Comprar=13157, Vender=12722\n",
      "Ganhos Totais: 10020.75, Perdas Totais: -10283.25\n",
      "Episode 76/200, Total Reward: 1238.50, Win Rate: 0.51, Wins: 428, Losses: 409, Epsilon: 0.2329, Steps: 36754, Time: 150.30s\n",
      "Ações: Manter=12869, Comprar=12703, Vender=11182\n",
      "Ganhos Totais: 11952.00, Perdas Totais: -10713.50\n",
      "Episode 77/200, Total Reward: 1547.75, Win Rate: 0.53, Wins: 449, Losses: 398, Epsilon: 0.2306, Steps: 36754, Time: 150.26s\n",
      "Ações: Manter=12026, Comprar=11405, Vender=13323\n",
      "Ganhos Totais: 12578.50, Perdas Totais: -11030.75\n",
      "Modelo e log do episódio 77 salvos em: 4.10.1\\model_episode_77.pth e 4.10.1\\log_episode_77.csv\n",
      "\n",
      "Episode 78/200, Total Reward: -268.50, Win Rate: 0.51, Wins: 415, Losses: 398, Epsilon: 0.2283, Steps: 36754, Time: 150.45s\n",
      "Ações: Manter=11122, Comprar=12016, Vender=13616\n",
      "Ganhos Totais: 10957.50, Perdas Totais: -11226.00\n",
      "Episode 79/200, Total Reward: 1561.00, Win Rate: 0.53, Wins: 453, Losses: 398, Epsilon: 0.2260, Steps: 36754, Time: 150.20s\n",
      "Ações: Manter=14760, Comprar=10244, Vender=11750\n",
      "Ganhos Totais: 12946.75, Perdas Totais: -11385.75\n",
      "Modelo e log do episódio 79 salvos em: 4.10.1\\model_episode_79.pth e 4.10.1\\log_episode_79.csv\n",
      "\n",
      "Episode 80/200, Total Reward: 393.00, Win Rate: 0.50, Wins: 413, Losses: 405, Epsilon: 0.2238, Steps: 36754, Time: 150.00s\n",
      "Ações: Manter=10512, Comprar=12855, Vender=13387\n",
      "Ganhos Totais: 11035.00, Perdas Totais: -10642.00\n",
      "Episode 81/200, Total Reward: -1796.50, Win Rate: 0.51, Wins: 422, Losses: 411, Epsilon: 0.2215, Steps: 36754, Time: 139.10s\n",
      "Ações: Manter=10733, Comprar=10867, Vender=15154\n",
      "Ganhos Totais: 9948.75, Perdas Totais: -11745.25\n",
      "Episode 82/200, Total Reward: 3291.00, Win Rate: 0.54, Wins: 465, Losses: 396, Epsilon: 0.2193, Steps: 36754, Time: 137.73s\n",
      "Ações: Manter=11661, Comprar=10711, Vender=14382\n",
      "Ganhos Totais: 14021.25, Perdas Totais: -10730.25\n",
      "Modelo e log do episódio 82 salvos em: 4.10.1\\model_episode_82.pth e 4.10.1\\log_episode_82.csv\n",
      "\n",
      "Episode 83/200, Total Reward: 509.00, Win Rate: 0.52, Wins: 425, Losses: 399, Epsilon: 0.2171, Steps: 36754, Time: 137.83s\n",
      "Ações: Manter=12943, Comprar=12754, Vender=11057\n",
      "Ganhos Totais: 11667.25, Perdas Totais: -11158.25\n",
      "Episode 84/200, Total Reward: -390.25, Win Rate: 0.49, Wins: 383, Losses: 404, Epsilon: 0.2149, Steps: 36754, Time: 137.36s\n",
      "Ações: Manter=13155, Comprar=13277, Vender=10322\n",
      "Ganhos Totais: 9607.00, Perdas Totais: -9997.25\n",
      "Episode 85/200, Total Reward: -1061.25, Win Rate: 0.51, Wins: 423, Losses: 410, Epsilon: 0.2128, Steps: 36754, Time: 137.48s\n",
      "Ações: Manter=12299, Comprar=12521, Vender=11934\n",
      "Ganhos Totais: 8876.75, Perdas Totais: -9938.00\n",
      "Episode 86/200, Total Reward: -626.25, Win Rate: 0.48, Wins: 365, Losses: 402, Epsilon: 0.2107, Steps: 36754, Time: 137.12s\n",
      "Ações: Manter=11331, Comprar=12384, Vender=13039\n",
      "Ganhos Totais: 9172.50, Perdas Totais: -9798.75\n",
      "Episode 87/200, Total Reward: -3099.50, Win Rate: 0.46, Wins: 354, Losses: 408, Epsilon: 0.2086, Steps: 36754, Time: 137.14s\n",
      "Ações: Manter=13673, Comprar=11717, Vender=11364\n",
      "Ganhos Totais: 9250.25, Perdas Totais: -12349.75\n",
      "Episode 88/200, Total Reward: -2080.75, Win Rate: 0.47, Wins: 373, Losses: 413, Epsilon: 0.2065, Steps: 36754, Time: 137.01s\n",
      "Ações: Manter=13193, Comprar=10243, Vender=13318\n",
      "Ganhos Totais: 9533.75, Perdas Totais: -11614.50\n",
      "Episode 89/200, Total Reward: 1948.75, Win Rate: 0.52, Wins: 436, Losses: 403, Epsilon: 0.2044, Steps: 36754, Time: 137.01s\n",
      "Ações: Manter=12212, Comprar=12458, Vender=12084\n",
      "Ganhos Totais: 11489.50, Perdas Totais: -9540.75\n",
      "Modelo e log do episódio 89 salvos em: 4.10.1\\model_episode_89.pth e 4.10.1\\log_episode_89.csv\n",
      "\n",
      "Episode 90/200, Total Reward: -2502.75, Win Rate: 0.47, Wins: 359, Losses: 406, Epsilon: 0.2024, Steps: 36754, Time: 137.31s\n",
      "Ações: Manter=12978, Comprar=10205, Vender=13571\n",
      "Ganhos Totais: 10176.25, Perdas Totais: -12679.00\n",
      "Episode 91/200, Total Reward: 500.75, Win Rate: 0.50, Wins: 396, Losses: 389, Epsilon: 0.2003, Steps: 36754, Time: 137.27s\n",
      "Ações: Manter=13415, Comprar=12308, Vender=11031\n",
      "Ganhos Totais: 11663.25, Perdas Totais: -11162.50\n",
      "Episode 92/200, Total Reward: 414.00, Win Rate: 0.52, Wins: 420, Losses: 393, Epsilon: 0.1983, Steps: 36754, Time: 137.30s\n",
      "Ações: Manter=11598, Comprar=12389, Vender=12767\n",
      "Ganhos Totais: 11791.50, Perdas Totais: -11377.50\n",
      "Episode 93/200, Total Reward: -1148.50, Win Rate: 0.49, Wins: 387, Losses: 409, Epsilon: 0.1964, Steps: 36754, Time: 137.50s\n",
      "Ações: Manter=11042, Comprar=15161, Vender=10551\n",
      "Ganhos Totais: 9905.00, Perdas Totais: -11053.50\n",
      "Episode 94/200, Total Reward: 483.75, Win Rate: 0.49, Wins: 378, Losses: 399, Epsilon: 0.1944, Steps: 36754, Time: 137.72s\n",
      "Ações: Manter=13623, Comprar=12123, Vender=11008\n",
      "Ganhos Totais: 10169.00, Perdas Totais: -9685.25\n",
      "Episode 95/200, Total Reward: 447.25, Win Rate: 0.51, Wins: 420, Losses: 399, Epsilon: 0.1924, Steps: 36754, Time: 137.42s\n",
      "Ações: Manter=11620, Comprar=13235, Vender=11899\n",
      "Ganhos Totais: 11306.75, Perdas Totais: -10859.50\n",
      "Episode 96/200, Total Reward: -3464.25, Win Rate: 0.46, Wins: 349, Losses: 408, Epsilon: 0.1905, Steps: 36754, Time: 137.31s\n",
      "Ações: Manter=11043, Comprar=12401, Vender=13310\n",
      "Ganhos Totais: 9354.75, Perdas Totais: -12819.00\n",
      "Episode 97/200, Total Reward: -3097.00, Win Rate: 0.51, Wins: 414, Losses: 403, Epsilon: 0.1886, Steps: 36754, Time: 137.77s\n",
      "Ações: Manter=10687, Comprar=11721, Vender=14346\n",
      "Ganhos Totais: 9596.00, Perdas Totais: -12693.00\n",
      "Episode 98/200, Total Reward: -320.50, Win Rate: 0.48, Wins: 369, Losses: 403, Epsilon: 0.1867, Steps: 36754, Time: 137.66s\n",
      "Ações: Manter=12964, Comprar=12359, Vender=11431\n",
      "Ganhos Totais: 10514.75, Perdas Totais: -10835.25\n",
      "Episode 99/200, Total Reward: -512.00, Win Rate: 0.53, Wins: 442, Losses: 398, Epsilon: 0.1849, Steps: 36754, Time: 137.98s\n",
      "Ações: Manter=12962, Comprar=10526, Vender=13266\n",
      "Ganhos Totais: 12466.75, Perdas Totais: -12978.75\n",
      "Episode 100/200, Total Reward: -1686.25, Win Rate: 0.48, Wins: 390, Losses: 417, Epsilon: 0.1830, Steps: 36754, Time: 138.71s\n",
      "Ações: Manter=10975, Comprar=12507, Vender=13272\n",
      "Ganhos Totais: 8796.00, Perdas Totais: -10482.25\n",
      "Episode 101/200, Total Reward: -165.75, Win Rate: 0.50, Wins: 405, Losses: 398, Epsilon: 0.1812, Steps: 36754, Time: 137.51s\n",
      "Ações: Manter=13915, Comprar=9467, Vender=13372\n",
      "Ganhos Totais: 10881.75, Perdas Totais: -11047.50\n",
      "Episode 102/200, Total Reward: 511.75, Win Rate: 0.50, Wins: 401, Losses: 405, Epsilon: 0.1794, Steps: 36754, Time: 132.44s\n",
      "Ações: Manter=9418, Comprar=13051, Vender=14285\n",
      "Ganhos Totais: 10891.50, Perdas Totais: -10379.75\n",
      "Episode 103/200, Total Reward: -2051.25, Win Rate: 0.52, Wins: 428, Losses: 389, Epsilon: 0.1776, Steps: 36754, Time: 130.31s\n",
      "Ações: Manter=14491, Comprar=9840, Vender=12423\n",
      "Ganhos Totais: 11526.75, Perdas Totais: -13578.00\n",
      "Episode 104/200, Total Reward: -1935.25, Win Rate: 0.49, Wins: 378, Losses: 400, Epsilon: 0.1758, Steps: 36754, Time: 130.49s\n",
      "Ações: Manter=13220, Comprar=10003, Vender=13531\n",
      "Ganhos Totais: 10456.00, Perdas Totais: -12391.25\n",
      "Episode 105/200, Total Reward: -578.75, Win Rate: 0.51, Wins: 414, Losses: 398, Epsilon: 0.1740, Steps: 36754, Time: 130.67s\n",
      "Ações: Manter=13352, Comprar=10451, Vender=12951\n",
      "Ganhos Totais: 10819.75, Perdas Totais: -11398.50\n",
      "Episode 106/200, Total Reward: 1198.50, Win Rate: 0.52, Wins: 422, Losses: 390, Epsilon: 0.1723, Steps: 36754, Time: 130.53s\n",
      "Ações: Manter=14268, Comprar=10926, Vender=11560\n",
      "Ganhos Totais: 13259.25, Perdas Totais: -12060.75\n",
      "Episode 107/200, Total Reward: -1242.50, Win Rate: 0.51, Wins: 400, Losses: 387, Epsilon: 0.1706, Steps: 36754, Time: 130.99s\n",
      "Ações: Manter=14204, Comprar=10744, Vender=11806\n",
      "Ganhos Totais: 10739.25, Perdas Totais: -11981.75\n",
      "Episode 108/200, Total Reward: -379.25, Win Rate: 0.48, Wins: 370, Losses: 400, Epsilon: 0.1689, Steps: 36754, Time: 134.51s\n",
      "Ações: Manter=9436, Comprar=15809, Vender=11509\n",
      "Ganhos Totais: 10247.50, Perdas Totais: -10626.75\n",
      "Episode 109/200, Total Reward: -2167.00, Win Rate: 0.53, Wins: 437, Losses: 395, Epsilon: 0.1672, Steps: 36754, Time: 131.54s\n",
      "Ações: Manter=14427, Comprar=9604, Vender=12723\n",
      "Ganhos Totais: 12129.75, Perdas Totais: -14296.75\n",
      "Episode 110/200, Total Reward: -71.25, Win Rate: 0.53, Wins: 443, Losses: 392, Epsilon: 0.1655, Steps: 36754, Time: 130.69s\n",
      "Ações: Manter=15342, Comprar=9945, Vender=11467\n",
      "Ganhos Totais: 12369.50, Perdas Totais: -12440.75\n",
      "Episode 111/200, Total Reward: -740.25, Win Rate: 0.51, Wins: 405, Losses: 384, Epsilon: 0.1639, Steps: 36754, Time: 130.99s\n",
      "Ações: Manter=15203, Comprar=11334, Vender=10217\n",
      "Ganhos Totais: 11855.50, Perdas Totais: -12595.75\n",
      "Episode 112/200, Total Reward: -350.00, Win Rate: 0.50, Wins: 399, Losses: 392, Epsilon: 0.1622, Steps: 36754, Time: 130.71s\n",
      "Ações: Manter=14493, Comprar=10230, Vender=12031\n",
      "Ganhos Totais: 12876.50, Perdas Totais: -13226.50\n",
      "Episode 113/200, Total Reward: -674.50, Win Rate: 0.50, Wins: 400, Losses: 402, Epsilon: 0.1606, Steps: 36754, Time: 132.54s\n",
      "Ações: Manter=13161, Comprar=12094, Vender=11499\n",
      "Ganhos Totais: 10092.50, Perdas Totais: -10767.00\n",
      "Episode 114/200, Total Reward: -1346.25, Win Rate: 0.51, Wins: 404, Losses: 394, Epsilon: 0.1590, Steps: 36754, Time: 130.63s\n",
      "Ações: Manter=16514, Comprar=9294, Vender=10946\n",
      "Ganhos Totais: 11365.25, Perdas Totais: -12711.50\n",
      "Episode 115/200, Total Reward: 2840.75, Win Rate: 0.53, Wins: 452, Losses: 399, Epsilon: 0.1574, Steps: 36754, Time: 131.14s\n",
      "Ações: Manter=12905, Comprar=12585, Vender=11264\n",
      "Ganhos Totais: 13619.25, Perdas Totais: -10778.50\n",
      "Modelo e log do episódio 115 salvos em: 4.10.1\\model_episode_115.pth e 4.10.1\\log_episode_115.csv\n",
      "\n",
      "Episode 116/200, Total Reward: 1093.00, Win Rate: 0.52, Wins: 426, Losses: 397, Epsilon: 0.1558, Steps: 36754, Time: 131.17s\n",
      "Ações: Manter=15565, Comprar=10381, Vender=10808\n",
      "Ganhos Totais: 10929.25, Perdas Totais: -9836.25\n",
      "Episode 117/200, Total Reward: -353.50, Win Rate: 0.50, Wins: 396, Losses: 397, Epsilon: 0.1543, Steps: 36754, Time: 131.22s\n",
      "Ações: Manter=15349, Comprar=10790, Vender=10615\n",
      "Ganhos Totais: 11651.75, Perdas Totais: -12005.25\n",
      "Episode 118/200, Total Reward: 2232.50, Win Rate: 0.52, Wins: 414, Losses: 389, Epsilon: 0.1527, Steps: 36754, Time: 131.93s\n",
      "Ações: Manter=13989, Comprar=13044, Vender=9721\n",
      "Ganhos Totais: 11870.25, Perdas Totais: -9637.75\n",
      "Modelo e log do episódio 118 salvos em: 4.10.1\\model_episode_118.pth e 4.10.1\\log_episode_118.csv\n",
      "\n",
      "Episode 119/200, Total Reward: 500.50, Win Rate: 0.52, Wins: 419, Losses: 392, Epsilon: 0.1512, Steps: 36754, Time: 131.50s\n",
      "Ações: Manter=13881, Comprar=11088, Vender=11785\n",
      "Ganhos Totais: 12443.50, Perdas Totais: -11943.00\n",
      "Episode 120/200, Total Reward: 1487.25, Win Rate: 0.52, Wins: 423, Losses: 385, Epsilon: 0.1497, Steps: 36754, Time: 131.80s\n",
      "Ações: Manter=13037, Comprar=12336, Vender=11381\n",
      "Ganhos Totais: 11707.00, Perdas Totais: -10219.75\n",
      "Episode 121/200, Total Reward: 2005.25, Win Rate: 0.53, Wins: 450, Losses: 397, Epsilon: 0.1482, Steps: 36754, Time: 131.99s\n",
      "Ações: Manter=12165, Comprar=11691, Vender=12898\n",
      "Ganhos Totais: 12868.75, Perdas Totais: -10863.50\n",
      "Modelo e log do episódio 121 salvos em: 4.10.1\\model_episode_121.pth e 4.10.1\\log_episode_121.csv\n",
      "\n",
      "Episode 122/200, Total Reward: -147.50, Win Rate: 0.53, Wins: 446, Losses: 392, Epsilon: 0.1467, Steps: 36754, Time: 131.61s\n",
      "Ações: Manter=14311, Comprar=11629, Vender=10814\n",
      "Ganhos Totais: 13234.00, Perdas Totais: -13381.50\n",
      "Episode 123/200, Total Reward: 680.25, Win Rate: 0.54, Wins: 461, Losses: 398, Epsilon: 0.1452, Steps: 36754, Time: 131.45s\n",
      "Ações: Manter=12262, Comprar=12468, Vender=12024\n",
      "Ganhos Totais: 11221.75, Perdas Totais: -10541.50\n",
      "Episode 124/200, Total Reward: 1433.00, Win Rate: 0.54, Wins: 458, Losses: 397, Epsilon: 0.1438, Steps: 36754, Time: 131.30s\n",
      "Ações: Manter=13244, Comprar=11150, Vender=12360\n",
      "Ganhos Totais: 11124.75, Perdas Totais: -9691.75\n",
      "Episode 125/200, Total Reward: 1969.50, Win Rate: 0.52, Wins: 432, Losses: 396, Epsilon: 0.1424, Steps: 36754, Time: 131.62s\n",
      "Ações: Manter=13988, Comprar=11557, Vender=11209\n",
      "Ganhos Totais: 12325.50, Perdas Totais: -10356.00\n",
      "Modelo e log do episódio 125 salvos em: 4.10.1\\model_episode_125.pth e 4.10.1\\log_episode_125.csv\n",
      "\n",
      "Episode 126/200, Total Reward: -2201.75, Win Rate: 0.52, Wins: 422, Losses: 392, Epsilon: 0.1409, Steps: 36754, Time: 131.80s\n",
      "Ações: Manter=14462, Comprar=10223, Vender=12069\n",
      "Ganhos Totais: 12036.25, Perdas Totais: -14238.00\n",
      "Episode 127/200, Total Reward: 362.50, Win Rate: 0.54, Wins: 452, Losses: 391, Epsilon: 0.1395, Steps: 36754, Time: 132.58s\n",
      "Ações: Manter=13365, Comprar=13382, Vender=10007\n",
      "Ganhos Totais: 12056.00, Perdas Totais: -11693.50\n",
      "Episode 128/200, Total Reward: -634.50, Win Rate: 0.51, Wins: 390, Losses: 380, Epsilon: 0.1381, Steps: 36754, Time: 131.27s\n",
      "Ações: Manter=13329, Comprar=11949, Vender=11476\n",
      "Ganhos Totais: 12362.75, Perdas Totais: -12997.25\n",
      "Episode 129/200, Total Reward: 1753.75, Win Rate: 0.54, Wins: 445, Losses: 384, Epsilon: 0.1367, Steps: 36754, Time: 131.94s\n",
      "Ações: Manter=12442, Comprar=14468, Vender=9844\n",
      "Ganhos Totais: 12957.00, Perdas Totais: -11203.25\n",
      "Episode 130/200, Total Reward: -1176.75, Win Rate: 0.54, Wins: 442, Losses: 373, Epsilon: 0.1354, Steps: 36754, Time: 131.86s\n",
      "Ações: Manter=14300, Comprar=13268, Vender=9186\n",
      "Ganhos Totais: 13492.75, Perdas Totais: -14669.50\n",
      "Episode 131/200, Total Reward: 1421.50, Win Rate: 0.51, Wins: 399, Losses: 381, Epsilon: 0.1340, Steps: 36754, Time: 131.81s\n",
      "Ações: Manter=14126, Comprar=8952, Vender=13676\n",
      "Ganhos Totais: 13834.75, Perdas Totais: -12413.25\n",
      "Episode 132/200, Total Reward: 1422.25, Win Rate: 0.53, Wins: 422, Losses: 381, Epsilon: 0.1327, Steps: 36754, Time: 131.79s\n",
      "Ações: Manter=14190, Comprar=12483, Vender=10081\n",
      "Ganhos Totais: 12426.00, Perdas Totais: -11003.75\n",
      "Episode 133/200, Total Reward: 492.75, Win Rate: 0.51, Wins: 430, Losses: 405, Epsilon: 0.1314, Steps: 36754, Time: 131.80s\n",
      "Ações: Manter=12088, Comprar=11798, Vender=12868\n",
      "Ganhos Totais: 11786.50, Perdas Totais: -11293.75\n",
      "Episode 134/200, Total Reward: 4357.75, Win Rate: 0.53, Wins: 426, Losses: 375, Epsilon: 0.1300, Steps: 36754, Time: 131.69s\n",
      "Ações: Manter=13346, Comprar=13276, Vender=10132\n",
      "Ganhos Totais: 14859.75, Perdas Totais: -10502.00\n",
      "Modelo e log do episódio 134 salvos em: 4.10.1\\model_episode_134.pth e 4.10.1\\log_episode_134.csv\n",
      "\n",
      "Episode 135/200, Total Reward: 307.75, Win Rate: 0.52, Wins: 431, Losses: 396, Epsilon: 0.1287, Steps: 36754, Time: 131.32s\n",
      "Ações: Manter=13525, Comprar=10376, Vender=12853\n",
      "Ganhos Totais: 11238.00, Perdas Totais: -10930.25\n",
      "Episode 136/200, Total Reward: -916.50, Win Rate: 0.53, Wins: 445, Losses: 389, Epsilon: 0.1275, Steps: 36754, Time: 133.90s\n",
      "Ações: Manter=15059, Comprar=8927, Vender=12768\n",
      "Ganhos Totais: 12335.00, Perdas Totais: -13251.50\n",
      "Episode 137/200, Total Reward: -2153.00, Win Rate: 0.48, Wins: 353, Losses: 381, Epsilon: 0.1262, Steps: 36754, Time: 131.87s\n",
      "Ações: Manter=17854, Comprar=7919, Vender=10981\n",
      "Ganhos Totais: 10671.75, Perdas Totais: -12824.75\n",
      "Episode 138/200, Total Reward: -1757.75, Win Rate: 0.50, Wins: 389, Losses: 382, Epsilon: 0.1249, Steps: 36754, Time: 131.66s\n",
      "Ações: Manter=16354, Comprar=9304, Vender=11096\n",
      "Ganhos Totais: 10677.75, Perdas Totais: -12435.50\n",
      "Episode 139/200, Total Reward: -894.75, Win Rate: 0.53, Wins: 441, Losses: 394, Epsilon: 0.1237, Steps: 36754, Time: 132.06s\n",
      "Ações: Manter=15841, Comprar=10108, Vender=10805\n",
      "Ganhos Totais: 10532.25, Perdas Totais: -11427.00\n",
      "Episode 140/200, Total Reward: 2561.00, Win Rate: 0.54, Wins: 462, Losses: 387, Epsilon: 0.1224, Steps: 36754, Time: 131.93s\n",
      "Ações: Manter=12416, Comprar=14896, Vender=9442\n",
      "Ganhos Totais: 13485.75, Perdas Totais: -10924.75\n",
      "Modelo e log do episódio 140 salvos em: 4.10.1\\model_episode_140.pth e 4.10.1\\log_episode_140.csv\n",
      "\n",
      "Episode 141/200, Total Reward: 121.50, Win Rate: 0.52, Wins: 422, Losses: 397, Epsilon: 0.1212, Steps: 36754, Time: 131.66s\n",
      "Ações: Manter=13948, Comprar=13037, Vender=9769\n",
      "Ganhos Totais: 11379.50, Perdas Totais: -11258.00\n",
      "Episode 142/200, Total Reward: 194.25, Win Rate: 0.50, Wins: 396, Losses: 393, Epsilon: 0.1200, Steps: 36754, Time: 131.66s\n",
      "Ações: Manter=17065, Comprar=9664, Vender=10025\n",
      "Ganhos Totais: 11161.75, Perdas Totais: -10967.50\n",
      "Episode 143/200, Total Reward: 1739.75, Win Rate: 0.55, Wins: 474, Losses: 381, Epsilon: 0.1188, Steps: 36754, Time: 131.93s\n",
      "Ações: Manter=14460, Comprar=9244, Vender=13050\n",
      "Ganhos Totais: 15452.00, Perdas Totais: -13712.25\n",
      "Episode 144/200, Total Reward: 2031.00, Win Rate: 0.52, Wins: 425, Losses: 392, Epsilon: 0.1176, Steps: 36754, Time: 131.78s\n",
      "Ações: Manter=16092, Comprar=9799, Vender=10863\n",
      "Ganhos Totais: 11741.00, Perdas Totais: -9710.00\n",
      "Modelo e log do episódio 144 salvos em: 4.10.1\\model_episode_144.pth e 4.10.1\\log_episode_144.csv\n",
      "\n",
      "Episode 145/200, Total Reward: -1164.25, Win Rate: 0.50, Wins: 393, Losses: 393, Epsilon: 0.1164, Steps: 36754, Time: 131.84s\n",
      "Ações: Manter=15423, Comprar=9601, Vender=11730\n",
      "Ganhos Totais: 12118.50, Perdas Totais: -13282.75\n",
      "Episode 146/200, Total Reward: -775.25, Win Rate: 0.48, Wins: 334, Losses: 366, Epsilon: 0.1153, Steps: 36754, Time: 132.09s\n",
      "Ações: Manter=18606, Comprar=8025, Vender=10123\n",
      "Ganhos Totais: 11412.75, Perdas Totais: -12188.00\n",
      "Episode 147/200, Total Reward: 459.25, Win Rate: 0.50, Wins: 401, Losses: 394, Epsilon: 0.1141, Steps: 36754, Time: 133.23s\n",
      "Ações: Manter=13145, Comprar=13042, Vender=10567\n",
      "Ganhos Totais: 11521.75, Perdas Totais: -11062.50\n",
      "Episode 148/200, Total Reward: 3144.50, Win Rate: 0.55, Wins: 446, Losses: 363, Epsilon: 0.1130, Steps: 36754, Time: 132.09s\n",
      "Ações: Manter=14782, Comprar=11881, Vender=10091\n",
      "Ganhos Totais: 15249.00, Perdas Totais: -12104.50\n",
      "Modelo e log do episódio 148 salvos em: 4.10.1\\model_episode_148.pth e 4.10.1\\log_episode_148.csv\n",
      "\n",
      "Episode 149/200, Total Reward: -2652.25, Win Rate: 0.50, Wins: 371, Losses: 368, Epsilon: 0.1118, Steps: 36754, Time: 132.45s\n",
      "Ações: Manter=16962, Comprar=9878, Vender=9914\n",
      "Ganhos Totais: 11445.75, Perdas Totais: -14098.00\n",
      "Episode 150/200, Total Reward: 698.50, Win Rate: 0.52, Wins: 417, Losses: 380, Epsilon: 0.1107, Steps: 36754, Time: 132.33s\n",
      "Ações: Manter=15101, Comprar=11230, Vender=10423\n",
      "Ganhos Totais: 11543.25, Perdas Totais: -10844.75\n",
      "Episode 151/200, Total Reward: 2277.50, Win Rate: 0.53, Wins: 454, Losses: 398, Epsilon: 0.1096, Steps: 36754, Time: 132.27s\n",
      "Ações: Manter=15043, Comprar=12077, Vender=9634\n",
      "Ganhos Totais: 13029.75, Perdas Totais: -10752.25\n",
      "Modelo e log do episódio 151 salvos em: 4.10.1\\model_episode_151.pth e 4.10.1\\log_episode_151.csv\n",
      "\n",
      "Episode 152/200, Total Reward: 36.25, Win Rate: 0.51, Wins: 397, Losses: 389, Epsilon: 0.1085, Steps: 36754, Time: 132.33s\n",
      "Ações: Manter=14134, Comprar=12350, Vender=10270\n",
      "Ganhos Totais: 10932.00, Perdas Totais: -10895.75\n",
      "Episode 153/200, Total Reward: -669.75, Win Rate: 0.54, Wins: 466, Losses: 392, Epsilon: 0.1074, Steps: 36754, Time: 132.43s\n",
      "Ações: Manter=14366, Comprar=10342, Vender=12046\n",
      "Ganhos Totais: 12186.50, Perdas Totais: -12856.25\n",
      "Episode 154/200, Total Reward: 1321.75, Win Rate: 0.53, Wins: 443, Losses: 387, Epsilon: 0.1064, Steps: 36754, Time: 133.43s\n",
      "Ações: Manter=13350, Comprar=14937, Vender=8467\n",
      "Ganhos Totais: 14013.75, Perdas Totais: -12692.00\n",
      "Episode 155/200, Total Reward: 340.00, Win Rate: 0.52, Wins: 418, Losses: 390, Epsilon: 0.1053, Steps: 36754, Time: 132.84s\n",
      "Ações: Manter=14448, Comprar=11378, Vender=10928\n",
      "Ganhos Totais: 12700.50, Perdas Totais: -12360.50\n",
      "Episode 156/200, Total Reward: 1199.50, Win Rate: 0.55, Wins: 471, Losses: 383, Epsilon: 0.1042, Steps: 36754, Time: 132.56s\n",
      "Ações: Manter=13426, Comprar=10910, Vender=12418\n",
      "Ganhos Totais: 13016.50, Perdas Totais: -11817.00\n",
      "Episode 157/200, Total Reward: 1648.75, Win Rate: 0.52, Wins: 414, Losses: 382, Epsilon: 0.1032, Steps: 36754, Time: 132.17s\n",
      "Ações: Manter=18198, Comprar=9651, Vender=8905\n",
      "Ganhos Totais: 13113.75, Perdas Totais: -11465.00\n",
      "Episode 158/200, Total Reward: -1709.25, Win Rate: 0.53, Wins: 417, Losses: 373, Epsilon: 0.1022, Steps: 36754, Time: 132.36s\n",
      "Ações: Manter=15633, Comprar=9765, Vender=11356\n",
      "Ganhos Totais: 11512.25, Perdas Totais: -13221.50\n",
      "Episode 159/200, Total Reward: 1439.50, Win Rate: 0.55, Wins: 480, Losses: 396, Epsilon: 0.1012, Steps: 36754, Time: 132.20s\n",
      "Ações: Manter=13741, Comprar=10573, Vender=12440\n",
      "Ganhos Totais: 12749.00, Perdas Totais: -11309.50\n",
      "Episode 160/200, Total Reward: 1764.50, Win Rate: 0.54, Wins: 450, Losses: 379, Epsilon: 0.1001, Steps: 36754, Time: 132.33s\n",
      "Ações: Manter=14812, Comprar=9782, Vender=12160\n",
      "Ganhos Totais: 13248.25, Perdas Totais: -11483.75\n",
      "Episode 161/200, Total Reward: 1280.25, Win Rate: 0.54, Wins: 453, Losses: 381, Epsilon: 0.0991, Steps: 36754, Time: 134.05s\n",
      "Ações: Manter=13673, Comprar=7490, Vender=15591\n",
      "Ganhos Totais: 14323.25, Perdas Totais: -13043.00\n",
      "Episode 162/200, Total Reward: -2086.00, Win Rate: 0.51, Wins: 406, Losses: 392, Epsilon: 0.0981, Steps: 36754, Time: 131.65s\n",
      "Ações: Manter=16238, Comprar=8731, Vender=11785\n",
      "Ganhos Totais: 11230.50, Perdas Totais: -13316.50\n",
      "Episode 163/200, Total Reward: -2092.50, Win Rate: 0.50, Wins: 384, Losses: 378, Epsilon: 0.0972, Steps: 36754, Time: 134.18s\n",
      "Ações: Manter=17209, Comprar=8326, Vender=11219\n",
      "Ganhos Totais: 11531.25, Perdas Totais: -13623.75\n",
      "Episode 164/200, Total Reward: 3919.25, Win Rate: 0.57, Wins: 500, Losses: 381, Epsilon: 0.0962, Steps: 36754, Time: 131.82s\n",
      "Ações: Manter=12086, Comprar=11656, Vender=13012\n",
      "Ganhos Totais: 15610.50, Perdas Totais: -11691.25\n",
      "Modelo e log do episódio 164 salvos em: 4.10.1\\model_episode_164.pth e 4.10.1\\log_episode_164.csv\n",
      "\n",
      "Episode 165/200, Total Reward: 1296.50, Win Rate: 0.52, Wins: 400, Losses: 371, Epsilon: 0.0952, Steps: 36754, Time: 131.81s\n",
      "Ações: Manter=15322, Comprar=8723, Vender=12709\n",
      "Ganhos Totais: 13247.25, Perdas Totais: -11950.75\n",
      "Episode 166/200, Total Reward: 810.75, Win Rate: 0.54, Wins: 438, Losses: 371, Epsilon: 0.0943, Steps: 36754, Time: 132.03s\n",
      "Ações: Manter=14003, Comprar=8999, Vender=13752\n",
      "Ganhos Totais: 13837.75, Perdas Totais: -13027.00\n",
      "Episode 167/200, Total Reward: 292.00, Win Rate: 0.51, Wins: 376, Losses: 367, Epsilon: 0.0933, Steps: 36754, Time: 131.65s\n",
      "Ações: Manter=14974, Comprar=10808, Vender=10972\n",
      "Ganhos Totais: 13111.25, Perdas Totais: -12819.25\n",
      "Episode 168/200, Total Reward: -25.75, Win Rate: 0.52, Wins: 433, Losses: 397, Epsilon: 0.0924, Steps: 36754, Time: 131.72s\n",
      "Ações: Manter=14569, Comprar=9762, Vender=12423\n",
      "Ganhos Totais: 10449.25, Perdas Totais: -10475.00\n",
      "Episode 169/200, Total Reward: 1579.75, Win Rate: 0.53, Wins: 457, Losses: 405, Epsilon: 0.0915, Steps: 36754, Time: 131.57s\n",
      "Ações: Manter=16300, Comprar=10318, Vender=10136\n",
      "Ganhos Totais: 12524.50, Perdas Totais: -10944.75\n",
      "Episode 170/200, Total Reward: -1894.50, Win Rate: 0.53, Wins: 423, Losses: 382, Epsilon: 0.0906, Steps: 36754, Time: 131.63s\n",
      "Ações: Manter=17334, Comprar=9579, Vender=9841\n",
      "Ganhos Totais: 11311.25, Perdas Totais: -13205.75\n",
      "Episode 171/200, Total Reward: 1669.50, Win Rate: 0.53, Wins: 432, Losses: 382, Epsilon: 0.0897, Steps: 36754, Time: 131.86s\n",
      "Ações: Manter=16108, Comprar=11836, Vender=8810\n",
      "Ganhos Totais: 12470.75, Perdas Totais: -10801.25\n",
      "Episode 172/200, Total Reward: 1626.50, Win Rate: 0.56, Wins: 474, Losses: 379, Epsilon: 0.0888, Steps: 36754, Time: 132.04s\n",
      "Ações: Manter=12904, Comprar=12075, Vender=11775\n",
      "Ganhos Totais: 13766.50, Perdas Totais: -12140.00\n",
      "Episode 173/200, Total Reward: 1235.50, Win Rate: 0.55, Wins: 483, Losses: 395, Epsilon: 0.0879, Steps: 36754, Time: 131.85s\n",
      "Ações: Manter=13648, Comprar=11473, Vender=11633\n",
      "Ganhos Totais: 12805.00, Perdas Totais: -11569.50\n",
      "Episode 174/200, Total Reward: 3138.50, Win Rate: 0.54, Wins: 444, Losses: 373, Epsilon: 0.0870, Steps: 36754, Time: 131.87s\n",
      "Ações: Manter=16361, Comprar=11278, Vender=9115\n",
      "Ganhos Totais: 16273.75, Perdas Totais: -13135.25\n",
      "Modelo e log do episódio 174 salvos em: 4.10.1\\model_episode_174.pth e 4.10.1\\log_episode_174.csv\n",
      "\n",
      "Episode 175/200, Total Reward: 1465.25, Win Rate: 0.56, Wins: 503, Losses: 390, Epsilon: 0.0861, Steps: 36754, Time: 131.43s\n",
      "Ações: Manter=14784, Comprar=10783, Vender=11187\n",
      "Ganhos Totais: 13005.75, Perdas Totais: -11540.50\n",
      "Episode 176/200, Total Reward: 1428.00, Win Rate: 0.54, Wins: 432, Losses: 363, Epsilon: 0.0853, Steps: 36754, Time: 131.66s\n",
      "Ações: Manter=15677, Comprar=13113, Vender=7964\n",
      "Ganhos Totais: 15327.25, Perdas Totais: -13899.25\n",
      "Episode 177/200, Total Reward: 1925.75, Win Rate: 0.54, Wins: 446, Losses: 374, Epsilon: 0.0844, Steps: 36754, Time: 132.19s\n",
      "Ações: Manter=15542, Comprar=9361, Vender=11851\n",
      "Ganhos Totais: 13600.25, Perdas Totais: -11674.50\n",
      "Episode 178/200, Total Reward: 1477.25, Win Rate: 0.52, Wins: 423, Losses: 393, Epsilon: 0.0836, Steps: 36754, Time: 131.88s\n",
      "Ações: Manter=13513, Comprar=11348, Vender=11893\n",
      "Ganhos Totais: 12745.75, Perdas Totais: -11268.50\n",
      "Episode 179/200, Total Reward: 716.75, Win Rate: 0.52, Wins: 415, Losses: 376, Epsilon: 0.0827, Steps: 36754, Time: 132.22s\n",
      "Ações: Manter=16180, Comprar=9305, Vender=11269\n",
      "Ganhos Totais: 14075.25, Perdas Totais: -13358.50\n",
      "Episode 180/200, Total Reward: 1308.25, Win Rate: 0.54, Wins: 453, Losses: 387, Epsilon: 0.0819, Steps: 36754, Time: 132.24s\n",
      "Ações: Manter=17378, Comprar=8583, Vender=10793\n",
      "Ganhos Totais: 13953.00, Perdas Totais: -12644.75\n",
      "Episode 181/200, Total Reward: 946.50, Win Rate: 0.53, Wins: 433, Losses: 387, Epsilon: 0.0811, Steps: 36754, Time: 133.57s\n",
      "Ações: Manter=13609, Comprar=10797, Vender=12348\n",
      "Ganhos Totais: 13709.75, Perdas Totais: -12763.25\n",
      "Episode 182/200, Total Reward: -821.25, Win Rate: 0.52, Wins: 424, Losses: 387, Epsilon: 0.0803, Steps: 36754, Time: 132.39s\n",
      "Ações: Manter=16728, Comprar=10248, Vender=9778\n",
      "Ganhos Totais: 13741.25, Perdas Totais: -14562.50\n",
      "Episode 183/200, Total Reward: 826.50, Win Rate: 0.51, Wins: 391, Losses: 381, Epsilon: 0.0795, Steps: 36754, Time: 132.25s\n",
      "Ações: Manter=18007, Comprar=9263, Vender=9484\n",
      "Ganhos Totais: 13357.50, Perdas Totais: -12531.00\n",
      "Episode 184/200, Total Reward: -1581.00, Win Rate: 0.51, Wins: 401, Losses: 379, Epsilon: 0.0787, Steps: 36754, Time: 132.50s\n",
      "Ações: Manter=17262, Comprar=8751, Vender=10741\n",
      "Ganhos Totais: 11518.50, Perdas Totais: -13099.50\n",
      "Episode 185/200, Total Reward: 632.00, Win Rate: 0.57, Wins: 497, Losses: 374, Epsilon: 0.0779, Steps: 36754, Time: 132.65s\n",
      "Ações: Manter=17756, Comprar=7281, Vender=11717\n",
      "Ganhos Totais: 14675.50, Perdas Totais: -14043.50\n",
      "Episode 186/200, Total Reward: -426.00, Win Rate: 0.53, Wins: 441, Losses: 397, Epsilon: 0.0771, Steps: 36754, Time: 132.42s\n",
      "Ações: Manter=16742, Comprar=9947, Vender=10065\n",
      "Ganhos Totais: 11838.25, Perdas Totais: -12264.25\n",
      "Episode 187/200, Total Reward: 1796.50, Win Rate: 0.55, Wins: 449, Losses: 373, Epsilon: 0.0763, Steps: 36754, Time: 132.51s\n",
      "Ações: Manter=14200, Comprar=12684, Vender=9870\n",
      "Ganhos Totais: 15920.00, Perdas Totais: -14123.50\n",
      "Episode 188/200, Total Reward: 627.25, Win Rate: 0.54, Wins: 462, Losses: 389, Epsilon: 0.0756, Steps: 36754, Time: 132.34s\n",
      "Ações: Manter=16284, Comprar=11175, Vender=9295\n",
      "Ganhos Totais: 13856.00, Perdas Totais: -13228.75\n",
      "Episode 189/200, Total Reward: 1758.75, Win Rate: 0.53, Wins: 435, Losses: 389, Epsilon: 0.0748, Steps: 36754, Time: 132.42s\n",
      "Ações: Manter=14138, Comprar=11919, Vender=10697\n",
      "Ganhos Totais: 13187.75, Perdas Totais: -11429.00\n",
      "Episode 190/200, Total Reward: -1640.25, Win Rate: 0.50, Wins: 387, Losses: 390, Epsilon: 0.0741, Steps: 36754, Time: 132.53s\n",
      "Ações: Manter=17615, Comprar=10336, Vender=8803\n",
      "Ganhos Totais: 10696.00, Perdas Totais: -12336.25\n",
      "Episode 191/200, Total Reward: 1745.25, Win Rate: 0.53, Wins: 455, Losses: 402, Epsilon: 0.0733, Steps: 36754, Time: 132.62s\n",
      "Ações: Manter=14923, Comprar=9866, Vender=11965\n",
      "Ganhos Totais: 11734.25, Perdas Totais: -9989.00\n",
      "Episode 192/200, Total Reward: 366.00, Win Rate: 0.52, Wins: 415, Losses: 388, Epsilon: 0.0726, Steps: 36754, Time: 132.21s\n",
      "Ações: Manter=17718, Comprar=10657, Vender=8379\n",
      "Ganhos Totais: 11462.25, Perdas Totais: -11096.25\n",
      "Episode 193/200, Total Reward: 574.75, Win Rate: 0.52, Wins: 407, Losses: 374, Epsilon: 0.0719, Steps: 36754, Time: 132.43s\n",
      "Ações: Manter=17429, Comprar=10437, Vender=8888\n",
      "Ganhos Totais: 13375.25, Perdas Totais: -12800.50\n",
      "Episode 194/200, Total Reward: 2756.25, Win Rate: 0.53, Wins: 436, Losses: 388, Epsilon: 0.0712, Steps: 36754, Time: 132.20s\n",
      "Ações: Manter=14793, Comprar=11154, Vender=10807\n",
      "Ganhos Totais: 12650.50, Perdas Totais: -9894.25\n",
      "Modelo e log do episódio 194 salvos em: 4.10.1\\model_episode_194.pth e 4.10.1\\log_episode_194.csv\n",
      "\n",
      "Episode 195/200, Total Reward: 3928.75, Win Rate: 0.53, Wins: 431, Losses: 378, Epsilon: 0.0704, Steps: 36754, Time: 132.34s\n",
      "Ações: Manter=15775, Comprar=9786, Vender=11193\n",
      "Ganhos Totais: 13125.75, Perdas Totais: -9197.00\n",
      "Modelo e log do episódio 195 salvos em: 4.10.1\\model_episode_195.pth e 4.10.1\\log_episode_195.csv\n",
      "\n",
      "Episode 196/200, Total Reward: -167.25, Win Rate: 0.51, Wins: 386, Losses: 377, Epsilon: 0.0697, Steps: 36754, Time: 132.98s\n",
      "Ações: Manter=14871, Comprar=11597, Vender=10286\n",
      "Ganhos Totais: 13932.00, Perdas Totais: -14099.25\n",
      "Episode 197/200, Total Reward: 735.25, Win Rate: 0.50, Wins: 389, Losses: 388, Epsilon: 0.0690, Steps: 36754, Time: 132.44s\n",
      "Ações: Manter=13717, Comprar=10770, Vender=12267\n",
      "Ganhos Totais: 10900.25, Perdas Totais: -10165.00\n",
      "Episode 198/200, Total Reward: 651.25, Win Rate: 0.50, Wins: 412, Losses: 407, Epsilon: 0.0684, Steps: 36754, Time: 132.42s\n",
      "Ações: Manter=13751, Comprar=10327, Vender=12676\n",
      "Ganhos Totais: 11445.75, Perdas Totais: -10794.50\n",
      "Episode 199/200, Total Reward: 637.75, Win Rate: 0.55, Wins: 454, Losses: 373, Epsilon: 0.0677, Steps: 36754, Time: 132.32s\n",
      "Ações: Manter=14263, Comprar=11801, Vender=10690\n",
      "Ganhos Totais: 14816.75, Perdas Totais: -14179.00\n",
      "Episode 200/200, Total Reward: 1268.25, Win Rate: 0.51, Wins: 416, Losses: 396, Epsilon: 0.0670, Steps: 36754, Time: 132.41s\n",
      "Ações: Manter=15540, Comprar=10598, Vender=10616\n",
      "Ganhos Totais: 12607.25, Perdas Totais: -11339.00\n",
      "\n",
      "Treinamento finalizado.\n",
      "Top 10 Melhores Episódios:\n",
      "Rank 1: Episode 134, Total Reward: 4357.75, Win Rate: 0.53, Wins: 426, Losses: 375, Ações: {0: 13346, 1: 13276, 2: 10132}, Steps: 36754, Time: 131.69s\n",
      "Rank 2: Episode 195, Total Reward: 3928.75, Win Rate: 0.53, Wins: 431, Losses: 378, Ações: {0: 15775, 1: 9786, 2: 11193}, Steps: 36754, Time: 132.34s\n",
      "Rank 3: Episode 164, Total Reward: 3919.25, Win Rate: 0.57, Wins: 500, Losses: 381, Ações: {0: 12086, 1: 11656, 2: 13012}, Steps: 36754, Time: 131.82s\n",
      "Rank 4: Episode 82, Total Reward: 3291.00, Win Rate: 0.54, Wins: 465, Losses: 396, Ações: {0: 11661, 1: 10711, 2: 14382}, Steps: 36754, Time: 137.73s\n",
      "Rank 5: Episode 148, Total Reward: 3144.50, Win Rate: 0.55, Wins: 446, Losses: 363, Ações: {0: 14782, 1: 11881, 2: 10091}, Steps: 36754, Time: 132.09s\n",
      "Rank 6: Episode 174, Total Reward: 3138.50, Win Rate: 0.54, Wins: 444, Losses: 373, Ações: {0: 16361, 1: 11278, 2: 9115}, Steps: 36754, Time: 131.87s\n",
      "Rank 7: Episode 115, Total Reward: 2840.75, Win Rate: 0.53, Wins: 452, Losses: 399, Ações: {0: 12905, 1: 12585, 2: 11264}, Steps: 36754, Time: 131.14s\n",
      "Rank 8: Episode 194, Total Reward: 2756.25, Win Rate: 0.53, Wins: 436, Losses: 388, Ações: {0: 14793, 1: 11154, 2: 10807}, Steps: 36754, Time: 132.20s\n",
      "Rank 9: Episode 66, Total Reward: 2672.00, Win Rate: 0.54, Wins: 476, Losses: 410, Ações: {0: 12327, 1: 13114, 2: 11313}, Steps: 36754, Time: 150.15s\n",
      "Rank 10: Episode 140, Total Reward: 2561.00, Win Rate: 0.54, Wins: 462, Losses: 387, Ações: {0: 12416, 1: 14896, 2: 9442}, Steps: 36754, Time: 131.93s\n"
     ]
    }
   ],
   "source": [
    "# Bloco 1: Preparar os Dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import os\n",
    "data = pd.read_csv('D:\\\\dados\\\\bar_M15_V03_data_01-01-2023_a_31-08-2024.csv')\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "# filtra o dataframe para pegar apenas o mês de 08 de 2024\n",
    "#data = data[(data['DateTime'] >= '2024-08-01') & (data['DateTime'] <= '2024-08-31')]\n",
    "\n",
    "# Criar a coluna \"Valor\", que é uma cópia de \"Close\" e não será normalizada\n",
    "data['Valor'] = data['Close']\n",
    "\n",
    "# Normalizar as colunas necessárias (exceto \"Valor\" e \"Gatilho\")\n",
    "scaler = MinMaxScaler()\n",
    "cols_to_normalize = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'PavioSuperior', 'PavioInferior',\n",
    "    'Corpo', 'Range','SMA4','SMA8','SMA12','SMA20', 'SMA50', 'SMA100', 'SMA200', 'StochasticoK',\n",
    "    'StochasticoD', 'RSI', 'MACD', 'MACDSignal', 'MACDHistogram','atr8','atr14','atr28','dayO','dayH','dayL'\n",
    "]\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "# Converter todos os valores para tipo float32 para evitar problemas de tipo\n",
    "data = data.astype({col: 'float32' for col in cols_to_normalize + ['Valor']})\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.current_step = 0\n",
    "        self.position = 0  # 0 = neutro, 1 = comprado, -1 = vendido\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None\n",
    "        self.entry_datetime = None  # Novo atributo para armazenar o DateTime de entrada\n",
    "        self.action_space = spaces.Discrete(3)  # 0 = Manter, 1 = Comprar, 2 = Vender\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(len(data.columns) - 3 + 1,), dtype=np.float32\n",
    "        )\n",
    "        self.trades = []  # Lista para armazenar as operações realizadas\n",
    "        self.operation_limit = 0  # Variável de controle para limitar operações após perda\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None\n",
    "        self.entry_datetime = None\n",
    "        self.trades = []\n",
    "        self.operation_limit = 0  # Resetar a limitação de operações ao resetar o ambiente\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = self.data.iloc[self.current_step].drop(['Valor', 'DateTime', 'Gatilho']).values\n",
    "        obs = np.append(obs, self.position)  # Incluir a posição atual na observação\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        done = self.current_step >= len(self.data) - 2  # Ajustado para evitar índice fora do intervalo\n",
    "        reward = 0\n",
    "        info = {}\n",
    "\n",
    "        # Obter o valor atual e o próximo valor\n",
    "        current_price = self.data['Valor'].iloc[self.current_step]\n",
    "        next_price = self.data['Valor'].iloc[self.current_step + 1]\n",
    "        price_change = next_price - current_price\n",
    "\n",
    "        # Obter o valor do gatilho no passo atual\n",
    "        gatilho = int(self.data['Gatilho'].iloc[self.current_step])\n",
    "\n",
    "        # Se o gatilho estiver ativo e o agente não estiver limitado por perda anterior\n",
    "        if gatilho == 1 and self.operation_limit == 0:\n",
    "            if action == 1:  # Comprar\n",
    "                if self.position == 0:\n",
    "                    self.position = 1  # Abrir posição comprada\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step\n",
    "                    self.entry_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime\n",
    "                    }\n",
    "                elif self.position == -1:\n",
    "                    # Fechar posição vendida\n",
    "                    self.exit_price = current_price\n",
    "                    profit = self.entry_price - self.exit_price - 0.25  # Ganho da posição vendida\n",
    "                    self.exit_step = self.current_step\n",
    "                    self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward += profit\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_short',\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime,\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    })\n",
    "                    # Resetar posição\n",
    "                    self.position = 0\n",
    "                    self.entry_step = None\n",
    "                    self.entry_datetime = None\n",
    "\n",
    "                    # Atualizar operation_limit caso a operação tenha dado prejuízo\n",
    "                    if profit < 0:\n",
    "                        self.operation_limit = 1\n",
    "\n",
    "            elif action == 2:  # Vender\n",
    "                if self.position == 0:\n",
    "                    self.position = -1  # Abrir posição vendida\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step\n",
    "                    self.entry_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime\n",
    "                    }\n",
    "                elif self.position == 1:\n",
    "                    # Fechar posição comprada\n",
    "                    self.exit_price = current_price\n",
    "                    profit = self.exit_price - self.entry_price - 0.25  # Ganho da posição comprada\n",
    "                    self.exit_step = self.current_step\n",
    "                    self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward += profit\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_long',\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime,\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    })\n",
    "                    # Resetar posição\n",
    "                    self.position = 0\n",
    "                    self.entry_step = None\n",
    "                    self.entry_datetime = None\n",
    "\n",
    "                    # Atualizar operation_limit caso a operação tenha dado prejuízo\n",
    "                    if profit < 0:\n",
    "                        self.operation_limit = 1\n",
    "        elif gatilho == 0:\n",
    "            # Quando o gatilho for zero, liberar a operação novamente\n",
    "            self.operation_limit = 0\n",
    "\n",
    "            # Fechar qualquer posição aberta\n",
    "            if self.position == 1:  # Fechar posição comprada\n",
    "                self.exit_price = current_price\n",
    "                profit = self.exit_price - self.entry_price - 0.25\n",
    "                self.exit_step = self.current_step\n",
    "                self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                reward += profit\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_long',\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                }\n",
    "                self.trades.append({\n",
    "                    'type': 'buy',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'entry_datetime': self.entry_datetime,\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                })\n",
    "                self.position = 0\n",
    "                self.entry_step = None\n",
    "                self.entry_datetime = None\n",
    "            elif self.position == -1:  # Fechar posição vendida\n",
    "                self.exit_price = current_price\n",
    "                profit = self.entry_price - self.exit_price - 0.25\n",
    "                self.exit_step = self.current_step\n",
    "                self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                reward += profit\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_short',\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                }\n",
    "                self.trades.append({\n",
    "                    'type': 'sell',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'entry_datetime': self.entry_datetime,\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                })\n",
    "                self.position = 0\n",
    "                self.entry_step = None\n",
    "                self.entry_datetime = None\n",
    "\n",
    "        # Atualizar o passo atual\n",
    "        self.current_step += 1\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        return obs, reward, done, info\n",
    "\n",
    "\n",
    "# Bloco 3: Criar o Agente DQN usando PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import random\n",
    "\n",
    "# Configurações do dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Criar o ambiente\n",
    "env = TradingEnv(data)\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Definir a rede DQN\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, obs_size, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(obs_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instanciar a rede\n",
    "q_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "# Definir o otimizador\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Hiperparâmetros para DQN\n",
    "memory_size = 10000\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "epsilon_start = 0.5\n",
    "epsilon_end = 0.05\n",
    "epsilon_decay = 0.99\n",
    "target_update = 10  # Atualizar a rede alvo a cada 10 episódios\n",
    "\n",
    "# Inicializar a memória de replay\n",
    "memory = collections.deque(maxlen=memory_size)\n",
    "\n",
    "# Função para selecionar ação usando epsilon-greedy\n",
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice([0, 1, 2])\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = q_net(state)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "# Bloco 4: Treinamento do Agente DQN com Salvamento dos Melhores Episódios Após Cada Episódio\n",
    "\n",
    "num_episodes = 200  # Defina o número de episódios de treinamento\n",
    "epsilon = epsilon_start\n",
    "best_episodes = []\n",
    "\n",
    "save_dir = \"4.10.1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    start_time = time.time()\n",
    "    obs = env.reset()\n",
    "    obs = torch.FloatTensor(obs).unsqueeze(0).to(device)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    actions_count = {0: 0, 1: 0, 2: 0}\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    win_total = 0\n",
    "    lose_total = 0\n",
    "    trades = []\n",
    "    current_trade = None\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "\n",
    "        # Selecionar ação\n",
    "        action = select_action(obs, epsilon)\n",
    "\n",
    "        # Executar ação no ambiente\n",
    "        obs_next, reward, done, info = env.step(action)\n",
    "        obs_next = torch.FloatTensor(obs_next).unsqueeze(0).to(device)\n",
    "\n",
    "        # Armazenar na memória de replay\n",
    "        memory.append((obs, action, reward, obs_next, done))\n",
    "\n",
    "        # Atualizar o estado\n",
    "        obs = obs_next\n",
    "\n",
    "        # Atualizar contagem de ações\n",
    "        actions_count[action] += 1\n",
    "\n",
    "        # Processar informações de trade\n",
    "        if 'trade' in info:\n",
    "            trade_info = info['trade']\n",
    "            if trade_info['type'] in ['buy', 'sell']:\n",
    "                # Início de uma nova operação\n",
    "                current_trade = {\n",
    "                    'type': trade_info['type'],\n",
    "                    'entry_step': trade_info['entry_step'],\n",
    "                    'entry_price': trade_info['entry_price'],\n",
    "                    'entry_datetime': trade_info['entry_datetime'],\n",
    "                    'exit_step': None,\n",
    "                    'exit_price': None,\n",
    "                    'exit_datetime': None,\n",
    "                    'profit': None\n",
    "                }\n",
    "            elif trade_info['type'] in ['close_long', 'close_short']:\n",
    "                # Fechamento de uma operação existente\n",
    "                current_trade['exit_step'] = trade_info['exit_step']\n",
    "                current_trade['exit_price'] = trade_info['exit_price']\n",
    "                current_trade['exit_datetime'] = trade_info['exit_datetime']\n",
    "                current_trade['profit'] = trade_info['profit']\n",
    "                trades.append(current_trade.copy())\n",
    "                # Atualizar ganhos e perdas\n",
    "                if current_trade['profit'] > 0:\n",
    "                    wins += 1\n",
    "                    win_total += current_trade['profit']\n",
    "                elif current_trade['profit'] < 0:\n",
    "                    losses += 1\n",
    "                    lose_total += current_trade['profit']\n",
    "                # Atualizar recompensa total\n",
    "                total_reward += current_trade['profit']\n",
    "                current_trade = None\n",
    "\n",
    "        # Treinar a rede se a memória tiver tamanho suficiente\n",
    "        if len(memory) >= batch_size:\n",
    "            batch = random.sample(memory, batch_size)\n",
    "            states, actions_batch, rewards_batch, next_states, dones = zip(*batch)\n",
    "\n",
    "            states = torch.cat(states).to(device)\n",
    "            actions_batch = torch.tensor(actions_batch, dtype=torch.long, device=device).unsqueeze(1)\n",
    "            rewards_batch = torch.tensor(rewards_batch, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            next_states = torch.cat(next_states).to(device)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            # Computar Q-valor atual\n",
    "            q_values = q_net(states).gather(1, actions_batch)\n",
    "\n",
    "            # Computar Q-valor alvo usando a rede alvo\n",
    "            with torch.no_grad():\n",
    "                next_q_values = target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "            target_q_values = rewards_batch + gamma * next_q_values * (1 - dones)\n",
    "\n",
    "            # Calcular a perda\n",
    "            loss = nn.MSELoss()(q_values, target_q_values)\n",
    "\n",
    "            # Otimizar a rede\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Decaimento de epsilon\n",
    "    epsilon = max(epsilon_end, epsilon_decay * epsilon)\n",
    "\n",
    "    # Atualizar a rede alvo\n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    # Cálculo do tempo de treinamento do episódio\n",
    "    end_time = time.time()\n",
    "    episode_time = end_time - start_time\n",
    "\n",
    "    win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "    print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward:.2f}, Win Rate: {win_rate:.2f}, \"\n",
    "          f\"Wins: {wins}, Losses: {losses}, Epsilon: {epsilon:.4f}, Steps: {steps}, Time: {episode_time:.2f}s\")\n",
    "    print(f\"Ações: Manter={actions_count[0]}, Comprar={actions_count[1]}, Vender={actions_count[2]}\")\n",
    "    print(f\"Ganhos Totais: {win_total:.2f}, Perdas Totais: {lose_total:.2f}\")\n",
    "\n",
    "    # Salvar informações do episódio\n",
    "    episode_info = {\n",
    "        'episode': episode + 1,\n",
    "        'total_reward': total_reward,\n",
    "        'win_rate': win_rate,\n",
    "        'wins': wins,\n",
    "        'losses': losses,\n",
    "        'actions_count': actions_count.copy(),\n",
    "        'win_total': win_total,\n",
    "        'lose_total': lose_total,\n",
    "        'steps': steps,\n",
    "        'episode_time': episode_time,\n",
    "        'model_state_dict': q_net.state_dict(),\n",
    "        'trades': trades.copy()  # Salvar as operações do episódio\n",
    "    }\n",
    "\n",
    "    # Adicionar o episódio à lista e manter os top 10\n",
    "    best_episodes.append(episode_info)\n",
    "    best_episodes = sorted(best_episodes, key=lambda x: x['total_reward'], reverse=True)[:10]\n",
    "\n",
    "    # Salvar o modelo e log se o episódio for um dos top 10\n",
    "    if episode_info in best_episodes:\n",
    "        model_path = os.path.join(save_dir, f\"model_episode_{episode_info['episode']}.pth\")\n",
    "        torch.save(episode_info['model_state_dict'], model_path)\n",
    "        episode_info['model_path'] = model_path\n",
    "\n",
    "        # Salvar o log completo das operações\n",
    "        log_path = os.path.join(save_dir, f\"log_episode_{episode_info['episode']}.csv\")\n",
    "        trades_df = pd.DataFrame(episode_info['trades'])\n",
    "        trades_df.to_csv(log_path, index=False)\n",
    "        episode_info['log_path'] = log_path\n",
    "\n",
    "        print(f\"Modelo e log do episódio {episode_info['episode']} salvos em: {model_path} e {log_path}\\n\")\n",
    "\n",
    "print(\"\\nTreinamento finalizado.\")\n",
    "print(\"Top 10 Melhores Episódios:\")\n",
    "for idx, ep in enumerate(best_episodes, 1):\n",
    "    print(f\"Rank {idx}: Episode {ep['episode']}, Total Reward: {ep['total_reward']:.2f}, \"\n",
    "          f\"Win Rate: {ep['win_rate']:.2f}, Wins: {ep['wins']}, Losses: {ep['losses']}, \"\n",
    "          f\"Ações: {ep['actions_count']}, Steps: {ep['steps']}, Time: {ep['episode_time']:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
