{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/200, Total Reward: -254579.75, Win Rate: 0.50, Wins: 1048, Losses: 1057, Epsilon: 0.4950, Steps: 36754, Time: 121.33s\n",
      "Ações: Manter=14403, Comprar=11631, Vender=10720\n",
      "Ganhos Totais: 33063.75, Perdas Totais: -287643.50\n",
      "Modelo e log do episódio 1 salvos em: 4.11\\model_episode_1.pth e 4.11\\log_episode_1.csv\n",
      "\n",
      "Episode 2/200, Total Reward: -236600.25, Win Rate: 0.52, Wins: 1051, Losses: 970, Epsilon: 0.4900, Steps: 36754, Time: 125.62s\n",
      "Ações: Manter=12268, Comprar=13411, Vender=11075\n",
      "Ganhos Totais: 33711.75, Perdas Totais: -270312.00\n",
      "Modelo e log do episódio 2 salvos em: 4.11\\model_episode_2.pth e 4.11\\log_episode_2.csv\n",
      "\n",
      "Episode 3/200, Total Reward: -262276.50, Win Rate: 0.50, Wins: 959, Losses: 972, Epsilon: 0.4851, Steps: 36754, Time: 120.93s\n",
      "Ações: Manter=12461, Comprar=13006, Vender=11287\n",
      "Ganhos Totais: 30289.25, Perdas Totais: -292565.75\n",
      "Modelo e log do episódio 3 salvos em: 4.11\\model_episode_3.pth e 4.11\\log_episode_3.csv\n",
      "\n",
      "Episode 4/200, Total Reward: -245813.00, Win Rate: 0.49, Wins: 928, Losses: 965, Epsilon: 0.4803, Steps: 36754, Time: 118.67s\n",
      "Ações: Manter=12423, Comprar=13134, Vender=11197\n",
      "Ganhos Totais: 30006.25, Perdas Totais: -275819.25\n",
      "Modelo e log do episódio 4 salvos em: 4.11\\model_episode_4.pth e 4.11\\log_episode_4.csv\n",
      "\n",
      "Episode 5/200, Total Reward: -247557.75, Win Rate: 0.49, Wins: 929, Losses: 980, Epsilon: 0.4755, Steps: 36754, Time: 119.75s\n",
      "Ações: Manter=12721, Comprar=12530, Vender=11503\n",
      "Ganhos Totais: 30388.00, Perdas Totais: -277945.75\n",
      "Modelo e log do episódio 5 salvos em: 4.11\\model_episode_5.pth e 4.11\\log_episode_5.csv\n",
      "\n",
      "Episode 6/200, Total Reward: -235730.75, Win Rate: 0.49, Wins: 911, Losses: 931, Epsilon: 0.4707, Steps: 36754, Time: 119.36s\n",
      "Ações: Manter=12885, Comprar=12579, Vender=11290\n",
      "Ganhos Totais: 31658.75, Perdas Totais: -267389.50\n",
      "Modelo e log do episódio 6 salvos em: 4.11\\model_episode_6.pth e 4.11\\log_episode_6.csv\n",
      "\n",
      "Episode 7/200, Total Reward: -241473.25, Win Rate: 0.50, Wins: 938, Losses: 938, Epsilon: 0.4660, Steps: 36754, Time: 122.20s\n",
      "Ações: Manter=12433, Comprar=12637, Vender=11684\n",
      "Ganhos Totais: 31377.75, Perdas Totais: -272851.00\n",
      "Modelo e log do episódio 7 salvos em: 4.11\\model_episode_7.pth e 4.11\\log_episode_7.csv\n",
      "\n",
      "Episode 8/200, Total Reward: -247420.25, Win Rate: 0.50, Wins: 926, Losses: 922, Epsilon: 0.4614, Steps: 36754, Time: 116.34s\n",
      "Ações: Manter=12283, Comprar=13075, Vender=11396\n",
      "Ganhos Totais: 33181.50, Perdas Totais: -280601.75\n",
      "Modelo e log do episódio 8 salvos em: 4.11\\model_episode_8.pth e 4.11\\log_episode_8.csv\n",
      "\n",
      "Episode 9/200, Total Reward: -251245.50, Win Rate: 0.50, Wins: 921, Losses: 929, Epsilon: 0.4568, Steps: 36754, Time: 119.04s\n",
      "Ações: Manter=12371, Comprar=12611, Vender=11772\n",
      "Ganhos Totais: 32006.00, Perdas Totais: -283251.50\n",
      "Modelo e log do episódio 9 salvos em: 4.11\\model_episode_9.pth e 4.11\\log_episode_9.csv\n",
      "\n",
      "Episode 10/200, Total Reward: -257468.25, Win Rate: 0.49, Wins: 900, Losses: 951, Epsilon: 0.4522, Steps: 36754, Time: 116.61s\n",
      "Ações: Manter=12223, Comprar=12892, Vender=11639\n",
      "Ganhos Totais: 29652.25, Perdas Totais: -287120.50\n",
      "Modelo e log do episódio 10 salvos em: 4.11\\model_episode_10.pth e 4.11\\log_episode_10.csv\n",
      "\n",
      "Episode 11/200, Total Reward: -253858.50, Win Rate: 0.48, Wins: 867, Losses: 924, Epsilon: 0.4477, Steps: 36754, Time: 116.71s\n",
      "Ações: Manter=12740, Comprar=12614, Vender=11400\n",
      "Ganhos Totais: 28876.50, Perdas Totais: -282735.00\n",
      "Modelo e log do episódio 11 salvos em: 4.11\\model_episode_11.pth e 4.11\\log_episode_11.csv\n",
      "\n",
      "Episode 12/200, Total Reward: -227828.50, Win Rate: 0.50, Wins: 913, Losses: 925, Epsilon: 0.4432, Steps: 36754, Time: 117.34s\n",
      "Ações: Manter=11749, Comprar=11777, Vender=13228\n",
      "Ganhos Totais: 32717.00, Perdas Totais: -260545.50\n",
      "Modelo e log do episódio 12 salvos em: 4.11\\model_episode_12.pth e 4.11\\log_episode_12.csv\n",
      "\n",
      "Episode 13/200, Total Reward: -217532.00, Win Rate: 0.51, Wins: 932, Losses: 897, Epsilon: 0.4388, Steps: 36754, Time: 117.63s\n",
      "Ações: Manter=12873, Comprar=11953, Vender=11928\n",
      "Ganhos Totais: 32077.25, Perdas Totais: -249609.25\n",
      "Modelo e log do episódio 13 salvos em: 4.11\\model_episode_13.pth e 4.11\\log_episode_13.csv\n",
      "\n",
      "Episode 14/200, Total Reward: -235915.50, Win Rate: 0.52, Wins: 959, Losses: 891, Epsilon: 0.4344, Steps: 36754, Time: 117.21s\n",
      "Ações: Manter=12216, Comprar=12089, Vender=12449\n",
      "Ganhos Totais: 35682.75, Perdas Totais: -271598.25\n",
      "Modelo e log do episódio 14 salvos em: 4.11\\model_episode_14.pth e 4.11\\log_episode_14.csv\n",
      "\n",
      "Episode 15/200, Total Reward: -232745.75, Win Rate: 0.51, Wins: 944, Losses: 919, Epsilon: 0.4300, Steps: 36754, Time: 117.81s\n",
      "Ações: Manter=11937, Comprar=12593, Vender=12224\n",
      "Ganhos Totais: 33195.00, Perdas Totais: -265940.75\n",
      "Modelo e log do episódio 15 salvos em: 4.11\\model_episode_15.pth e 4.11\\log_episode_15.csv\n",
      "\n",
      "Episode 16/200, Total Reward: -257328.75, Win Rate: 0.49, Wins: 896, Losses: 948, Epsilon: 0.4257, Steps: 36754, Time: 117.24s\n",
      "Ações: Manter=11602, Comprar=12414, Vender=12738\n",
      "Ganhos Totais: 29962.00, Perdas Totais: -287290.75\n",
      "Episode 17/200, Total Reward: -245504.25, Win Rate: 0.48, Wins: 900, Losses: 968, Epsilon: 0.4215, Steps: 36754, Time: 117.47s\n",
      "Ações: Manter=12191, Comprar=11476, Vender=13087\n",
      "Ganhos Totais: 31160.25, Perdas Totais: -276664.50\n",
      "Modelo e log do episódio 17 salvos em: 4.11\\model_episode_17.pth e 4.11\\log_episode_17.csv\n",
      "\n",
      "Episode 18/200, Total Reward: -231487.50, Win Rate: 0.51, Wins: 925, Losses: 901, Epsilon: 0.4173, Steps: 36754, Time: 117.42s\n",
      "Ações: Manter=11564, Comprar=11691, Vender=13499\n",
      "Ganhos Totais: 33790.75, Perdas Totais: -265278.25\n",
      "Modelo e log do episódio 18 salvos em: 4.11\\model_episode_18.pth e 4.11\\log_episode_18.csv\n",
      "\n",
      "Episode 19/200, Total Reward: -224824.00, Win Rate: 0.51, Wins: 887, Losses: 860, Epsilon: 0.4131, Steps: 36754, Time: 117.79s\n",
      "Ações: Manter=12201, Comprar=12200, Vender=12353\n",
      "Ganhos Totais: 32383.00, Perdas Totais: -257207.00\n",
      "Modelo e log do episódio 19 salvos em: 4.11\\model_episode_19.pth e 4.11\\log_episode_19.csv\n",
      "\n",
      "Episode 20/200, Total Reward: -225826.75, Win Rate: 0.50, Wins: 909, Losses: 915, Epsilon: 0.4090, Steps: 36754, Time: 117.95s\n",
      "Ações: Manter=12130, Comprar=12580, Vender=12044\n",
      "Ganhos Totais: 33202.00, Perdas Totais: -259028.75\n",
      "Modelo e log do episódio 20 salvos em: 4.11\\model_episode_20.pth e 4.11\\log_episode_20.csv\n",
      "\n",
      "Episode 21/200, Total Reward: -239819.25, Win Rate: 0.47, Wins: 838, Losses: 937, Epsilon: 0.4049, Steps: 36754, Time: 117.64s\n",
      "Ações: Manter=12243, Comprar=11749, Vender=12762\n",
      "Ganhos Totais: 30288.00, Perdas Totais: -270107.25\n",
      "Modelo e log do episódio 21 salvos em: 4.11\\model_episode_21.pth e 4.11\\log_episode_21.csv\n",
      "\n",
      "Episode 22/200, Total Reward: -204049.50, Win Rate: 0.53, Wins: 952, Losses: 836, Epsilon: 0.4008, Steps: 36754, Time: 118.09s\n",
      "Ações: Manter=12994, Comprar=12731, Vender=11029\n",
      "Ganhos Totais: 35408.50, Perdas Totais: -239458.00\n",
      "Modelo e log do episódio 22 salvos em: 4.11\\model_episode_22.pth e 4.11\\log_episode_22.csv\n",
      "\n",
      "Episode 23/200, Total Reward: -209380.00, Win Rate: 0.51, Wins: 871, Losses: 846, Epsilon: 0.3968, Steps: 36754, Time: 118.57s\n",
      "Ações: Manter=12557, Comprar=13301, Vender=10896\n",
      "Ganhos Totais: 32499.25, Perdas Totais: -241879.25\n",
      "Modelo e log do episódio 23 salvos em: 4.11\\model_episode_23.pth e 4.11\\log_episode_23.csv\n",
      "\n",
      "Episode 24/200, Total Reward: -233962.75, Win Rate: 0.49, Wins: 853, Losses: 894, Epsilon: 0.3928, Steps: 36754, Time: 119.21s\n",
      "Ações: Manter=12834, Comprar=11557, Vender=12363\n",
      "Ganhos Totais: 32560.75, Perdas Totais: -266523.50\n",
      "Modelo e log do episódio 24 salvos em: 4.11\\model_episode_24.pth e 4.11\\log_episode_24.csv\n",
      "\n",
      "Episode 25/200, Total Reward: -223034.75, Win Rate: 0.50, Wins: 857, Losses: 868, Epsilon: 0.3889, Steps: 36754, Time: 118.55s\n",
      "Ações: Manter=12611, Comprar=12752, Vender=11391\n",
      "Ganhos Totais: 32528.75, Perdas Totais: -255563.50\n",
      "Modelo e log do episódio 25 salvos em: 4.11\\model_episode_25.pth e 4.11\\log_episode_25.csv\n",
      "\n",
      "Episode 26/200, Total Reward: -235545.25, Win Rate: 0.50, Wins: 911, Losses: 916, Epsilon: 0.3850, Steps: 36754, Time: 118.47s\n",
      "Ações: Manter=12440, Comprar=12007, Vender=12307\n",
      "Ganhos Totais: 31586.25, Perdas Totais: -267131.50\n",
      "Episode 27/200, Total Reward: -190373.50, Win Rate: 0.51, Wins: 873, Losses: 845, Epsilon: 0.3812, Steps: 36754, Time: 118.87s\n",
      "Ações: Manter=12642, Comprar=12758, Vender=11354\n",
      "Ganhos Totais: 35485.00, Perdas Totais: -225858.50\n",
      "Modelo e log do episódio 27 salvos em: 4.11\\model_episode_27.pth e 4.11\\log_episode_27.csv\n",
      "\n",
      "Episode 28/200, Total Reward: -238388.00, Win Rate: 0.51, Wins: 897, Losses: 865, Epsilon: 0.3774, Steps: 36754, Time: 119.33s\n",
      "Ações: Manter=12651, Comprar=11745, Vender=12358\n",
      "Ganhos Totais: 33846.00, Perdas Totais: -272234.00\n",
      "Episode 29/200, Total Reward: -210058.75, Win Rate: 0.49, Wins: 807, Losses: 828, Epsilon: 0.3736, Steps: 36754, Time: 118.57s\n",
      "Ações: Manter=12445, Comprar=12330, Vender=11979\n",
      "Ganhos Totais: 31573.00, Perdas Totais: -241631.75\n",
      "Modelo e log do episódio 29 salvos em: 4.11\\model_episode_29.pth e 4.11\\log_episode_29.csv\n",
      "\n",
      "Episode 30/200, Total Reward: -223179.75, Win Rate: 0.49, Wins: 820, Losses: 843, Epsilon: 0.3699, Steps: 36754, Time: 117.91s\n",
      "Ações: Manter=12868, Comprar=12629, Vender=11257\n",
      "Ganhos Totais: 30481.75, Perdas Totais: -253661.50\n",
      "Modelo e log do episódio 30 salvos em: 4.11\\model_episode_30.pth e 4.11\\log_episode_30.csv\n",
      "\n",
      "Episode 31/200, Total Reward: -205794.75, Win Rate: 0.51, Wins: 813, Losses: 784, Epsilon: 0.3662, Steps: 36754, Time: 118.37s\n",
      "Ações: Manter=12806, Comprar=12295, Vender=11653\n",
      "Ganhos Totais: 31781.25, Perdas Totais: -237576.00\n",
      "Modelo e log do episódio 31 salvos em: 4.11\\model_episode_31.pth e 4.11\\log_episode_31.csv\n",
      "\n",
      "Episode 32/200, Total Reward: -244516.50, Win Rate: 0.49, Wins: 806, Losses: 830, Epsilon: 0.3625, Steps: 36754, Time: 118.29s\n",
      "Ações: Manter=11644, Comprar=10799, Vender=14311\n",
      "Ganhos Totais: 29676.75, Perdas Totais: -274193.25\n",
      "Episode 33/200, Total Reward: -223609.75, Win Rate: 0.49, Wins: 800, Losses: 832, Epsilon: 0.3589, Steps: 36754, Time: 119.19s\n",
      "Ações: Manter=12183, Comprar=11871, Vender=12700\n",
      "Ganhos Totais: 29982.25, Perdas Totais: -253592.00\n",
      "Modelo e log do episódio 33 salvos em: 4.11\\model_episode_33.pth e 4.11\\log_episode_33.csv\n",
      "\n",
      "Episode 34/200, Total Reward: -223265.25, Win Rate: 0.52, Wins: 914, Losses: 836, Epsilon: 0.3553, Steps: 36754, Time: 118.62s\n",
      "Ações: Manter=11759, Comprar=11877, Vender=13118\n",
      "Ganhos Totais: 32706.25, Perdas Totais: -255971.50\n",
      "Modelo e log do episódio 34 salvos em: 4.11\\model_episode_34.pth e 4.11\\log_episode_34.csv\n",
      "\n",
      "Episode 35/200, Total Reward: -233668.25, Win Rate: 0.50, Wins: 852, Losses: 837, Epsilon: 0.3517, Steps: 36754, Time: 118.44s\n",
      "Ações: Manter=11674, Comprar=11328, Vender=13752\n",
      "Ganhos Totais: 30251.75, Perdas Totais: -263920.00\n",
      "Episode 36/200, Total Reward: -195087.25, Win Rate: 0.52, Wins: 823, Losses: 772, Epsilon: 0.3482, Steps: 36754, Time: 118.43s\n",
      "Ações: Manter=12947, Comprar=10754, Vender=13053\n",
      "Ganhos Totais: 31331.50, Perdas Totais: -226418.75\n",
      "Modelo e log do episódio 36 salvos em: 4.11\\model_episode_36.pth e 4.11\\log_episode_36.csv\n",
      "\n",
      "Episode 37/200, Total Reward: -208946.25, Win Rate: 0.50, Wins: 822, Losses: 833, Epsilon: 0.3447, Steps: 36754, Time: 118.52s\n",
      "Ações: Manter=12556, Comprar=11300, Vender=12898\n",
      "Ganhos Totais: 30584.50, Perdas Totais: -239530.75\n",
      "Modelo e log do episódio 37 salvos em: 4.11\\model_episode_37.pth e 4.11\\log_episode_37.csv\n",
      "\n",
      "Episode 38/200, Total Reward: -227426.00, Win Rate: 0.51, Wins: 851, Losses: 831, Epsilon: 0.3413, Steps: 36754, Time: 118.25s\n",
      "Ações: Manter=13119, Comprar=11060, Vender=12575\n",
      "Ganhos Totais: 30778.75, Perdas Totais: -258204.75\n",
      "Episode 39/200, Total Reward: -205639.75, Win Rate: 0.52, Wins: 842, Losses: 776, Epsilon: 0.3379, Steps: 36754, Time: 118.95s\n",
      "Ações: Manter=12622, Comprar=11513, Vender=12619\n",
      "Ganhos Totais: 31348.75, Perdas Totais: -236988.50\n",
      "Modelo e log do episódio 39 salvos em: 4.11\\model_episode_39.pth e 4.11\\log_episode_39.csv\n",
      "\n",
      "Episode 40/200, Total Reward: -212042.50, Win Rate: 0.51, Wins: 860, Losses: 830, Epsilon: 0.3345, Steps: 36754, Time: 118.78s\n",
      "Ações: Manter=12441, Comprar=12025, Vender=12288\n",
      "Ganhos Totais: 30802.50, Perdas Totais: -242845.00\n",
      "Modelo e log do episódio 40 salvos em: 4.11\\model_episode_40.pth e 4.11\\log_episode_40.csv\n",
      "\n",
      "Episode 41/200, Total Reward: -215456.25, Win Rate: 0.51, Wins: 822, Losses: 793, Epsilon: 0.3311, Steps: 36754, Time: 118.81s\n",
      "Ações: Manter=12755, Comprar=12505, Vender=11494\n",
      "Ganhos Totais: 29862.00, Perdas Totais: -245318.25\n",
      "Modelo e log do episódio 41 salvos em: 4.11\\model_episode_41.pth e 4.11\\log_episode_41.csv\n",
      "\n",
      "Episode 42/200, Total Reward: -206440.25, Win Rate: 0.51, Wins: 847, Losses: 817, Epsilon: 0.3278, Steps: 36754, Time: 119.21s\n",
      "Ações: Manter=12282, Comprar=11808, Vender=12664\n",
      "Ganhos Totais: 31439.00, Perdas Totais: -237879.25\n",
      "Modelo e log do episódio 42 salvos em: 4.11\\model_episode_42.pth e 4.11\\log_episode_42.csv\n",
      "\n",
      "Episode 43/200, Total Reward: -203868.75, Win Rate: 0.52, Wins: 863, Losses: 804, Epsilon: 0.3246, Steps: 36754, Time: 118.99s\n",
      "Ações: Manter=12602, Comprar=11818, Vender=12334\n",
      "Ganhos Totais: 33091.75, Perdas Totais: -236960.50\n",
      "Modelo e log do episódio 43 salvos em: 4.11\\model_episode_43.pth e 4.11\\log_episode_43.csv\n",
      "\n",
      "Episode 44/200, Total Reward: -234011.50, Win Rate: 0.51, Wins: 849, Losses: 807, Epsilon: 0.3213, Steps: 36754, Time: 118.97s\n",
      "Ações: Manter=11615, Comprar=12777, Vender=12362\n",
      "Ganhos Totais: 32021.00, Perdas Totais: -266032.50\n",
      "Episode 45/200, Total Reward: -223309.00, Win Rate: 0.51, Wins: 882, Losses: 857, Epsilon: 0.3181, Steps: 36754, Time: 118.93s\n",
      "Ações: Manter=12923, Comprar=10932, Vender=12899\n",
      "Ganhos Totais: 30326.75, Perdas Totais: -253635.75\n",
      "Episode 46/200, Total Reward: -192742.25, Win Rate: 0.52, Wins: 807, Losses: 747, Epsilon: 0.3149, Steps: 36754, Time: 118.89s\n",
      "Ações: Manter=12643, Comprar=11134, Vender=12977\n",
      "Ganhos Totais: 29188.25, Perdas Totais: -221930.50\n",
      "Modelo e log do episódio 46 salvos em: 4.11\\model_episode_46.pth e 4.11\\log_episode_46.csv\n",
      "\n",
      "Episode 47/200, Total Reward: -210061.00, Win Rate: 0.50, Wins: 837, Losses: 835, Epsilon: 0.3118, Steps: 36754, Time: 118.87s\n",
      "Ações: Manter=12906, Comprar=11338, Vender=12510\n",
      "Ganhos Totais: 31094.50, Perdas Totais: -241155.50\n",
      "Episode 48/200, Total Reward: -206291.75, Win Rate: 0.52, Wins: 893, Losses: 817, Epsilon: 0.3086, Steps: 36754, Time: 119.24s\n",
      "Ações: Manter=12933, Comprar=11318, Vender=12503\n",
      "Ganhos Totais: 35768.25, Perdas Totais: -242060.00\n",
      "Modelo e log do episódio 48 salvos em: 4.11\\model_episode_48.pth e 4.11\\log_episode_48.csv\n",
      "\n",
      "Episode 49/200, Total Reward: -224933.50, Win Rate: 0.50, Wins: 783, Losses: 798, Epsilon: 0.3056, Steps: 36754, Time: 119.24s\n",
      "Ações: Manter=13231, Comprar=11396, Vender=12127\n",
      "Ganhos Totais: 29748.75, Perdas Totais: -254682.25\n",
      "Episode 50/200, Total Reward: -203284.50, Win Rate: 0.51, Wins: 850, Losses: 822, Epsilon: 0.3025, Steps: 36754, Time: 119.06s\n",
      "Ações: Manter=12275, Comprar=11266, Vender=13213\n",
      "Ganhos Totais: 32597.25, Perdas Totais: -235881.75\n",
      "Modelo e log do episódio 50 salvos em: 4.11\\model_episode_50.pth e 4.11\\log_episode_50.csv\n",
      "\n",
      "Episode 51/200, Total Reward: -186823.50, Win Rate: 0.53, Wins: 838, Losses: 740, Epsilon: 0.2995, Steps: 36754, Time: 119.55s\n",
      "Ações: Manter=11923, Comprar=11932, Vender=12899\n",
      "Ganhos Totais: 31272.75, Perdas Totais: -218096.25\n",
      "Modelo e log do episódio 51 salvos em: 4.11\\model_episode_51.pth e 4.11\\log_episode_51.csv\n",
      "\n",
      "Episode 52/200, Total Reward: -203285.25, Win Rate: 0.52, Wins: 822, Losses: 774, Epsilon: 0.2965, Steps: 36754, Time: 119.23s\n",
      "Ações: Manter=13084, Comprar=11301, Vender=12369\n",
      "Ganhos Totais: 28317.75, Perdas Totais: -231603.00\n",
      "Modelo e log do episódio 52 salvos em: 4.11\\model_episode_52.pth e 4.11\\log_episode_52.csv\n",
      "\n",
      "Episode 53/200, Total Reward: -202591.00, Win Rate: 0.51, Wins: 811, Losses: 766, Epsilon: 0.2935, Steps: 36754, Time: 119.72s\n",
      "Ações: Manter=13558, Comprar=11482, Vender=11714\n",
      "Ganhos Totais: 28717.75, Perdas Totais: -231308.75\n",
      "Modelo e log do episódio 53 salvos em: 4.11\\model_episode_53.pth e 4.11\\log_episode_53.csv\n",
      "\n",
      "Episode 54/200, Total Reward: -200798.50, Win Rate: 0.51, Wins: 807, Losses: 767, Epsilon: 0.2906, Steps: 36754, Time: 119.38s\n",
      "Ações: Manter=13251, Comprar=11492, Vender=12011\n",
      "Ganhos Totais: 30312.75, Perdas Totais: -231111.25\n",
      "Modelo e log do episódio 54 salvos em: 4.11\\model_episode_54.pth e 4.11\\log_episode_54.csv\n",
      "\n",
      "Episode 55/200, Total Reward: -183411.50, Win Rate: 0.51, Wins: 801, Losses: 779, Epsilon: 0.2877, Steps: 36754, Time: 119.59s\n",
      "Ações: Manter=13300, Comprar=11695, Vender=11759\n",
      "Ganhos Totais: 31263.25, Perdas Totais: -214674.75\n",
      "Modelo e log do episódio 55 salvos em: 4.11\\model_episode_55.pth e 4.11\\log_episode_55.csv\n",
      "\n",
      "Episode 56/200, Total Reward: -185599.75, Win Rate: 0.53, Wins: 816, Losses: 732, Epsilon: 0.2848, Steps: 36754, Time: 120.01s\n",
      "Ações: Manter=12744, Comprar=11584, Vender=12426\n",
      "Ganhos Totais: 33030.75, Perdas Totais: -218630.50\n",
      "Modelo e log do episódio 56 salvos em: 4.11\\model_episode_56.pth e 4.11\\log_episode_56.csv\n",
      "\n",
      "Episode 57/200, Total Reward: -203442.00, Win Rate: 0.51, Wins: 800, Losses: 771, Epsilon: 0.2820, Steps: 36754, Time: 119.81s\n",
      "Ações: Manter=12610, Comprar=12044, Vender=12100\n",
      "Ganhos Totais: 29827.00, Perdas Totais: -233269.00\n",
      "Episode 58/200, Total Reward: -188546.50, Win Rate: 0.53, Wins: 776, Losses: 697, Epsilon: 0.2791, Steps: 36754, Time: 119.90s\n",
      "Ações: Manter=13732, Comprar=11996, Vender=11026\n",
      "Ganhos Totais: 28474.25, Perdas Totais: -217020.75\n",
      "Modelo e log do episódio 58 salvos em: 4.11\\model_episode_58.pth e 4.11\\log_episode_58.csv\n",
      "\n",
      "Episode 59/200, Total Reward: -188967.75, Win Rate: 0.52, Wins: 774, Losses: 707, Epsilon: 0.2763, Steps: 36754, Time: 120.11s\n",
      "Ações: Manter=14538, Comprar=11264, Vender=10952\n",
      "Ganhos Totais: 30734.00, Perdas Totais: -219701.75\n",
      "Modelo e log do episódio 59 salvos em: 4.11\\model_episode_59.pth e 4.11\\log_episode_59.csv\n",
      "\n",
      "Episode 60/200, Total Reward: -193504.25, Win Rate: 0.52, Wins: 789, Losses: 728, Epsilon: 0.2736, Steps: 36754, Time: 119.77s\n",
      "Ações: Manter=12886, Comprar=10823, Vender=13045\n",
      "Ganhos Totais: 27615.75, Perdas Totais: -221120.00\n",
      "Modelo e log do episódio 60 salvos em: 4.11\\model_episode_60.pth e 4.11\\log_episode_60.csv\n",
      "\n",
      "Episode 61/200, Total Reward: -190407.75, Win Rate: 0.51, Wins: 797, Losses: 757, Epsilon: 0.2708, Steps: 36754, Time: 119.70s\n",
      "Ações: Manter=14022, Comprar=10647, Vender=12085\n",
      "Ganhos Totais: 30623.25, Perdas Totais: -221031.00\n",
      "Modelo e log do episódio 61 salvos em: 4.11\\model_episode_61.pth e 4.11\\log_episode_61.csv\n",
      "\n",
      "Episode 62/200, Total Reward: -202587.50, Win Rate: 0.52, Wins: 731, Losses: 688, Epsilon: 0.2681, Steps: 36754, Time: 119.78s\n",
      "Ações: Manter=13208, Comprar=10629, Vender=12917\n",
      "Ganhos Totais: 27161.00, Perdas Totais: -229748.50\n",
      "Episode 63/200, Total Reward: -199909.00, Win Rate: 0.52, Wins: 842, Losses: 789, Epsilon: 0.2655, Steps: 36754, Time: 120.65s\n",
      "Ações: Manter=12372, Comprar=10535, Vender=13847\n",
      "Ganhos Totais: 30568.50, Perdas Totais: -230477.50\n",
      "Episode 64/200, Total Reward: -193283.75, Win Rate: 0.51, Wins: 765, Losses: 744, Epsilon: 0.2628, Steps: 36754, Time: 120.28s\n",
      "Ações: Manter=11767, Comprar=11468, Vender=13519\n",
      "Ganhos Totais: 30836.25, Perdas Totais: -224120.00\n",
      "Modelo e log do episódio 64 salvos em: 4.11\\model_episode_64.pth e 4.11\\log_episode_64.csv\n",
      "\n",
      "Episode 65/200, Total Reward: -199070.00, Win Rate: 0.50, Wins: 772, Losses: 777, Epsilon: 0.2602, Steps: 36754, Time: 120.06s\n",
      "Ações: Manter=12840, Comprar=10788, Vender=13126\n",
      "Ganhos Totais: 29938.00, Perdas Totais: -229008.00\n",
      "Episode 66/200, Total Reward: -187745.50, Win Rate: 0.52, Wins: 809, Losses: 758, Epsilon: 0.2576, Steps: 36754, Time: 119.94s\n",
      "Ações: Manter=12175, Comprar=10856, Vender=13723\n",
      "Ganhos Totais: 29989.75, Perdas Totais: -217735.25\n",
      "Modelo e log do episódio 66 salvos em: 4.11\\model_episode_66.pth e 4.11\\log_episode_66.csv\n",
      "\n",
      "Episode 67/200, Total Reward: -197002.50, Win Rate: 0.51, Wins: 758, Losses: 736, Epsilon: 0.2550, Steps: 36754, Time: 120.11s\n",
      "Ações: Manter=12354, Comprar=11311, Vender=13089\n",
      "Ganhos Totais: 29447.00, Perdas Totais: -226449.50\n",
      "Episode 68/200, Total Reward: -196552.25, Win Rate: 0.51, Wins: 775, Losses: 747, Epsilon: 0.2524, Steps: 36754, Time: 120.17s\n",
      "Ações: Manter=12941, Comprar=10371, Vender=13442\n",
      "Ganhos Totais: 28701.00, Perdas Totais: -225253.25\n",
      "Episode 69/200, Total Reward: -182481.00, Win Rate: 0.52, Wins: 733, Losses: 680, Epsilon: 0.2499, Steps: 36754, Time: 120.14s\n",
      "Ações: Manter=13488, Comprar=10958, Vender=12308\n",
      "Ganhos Totais: 30899.25, Perdas Totais: -213380.25\n",
      "Modelo e log do episódio 69 salvos em: 4.11\\model_episode_69.pth e 4.11\\log_episode_69.csv\n",
      "\n",
      "Episode 70/200, Total Reward: -168008.00, Win Rate: 0.53, Wins: 813, Losses: 720, Epsilon: 0.2474, Steps: 36754, Time: 120.39s\n",
      "Ações: Manter=12549, Comprar=10567, Vender=13638\n",
      "Ganhos Totais: 31391.75, Perdas Totais: -199399.75\n",
      "Modelo e log do episódio 70 salvos em: 4.11\\model_episode_70.pth e 4.11\\log_episode_70.csv\n",
      "\n",
      "Episode 71/200, Total Reward: -202374.00, Win Rate: 0.50, Wins: 712, Losses: 718, Epsilon: 0.2449, Steps: 36754, Time: 120.05s\n",
      "Ações: Manter=13311, Comprar=10971, Vender=12472\n",
      "Ganhos Totais: 27918.50, Perdas Totais: -230292.50\n",
      "Episode 72/200, Total Reward: -178965.75, Win Rate: 0.51, Wins: 745, Losses: 710, Epsilon: 0.2425, Steps: 36754, Time: 120.14s\n",
      "Ações: Manter=12688, Comprar=12268, Vender=11798\n",
      "Ganhos Totais: 28373.00, Perdas Totais: -207338.75\n",
      "Modelo e log do episódio 72 salvos em: 4.11\\model_episode_72.pth e 4.11\\log_episode_72.csv\n",
      "\n",
      "Episode 73/200, Total Reward: -160665.75, Win Rate: 0.54, Wins: 727, Losses: 630, Epsilon: 0.2401, Steps: 36754, Time: 120.68s\n",
      "Ações: Manter=13585, Comprar=11849, Vender=11320\n",
      "Ganhos Totais: 30553.75, Perdas Totais: -191219.50\n",
      "Modelo e log do episódio 73 salvos em: 4.11\\model_episode_73.pth e 4.11\\log_episode_73.csv\n",
      "\n",
      "Episode 74/200, Total Reward: -192296.75, Win Rate: 0.49, Wins: 684, Losses: 711, Epsilon: 0.2377, Steps: 36754, Time: 120.26s\n",
      "Ações: Manter=12280, Comprar=12002, Vender=12472\n",
      "Ganhos Totais: 26645.75, Perdas Totais: -218942.50\n",
      "Episode 75/200, Total Reward: -177473.25, Win Rate: 0.51, Wins: 724, Losses: 696, Epsilon: 0.2353, Steps: 36754, Time: 120.74s\n",
      "Ações: Manter=13481, Comprar=10927, Vender=12346\n",
      "Ganhos Totais: 27338.50, Perdas Totais: -204811.75\n",
      "Modelo e log do episódio 75 salvos em: 4.11\\model_episode_75.pth e 4.11\\log_episode_75.csv\n",
      "\n",
      "Episode 76/200, Total Reward: -160108.50, Win Rate: 0.53, Wins: 737, Losses: 660, Epsilon: 0.2329, Steps: 36754, Time: 120.31s\n",
      "Ações: Manter=12851, Comprar=11962, Vender=11941\n",
      "Ganhos Totais: 29417.50, Perdas Totais: -189526.00\n",
      "Modelo e log do episódio 76 salvos em: 4.11\\model_episode_76.pth e 4.11\\log_episode_76.csv\n",
      "\n",
      "Episode 77/200, Total Reward: -170943.25, Win Rate: 0.50, Wins: 670, Losses: 680, Epsilon: 0.2306, Steps: 36754, Time: 120.11s\n",
      "Ações: Manter=14265, Comprar=12170, Vender=10319\n",
      "Ganhos Totais: 27795.75, Perdas Totais: -198739.00\n",
      "Modelo e log do episódio 77 salvos em: 4.11\\model_episode_77.pth e 4.11\\log_episode_77.csv\n",
      "\n",
      "Episode 78/200, Total Reward: -181401.75, Win Rate: 0.50, Wins: 690, Losses: 693, Epsilon: 0.2283, Steps: 36754, Time: 120.42s\n",
      "Ações: Manter=13773, Comprar=11369, Vender=11612\n",
      "Ganhos Totais: 28963.75, Perdas Totais: -210365.50\n",
      "Modelo e log do episódio 78 salvos em: 4.11\\model_episode_78.pth e 4.11\\log_episode_78.csv\n",
      "\n",
      "Episode 79/200, Total Reward: -164497.00, Win Rate: 0.51, Wins: 716, Losses: 684, Epsilon: 0.2260, Steps: 36754, Time: 120.50s\n",
      "Ações: Manter=13229, Comprar=11567, Vender=11958\n",
      "Ganhos Totais: 29725.75, Perdas Totais: -194222.75\n",
      "Modelo e log do episódio 79 salvos em: 4.11\\model_episode_79.pth e 4.11\\log_episode_79.csv\n",
      "\n",
      "Episode 80/200, Total Reward: -150172.50, Win Rate: 0.53, Wins: 699, Losses: 624, Epsilon: 0.2238, Steps: 36754, Time: 120.25s\n",
      "Ações: Manter=12313, Comprar=11898, Vender=12543\n",
      "Ganhos Totais: 30819.75, Perdas Totais: -180992.25\n",
      "Modelo e log do episódio 80 salvos em: 4.11\\model_episode_80.pth e 4.11\\log_episode_80.csv\n",
      "\n",
      "Episode 81/200, Total Reward: -166058.00, Win Rate: 0.53, Wins: 738, Losses: 654, Epsilon: 0.2215, Steps: 36754, Time: 120.38s\n",
      "Ações: Manter=12672, Comprar=11740, Vender=12342\n",
      "Ganhos Totais: 31180.75, Perdas Totais: -197238.75\n",
      "Modelo e log do episódio 81 salvos em: 4.11\\model_episode_81.pth e 4.11\\log_episode_81.csv\n",
      "\n",
      "Episode 82/200, Total Reward: -170050.00, Win Rate: 0.49, Wins: 694, Losses: 718, Epsilon: 0.2193, Steps: 36754, Time: 120.19s\n",
      "Ações: Manter=13203, Comprar=11500, Vender=12051\n",
      "Ganhos Totais: 28507.25, Perdas Totais: -198557.25\n",
      "Modelo e log do episódio 82 salvos em: 4.11\\model_episode_82.pth e 4.11\\log_episode_82.csv\n",
      "\n",
      "Episode 83/200, Total Reward: -154840.00, Win Rate: 0.51, Wins: 684, Losses: 670, Epsilon: 0.2171, Steps: 36754, Time: 120.41s\n",
      "Ações: Manter=13443, Comprar=11923, Vender=11388\n",
      "Ganhos Totais: 29112.00, Perdas Totais: -183952.00\n",
      "Modelo e log do episódio 83 salvos em: 4.11\\model_episode_83.pth e 4.11\\log_episode_83.csv\n",
      "\n",
      "Episode 84/200, Total Reward: -149994.25, Win Rate: 0.53, Wins: 700, Losses: 611, Epsilon: 0.2149, Steps: 36754, Time: 120.67s\n",
      "Ações: Manter=14264, Comprar=12028, Vender=10462\n",
      "Ganhos Totais: 29637.00, Perdas Totais: -179631.25\n",
      "Modelo e log do episódio 84 salvos em: 4.11\\model_episode_84.pth e 4.11\\log_episode_84.csv\n",
      "\n",
      "Episode 85/200, Total Reward: -163267.25, Win Rate: 0.53, Wins: 734, Losses: 646, Epsilon: 0.2128, Steps: 36754, Time: 120.43s\n",
      "Ações: Manter=12174, Comprar=12441, Vender=12139\n",
      "Ganhos Totais: 30349.00, Perdas Totais: -193616.25\n",
      "Modelo e log do episódio 85 salvos em: 4.11\\model_episode_85.pth e 4.11\\log_episode_85.csv\n",
      "\n",
      "Episode 86/200, Total Reward: -149579.00, Win Rate: 0.52, Wins: 649, Losses: 595, Epsilon: 0.2107, Steps: 36754, Time: 120.20s\n",
      "Ações: Manter=12698, Comprar=11982, Vender=12074\n",
      "Ganhos Totais: 29567.00, Perdas Totais: -179146.00\n",
      "Modelo e log do episódio 86 salvos em: 4.11\\model_episode_86.pth e 4.11\\log_episode_86.csv\n",
      "\n",
      "Episode 87/200, Total Reward: -161788.50, Win Rate: 0.52, Wins: 651, Losses: 594, Epsilon: 0.2086, Steps: 36754, Time: 121.41s\n",
      "Ações: Manter=12219, Comprar=12732, Vender=11803\n",
      "Ganhos Totais: 29768.00, Perdas Totais: -191556.50\n",
      "Modelo e log do episódio 87 salvos em: 4.11\\model_episode_87.pth e 4.11\\log_episode_87.csv\n",
      "\n",
      "Episode 88/200, Total Reward: -172738.00, Win Rate: 0.51, Wins: 687, Losses: 657, Epsilon: 0.2065, Steps: 36754, Time: 121.11s\n",
      "Ações: Manter=12806, Comprar=12295, Vender=11653\n",
      "Ganhos Totais: 28454.25, Perdas Totais: -201192.25\n",
      "Episode 89/200, Total Reward: -150436.25, Win Rate: 0.53, Wins: 724, Losses: 644, Epsilon: 0.2044, Steps: 36754, Time: 120.87s\n",
      "Ações: Manter=13736, Comprar=11894, Vender=11124\n",
      "Ganhos Totais: 29253.00, Perdas Totais: -179689.25\n",
      "Modelo e log do episódio 89 salvos em: 4.11\\model_episode_89.pth e 4.11\\log_episode_89.csv\n",
      "\n",
      "Episode 90/200, Total Reward: -160331.25, Win Rate: 0.50, Wins: 638, Losses: 641, Epsilon: 0.2024, Steps: 36754, Time: 120.49s\n",
      "Ações: Manter=13519, Comprar=12198, Vender=11037\n",
      "Ganhos Totais: 28370.25, Perdas Totais: -188701.50\n",
      "Modelo e log do episódio 90 salvos em: 4.11\\model_episode_90.pth e 4.11\\log_episode_90.csv\n",
      "\n",
      "Episode 91/200, Total Reward: -163489.50, Win Rate: 0.52, Wins: 671, Losses: 618, Epsilon: 0.2003, Steps: 36754, Time: 120.91s\n",
      "Ações: Manter=13757, Comprar=12172, Vender=10825\n",
      "Ganhos Totais: 29027.00, Perdas Totais: -192516.50\n",
      "Episode 92/200, Total Reward: -146294.75, Win Rate: 0.52, Wins: 655, Losses: 610, Epsilon: 0.1983, Steps: 36754, Time: 120.82s\n",
      "Ações: Manter=11336, Comprar=11252, Vender=14166\n",
      "Ganhos Totais: 28410.25, Perdas Totais: -174705.00\n",
      "Modelo e log do episódio 92 salvos em: 4.11\\model_episode_92.pth e 4.11\\log_episode_92.csv\n",
      "\n",
      "Episode 93/200, Total Reward: -164620.50, Win Rate: 0.49, Wins: 575, Losses: 594, Epsilon: 0.1964, Steps: 36754, Time: 121.69s\n",
      "Ações: Manter=12262, Comprar=10630, Vender=13862\n",
      "Ganhos Totais: 26252.25, Perdas Totais: -190872.75\n",
      "Episode 94/200, Total Reward: -146154.50, Win Rate: 0.50, Wins: 607, Losses: 598, Epsilon: 0.1944, Steps: 36754, Time: 121.60s\n",
      "Ações: Manter=12449, Comprar=10196, Vender=14109\n",
      "Ganhos Totais: 28769.75, Perdas Totais: -174924.25\n",
      "Modelo e log do episódio 94 salvos em: 4.11\\model_episode_94.pth e 4.11\\log_episode_94.csv\n",
      "\n",
      "Episode 95/200, Total Reward: -162680.50, Win Rate: 0.50, Wins: 621, Losses: 625, Epsilon: 0.1924, Steps: 36754, Time: 121.11s\n",
      "Ações: Manter=11796, Comprar=10307, Vender=14651\n",
      "Ganhos Totais: 30256.00, Perdas Totais: -192936.50\n",
      "Episode 96/200, Total Reward: -138026.25, Win Rate: 0.54, Wins: 691, Losses: 594, Epsilon: 0.1905, Steps: 36754, Time: 121.19s\n",
      "Ações: Manter=11970, Comprar=12072, Vender=12712\n",
      "Ganhos Totais: 28788.00, Perdas Totais: -166814.25\n",
      "Modelo e log do episódio 96 salvos em: 4.11\\model_episode_96.pth e 4.11\\log_episode_96.csv\n",
      "\n",
      "Episode 97/200, Total Reward: -147165.50, Win Rate: 0.51, Wins: 654, Losses: 619, Epsilon: 0.1886, Steps: 36754, Time: 121.44s\n",
      "Ações: Manter=10842, Comprar=10412, Vender=15500\n",
      "Ganhos Totais: 27187.00, Perdas Totais: -174352.50\n",
      "Modelo e log do episódio 97 salvos em: 4.11\\model_episode_97.pth e 4.11\\log_episode_97.csv\n",
      "\n",
      "Episode 98/200, Total Reward: -152322.25, Win Rate: 0.49, Wins: 578, Losses: 603, Epsilon: 0.1867, Steps: 36754, Time: 120.89s\n",
      "Ações: Manter=12016, Comprar=10218, Vender=14520\n",
      "Ganhos Totais: 25779.75, Perdas Totais: -178102.00\n",
      "Modelo e log do episódio 98 salvos em: 4.11\\model_episode_98.pth e 4.11\\log_episode_98.csv\n",
      "\n",
      "Episode 99/200, Total Reward: -158426.50, Win Rate: 0.50, Wins: 597, Losses: 600, Epsilon: 0.1849, Steps: 36754, Time: 120.90s\n",
      "Ações: Manter=12305, Comprar=10719, Vender=13730\n",
      "Ganhos Totais: 27633.75, Perdas Totais: -186060.25\n",
      "Episode 100/200, Total Reward: -156098.75, Win Rate: 0.50, Wins: 610, Losses: 599, Epsilon: 0.1830, Steps: 36754, Time: 121.07s\n",
      "Ações: Manter=10563, Comprar=10996, Vender=15195\n",
      "Ganhos Totais: 27417.50, Perdas Totais: -183516.25\n",
      "Episode 101/200, Total Reward: -140575.50, Win Rate: 0.50, Wins: 610, Losses: 618, Epsilon: 0.1812, Steps: 36754, Time: 121.54s\n",
      "Ações: Manter=10749, Comprar=11700, Vender=14305\n",
      "Ganhos Totais: 29097.25, Perdas Totais: -169672.75\n",
      "Modelo e log do episódio 101 salvos em: 4.11\\model_episode_101.pth e 4.11\\log_episode_101.csv\n",
      "\n",
      "Episode 102/200, Total Reward: -149827.00, Win Rate: 0.52, Wins: 623, Losses: 566, Epsilon: 0.1794, Steps: 36754, Time: 121.49s\n",
      "Ações: Manter=12700, Comprar=13245, Vender=10809\n",
      "Ganhos Totais: 26311.50, Perdas Totais: -176138.50\n",
      "Modelo e log do episódio 102 salvos em: 4.11\\model_episode_102.pth e 4.11\\log_episode_102.csv\n",
      "\n",
      "Episode 103/200, Total Reward: -145483.00, Win Rate: 0.52, Wins: 620, Losses: 566, Epsilon: 0.1776, Steps: 36754, Time: 121.58s\n",
      "Ações: Manter=11978, Comprar=12143, Vender=12633\n",
      "Ganhos Totais: 29437.00, Perdas Totais: -174920.00\n",
      "Modelo e log do episódio 103 salvos em: 4.11\\model_episode_103.pth e 4.11\\log_episode_103.csv\n",
      "\n",
      "Episode 104/200, Total Reward: -129802.75, Win Rate: 0.52, Wins: 630, Losses: 576, Epsilon: 0.1758, Steps: 36754, Time: 121.35s\n",
      "Ações: Manter=10942, Comprar=12623, Vender=13189\n",
      "Ganhos Totais: 29048.50, Perdas Totais: -158851.25\n",
      "Modelo e log do episódio 104 salvos em: 4.11\\model_episode_104.pth e 4.11\\log_episode_104.csv\n",
      "\n",
      "Episode 105/200, Total Reward: -143303.75, Win Rate: 0.50, Wins: 573, Losses: 570, Epsilon: 0.1740, Steps: 36754, Time: 121.75s\n",
      "Ações: Manter=12945, Comprar=11922, Vender=11887\n",
      "Ganhos Totais: 26278.25, Perdas Totais: -169582.00\n",
      "Modelo e log do episódio 105 salvos em: 4.11\\model_episode_105.pth e 4.11\\log_episode_105.csv\n",
      "\n",
      "Episode 106/200, Total Reward: -133997.75, Win Rate: 0.51, Wins: 642, Losses: 622, Epsilon: 0.1723, Steps: 36754, Time: 121.20s\n",
      "Ações: Manter=12088, Comprar=11357, Vender=13309\n",
      "Ganhos Totais: 28755.25, Perdas Totais: -162753.00\n",
      "Modelo e log do episódio 106 salvos em: 4.11\\model_episode_106.pth e 4.11\\log_episode_106.csv\n",
      "\n",
      "Episode 107/200, Total Reward: -146868.25, Win Rate: 0.49, Wins: 573, Losses: 608, Epsilon: 0.1706, Steps: 36754, Time: 126.24s\n",
      "Ações: Manter=12396, Comprar=11433, Vender=12925\n",
      "Ganhos Totais: 25588.75, Perdas Totais: -172457.00\n",
      "Modelo e log do episódio 107 salvos em: 4.11\\model_episode_107.pth e 4.11\\log_episode_107.csv\n",
      "\n",
      "Episode 108/200, Total Reward: -135926.00, Win Rate: 0.53, Wins: 623, Losses: 561, Epsilon: 0.1689, Steps: 36754, Time: 123.88s\n",
      "Ações: Manter=11969, Comprar=12140, Vender=12645\n",
      "Ganhos Totais: 27570.50, Perdas Totais: -163496.50\n",
      "Modelo e log do episódio 108 salvos em: 4.11\\model_episode_108.pth e 4.11\\log_episode_108.csv\n",
      "\n",
      "Episode 109/200, Total Reward: -139370.75, Win Rate: 0.53, Wins: 632, Losses: 570, Epsilon: 0.1672, Steps: 36754, Time: 123.80s\n",
      "Ações: Manter=11332, Comprar=11005, Vender=14417\n",
      "Ganhos Totais: 28134.75, Perdas Totais: -167505.50\n",
      "Modelo e log do episódio 109 salvos em: 4.11\\model_episode_109.pth e 4.11\\log_episode_109.csv\n",
      "\n",
      "Episode 110/200, Total Reward: -132180.50, Win Rate: 0.53, Wins: 602, Losses: 526, Epsilon: 0.1655, Steps: 36754, Time: 123.79s\n",
      "Ações: Manter=11830, Comprar=11416, Vender=13508\n",
      "Ganhos Totais: 27295.25, Perdas Totais: -159475.75\n",
      "Modelo e log do episódio 110 salvos em: 4.11\\model_episode_110.pth e 4.11\\log_episode_110.csv\n",
      "\n",
      "Episode 111/200, Total Reward: -122908.00, Win Rate: 0.52, Wins: 623, Losses: 573, Epsilon: 0.1639, Steps: 36754, Time: 124.05s\n",
      "Ações: Manter=11936, Comprar=10702, Vender=14116\n",
      "Ganhos Totais: 29553.50, Perdas Totais: -152461.50\n",
      "Modelo e log do episódio 111 salvos em: 4.11\\model_episode_111.pth e 4.11\\log_episode_111.csv\n",
      "\n",
      "Episode 112/200, Total Reward: -119351.25, Win Rate: 0.51, Wins: 578, Losses: 563, Epsilon: 0.1622, Steps: 36754, Time: 123.62s\n",
      "Ações: Manter=13420, Comprar=10546, Vender=12788\n",
      "Ganhos Totais: 25666.00, Perdas Totais: -145017.25\n",
      "Modelo e log do episódio 112 salvos em: 4.11\\model_episode_112.pth e 4.11\\log_episode_112.csv\n",
      "\n",
      "Episode 113/200, Total Reward: -161215.50, Win Rate: 0.50, Wins: 616, Losses: 621, Epsilon: 0.1606, Steps: 36754, Time: 124.10s\n",
      "Ações: Manter=12801, Comprar=10480, Vender=13473\n",
      "Ganhos Totais: 27394.50, Perdas Totais: -188610.00\n",
      "Episode 114/200, Total Reward: -127396.00, Win Rate: 0.49, Wins: 554, Losses: 574, Epsilon: 0.1590, Steps: 36754, Time: 123.92s\n",
      "Ações: Manter=13777, Comprar=10094, Vender=12883\n",
      "Ganhos Totais: 25938.25, Perdas Totais: -153334.25\n",
      "Modelo e log do episódio 114 salvos em: 4.11\\model_episode_114.pth e 4.11\\log_episode_114.csv\n",
      "\n",
      "Episode 115/200, Total Reward: -138794.25, Win Rate: 0.48, Wins: 500, Losses: 552, Epsilon: 0.1574, Steps: 36754, Time: 124.17s\n",
      "Ações: Manter=13821, Comprar=10941, Vender=11992\n",
      "Ganhos Totais: 24977.50, Perdas Totais: -163771.75\n",
      "Modelo e log do episódio 115 salvos em: 4.11\\model_episode_115.pth e 4.11\\log_episode_115.csv\n",
      "\n",
      "Episode 116/200, Total Reward: -147414.50, Win Rate: 0.52, Wins: 608, Losses: 557, Epsilon: 0.1558, Steps: 36754, Time: 123.77s\n",
      "Ações: Manter=14057, Comprar=10258, Vender=12439\n",
      "Ganhos Totais: 26853.50, Perdas Totais: -174268.00\n",
      "Episode 117/200, Total Reward: -122845.25, Win Rate: 0.50, Wins: 572, Losses: 564, Epsilon: 0.1543, Steps: 36754, Time: 124.23s\n",
      "Ações: Manter=12301, Comprar=11234, Vender=13219\n",
      "Ganhos Totais: 26529.50, Perdas Totais: -149374.75\n",
      "Modelo e log do episódio 117 salvos em: 4.11\\model_episode_117.pth e 4.11\\log_episode_117.csv\n",
      "\n",
      "Episode 118/200, Total Reward: -144768.75, Win Rate: 0.50, Wins: 564, Losses: 571, Epsilon: 0.1527, Steps: 36754, Time: 123.88s\n",
      "Ações: Manter=13772, Comprar=10388, Vender=12594\n",
      "Ganhos Totais: 26549.50, Perdas Totais: -171318.25\n",
      "Episode 119/200, Total Reward: -138705.50, Win Rate: 0.50, Wins: 575, Losses: 572, Epsilon: 0.1512, Steps: 36754, Time: 123.80s\n",
      "Ações: Manter=14063, Comprar=10479, Vender=12212\n",
      "Ganhos Totais: 25358.75, Perdas Totais: -164064.25\n",
      "Modelo e log do episódio 119 salvos em: 4.11\\model_episode_119.pth e 4.11\\log_episode_119.csv\n",
      "\n",
      "Episode 120/200, Total Reward: -137497.00, Win Rate: 0.50, Wins: 553, Losses: 549, Epsilon: 0.1497, Steps: 36754, Time: 124.11s\n",
      "Ações: Manter=13279, Comprar=11397, Vender=12078\n",
      "Ganhos Totais: 27492.75, Perdas Totais: -164989.75\n",
      "Modelo e log do episódio 120 salvos em: 4.11\\model_episode_120.pth e 4.11\\log_episode_120.csv\n",
      "\n",
      "Episode 121/200, Total Reward: -142107.50, Win Rate: 0.52, Wins: 601, Losses: 549, Epsilon: 0.1482, Steps: 36754, Time: 123.87s\n",
      "Ações: Manter=14807, Comprar=10391, Vender=11556\n",
      "Ganhos Totais: 28095.00, Perdas Totais: -170202.50\n",
      "Episode 122/200, Total Reward: -122859.75, Win Rate: 0.52, Wins: 552, Losses: 511, Epsilon: 0.1467, Steps: 36754, Time: 124.46s\n",
      "Ações: Manter=14639, Comprar=11164, Vender=10951\n",
      "Ganhos Totais: 28569.25, Perdas Totais: -151429.00\n",
      "Modelo e log do episódio 122 salvos em: 4.11\\model_episode_122.pth e 4.11\\log_episode_122.csv\n",
      "\n",
      "Episode 123/200, Total Reward: -140062.25, Win Rate: 0.50, Wins: 525, Losses: 521, Epsilon: 0.1452, Steps: 36754, Time: 123.88s\n",
      "Ações: Manter=13928, Comprar=11365, Vender=11461\n",
      "Ganhos Totais: 25473.00, Perdas Totais: -165535.25\n",
      "Episode 124/200, Total Reward: -107146.50, Win Rate: 0.54, Wins: 558, Losses: 477, Epsilon: 0.1438, Steps: 36754, Time: 124.34s\n",
      "Ações: Manter=13622, Comprar=12175, Vender=10957\n",
      "Ganhos Totais: 28554.25, Perdas Totais: -135700.75\n",
      "Modelo e log do episódio 124 salvos em: 4.11\\model_episode_124.pth e 4.11\\log_episode_124.csv\n",
      "\n",
      "Episode 125/200, Total Reward: -122332.50, Win Rate: 0.52, Wins: 564, Losses: 518, Epsilon: 0.1424, Steps: 36754, Time: 124.24s\n",
      "Ações: Manter=14721, Comprar=10716, Vender=11317\n",
      "Ganhos Totais: 27956.00, Perdas Totais: -150288.50\n",
      "Modelo e log do episódio 125 salvos em: 4.11\\model_episode_125.pth e 4.11\\log_episode_125.csv\n",
      "\n",
      "Episode 126/200, Total Reward: -107695.75, Win Rate: 0.52, Wins: 511, Losses: 478, Epsilon: 0.1409, Steps: 36754, Time: 124.08s\n",
      "Ações: Manter=14951, Comprar=11265, Vender=10538\n",
      "Ganhos Totais: 24703.50, Perdas Totais: -132399.25\n",
      "Modelo e log do episódio 126 salvos em: 4.11\\model_episode_126.pth e 4.11\\log_episode_126.csv\n",
      "\n",
      "Episode 127/200, Total Reward: -127478.00, Win Rate: 0.51, Wins: 548, Losses: 537, Epsilon: 0.1395, Steps: 36754, Time: 124.39s\n",
      "Ações: Manter=13080, Comprar=12162, Vender=11512\n",
      "Ganhos Totais: 26933.25, Perdas Totais: -154411.25\n",
      "Modelo e log do episódio 127 salvos em: 4.11\\model_episode_127.pth e 4.11\\log_episode_127.csv\n",
      "\n",
      "Episode 128/200, Total Reward: -124661.50, Win Rate: 0.51, Wins: 555, Losses: 524, Epsilon: 0.1381, Steps: 36754, Time: 124.01s\n",
      "Ações: Manter=14665, Comprar=10692, Vender=11397\n",
      "Ganhos Totais: 27628.75, Perdas Totais: -152290.25\n",
      "Modelo e log do episódio 128 salvos em: 4.11\\model_episode_128.pth e 4.11\\log_episode_128.csv\n",
      "\n",
      "Episode 129/200, Total Reward: -121635.00, Win Rate: 0.51, Wins: 518, Losses: 489, Epsilon: 0.1367, Steps: 36754, Time: 124.43s\n",
      "Ações: Manter=14557, Comprar=12343, Vender=9854\n",
      "Ganhos Totais: 24865.75, Perdas Totais: -146500.75\n",
      "Modelo e log do episódio 129 salvos em: 4.11\\model_episode_129.pth e 4.11\\log_episode_129.csv\n",
      "\n",
      "Episode 130/200, Total Reward: -109683.00, Win Rate: 0.51, Wins: 494, Losses: 474, Epsilon: 0.1354, Steps: 36754, Time: 124.85s\n",
      "Ações: Manter=14430, Comprar=11260, Vender=11064\n",
      "Ganhos Totais: 25429.75, Perdas Totais: -135112.75\n",
      "Modelo e log do episódio 130 salvos em: 4.11\\model_episode_130.pth e 4.11\\log_episode_130.csv\n",
      "\n",
      "Episode 131/200, Total Reward: -106359.25, Win Rate: 0.53, Wins: 569, Losses: 505, Epsilon: 0.1340, Steps: 36754, Time: 124.55s\n",
      "Ações: Manter=14773, Comprar=12341, Vender=9640\n",
      "Ganhos Totais: 25752.25, Perdas Totais: -132111.50\n",
      "Modelo e log do episódio 131 salvos em: 4.11\\model_episode_131.pth e 4.11\\log_episode_131.csv\n",
      "\n",
      "Episode 132/200, Total Reward: -123543.25, Win Rate: 0.53, Wins: 592, Losses: 521, Epsilon: 0.1327, Steps: 36754, Time: 124.80s\n",
      "Ações: Manter=13834, Comprar=12800, Vender=10120\n",
      "Ganhos Totais: 27057.50, Perdas Totais: -150600.75\n",
      "Episode 133/200, Total Reward: -128570.75, Win Rate: 0.52, Wins: 566, Losses: 529, Epsilon: 0.1314, Steps: 36754, Time: 124.60s\n",
      "Ações: Manter=14629, Comprar=11951, Vender=10174\n",
      "Ganhos Totais: 25565.25, Perdas Totais: -154136.00\n",
      "Episode 134/200, Total Reward: -110933.75, Win Rate: 0.53, Wins: 538, Losses: 482, Epsilon: 0.1300, Steps: 36754, Time: 124.76s\n",
      "Ações: Manter=14139, Comprar=11397, Vender=11218\n",
      "Ganhos Totais: 28790.25, Perdas Totais: -139724.00\n",
      "Modelo e log do episódio 134 salvos em: 4.11\\model_episode_134.pth e 4.11\\log_episode_134.csv\n",
      "\n",
      "Episode 135/200, Total Reward: -128962.50, Win Rate: 0.49, Wins: 504, Losses: 521, Epsilon: 0.1287, Steps: 36754, Time: 124.73s\n",
      "Ações: Manter=15328, Comprar=12259, Vender=9167\n",
      "Ganhos Totais: 24770.00, Perdas Totais: -153732.50\n",
      "Episode 136/200, Total Reward: -121507.25, Win Rate: 0.52, Wins: 533, Losses: 488, Epsilon: 0.1275, Steps: 36754, Time: 124.51s\n",
      "Ações: Manter=13923, Comprar=12991, Vender=9840\n",
      "Ganhos Totais: 25879.25, Perdas Totais: -147386.50\n",
      "Modelo e log do episódio 136 salvos em: 4.11\\model_episode_136.pth e 4.11\\log_episode_136.csv\n",
      "\n",
      "Episode 137/200, Total Reward: -123778.25, Win Rate: 0.50, Wins: 499, Losses: 493, Epsilon: 0.1262, Steps: 36754, Time: 124.61s\n",
      "Ações: Manter=13464, Comprar=13401, Vender=9889\n",
      "Ganhos Totais: 27086.00, Perdas Totais: -150864.25\n",
      "Episode 138/200, Total Reward: -129204.25, Win Rate: 0.52, Wins: 540, Losses: 501, Epsilon: 0.1249, Steps: 36754, Time: 124.80s\n",
      "Ações: Manter=14075, Comprar=11997, Vender=10682\n",
      "Ganhos Totais: 27996.75, Perdas Totais: -157201.00\n",
      "Episode 139/200, Total Reward: -100841.50, Win Rate: 0.49, Wins: 475, Losses: 490, Epsilon: 0.1237, Steps: 36754, Time: 124.94s\n",
      "Ações: Manter=14501, Comprar=12322, Vender=9931\n",
      "Ganhos Totais: 25961.75, Perdas Totais: -126803.25\n",
      "Modelo e log do episódio 139 salvos em: 4.11\\model_episode_139.pth e 4.11\\log_episode_139.csv\n",
      "\n",
      "Episode 140/200, Total Reward: -110588.25, Win Rate: 0.51, Wins: 533, Losses: 506, Epsilon: 0.1224, Steps: 36754, Time: 124.90s\n",
      "Ações: Manter=14201, Comprar=12373, Vender=10180\n",
      "Ganhos Totais: 27654.75, Perdas Totais: -138243.00\n",
      "Modelo e log do episódio 140 salvos em: 4.11\\model_episode_140.pth e 4.11\\log_episode_140.csv\n",
      "\n",
      "Episode 141/200, Total Reward: -119381.00, Win Rate: 0.52, Wins: 586, Losses: 532, Epsilon: 0.1212, Steps: 36754, Time: 125.01s\n",
      "Ações: Manter=12851, Comprar=12022, Vender=11881\n",
      "Ganhos Totais: 26433.75, Perdas Totais: -145814.75\n",
      "Modelo e log do episódio 141 salvos em: 4.11\\model_episode_141.pth e 4.11\\log_episode_141.csv\n",
      "\n",
      "Episode 142/200, Total Reward: -120099.25, Win Rate: 0.50, Wins: 526, Losses: 528, Epsilon: 0.1200, Steps: 36754, Time: 124.95s\n",
      "Ações: Manter=13646, Comprar=10148, Vender=12960\n",
      "Ganhos Totais: 27121.25, Perdas Totais: -147220.50\n",
      "Modelo e log do episódio 142 salvos em: 4.11\\model_episode_142.pth e 4.11\\log_episode_142.csv\n",
      "\n",
      "Episode 143/200, Total Reward: -95474.75, Win Rate: 0.55, Wins: 605, Losses: 496, Epsilon: 0.1188, Steps: 36754, Time: 124.88s\n",
      "Ações: Manter=14023, Comprar=11964, Vender=10767\n",
      "Ganhos Totais: 28655.00, Perdas Totais: -124129.75\n",
      "Modelo e log do episódio 143 salvos em: 4.11\\model_episode_143.pth e 4.11\\log_episode_143.csv\n",
      "\n",
      "Episode 144/200, Total Reward: -90073.00, Win Rate: 0.53, Wins: 527, Losses: 470, Epsilon: 0.1176, Steps: 36754, Time: 125.05s\n",
      "Ações: Manter=13669, Comprar=10711, Vender=12374\n",
      "Ganhos Totais: 28168.00, Perdas Totais: -118241.00\n",
      "Modelo e log do episódio 144 salvos em: 4.11\\model_episode_144.pth e 4.11\\log_episode_144.csv\n",
      "\n",
      "Episode 145/200, Total Reward: -114164.50, Win Rate: 0.52, Wins: 527, Losses: 485, Epsilon: 0.1164, Steps: 36754, Time: 125.12s\n",
      "Ações: Manter=13637, Comprar=12850, Vender=10267\n",
      "Ganhos Totais: 26497.75, Perdas Totais: -140662.25\n",
      "Modelo e log do episódio 145 salvos em: 4.11\\model_episode_145.pth e 4.11\\log_episode_145.csv\n",
      "\n",
      "Episode 146/200, Total Reward: -115939.00, Win Rate: 0.52, Wins: 518, Losses: 473, Epsilon: 0.1153, Steps: 36754, Time: 124.41s\n",
      "Ações: Manter=13468, Comprar=11984, Vender=11302\n",
      "Ganhos Totais: 26000.00, Perdas Totais: -141939.00\n",
      "Episode 147/200, Total Reward: -113237.75, Win Rate: 0.52, Wins: 481, Losses: 441, Epsilon: 0.1141, Steps: 36754, Time: 125.05s\n",
      "Ações: Manter=13410, Comprar=11247, Vender=12097\n",
      "Ganhos Totais: 25697.75, Perdas Totais: -138935.50\n",
      "Modelo e log do episódio 147 salvos em: 4.11\\model_episode_147.pth e 4.11\\log_episode_147.csv\n",
      "\n",
      "Episode 148/200, Total Reward: -100317.00, Win Rate: 0.53, Wins: 542, Losses: 478, Epsilon: 0.1130, Steps: 36754, Time: 125.34s\n",
      "Ações: Manter=14822, Comprar=11447, Vender=10485\n",
      "Ganhos Totais: 27785.25, Perdas Totais: -128102.25\n",
      "Modelo e log do episódio 148 salvos em: 4.11\\model_episode_148.pth e 4.11\\log_episode_148.csv\n",
      "\n",
      "Episode 149/200, Total Reward: -109622.00, Win Rate: 0.53, Wins: 548, Losses: 477, Epsilon: 0.1118, Steps: 36754, Time: 125.31s\n",
      "Ações: Manter=13125, Comprar=11483, Vender=12146\n",
      "Ganhos Totais: 27388.75, Perdas Totais: -137010.75\n",
      "Modelo e log do episódio 149 salvos em: 4.11\\model_episode_149.pth e 4.11\\log_episode_149.csv\n",
      "\n",
      "Episode 150/200, Total Reward: -108353.25, Win Rate: 0.55, Wins: 590, Losses: 481, Epsilon: 0.1107, Steps: 36754, Time: 124.90s\n",
      "Ações: Manter=13630, Comprar=12437, Vender=10687\n",
      "Ganhos Totais: 25739.50, Perdas Totais: -134092.75\n",
      "Modelo e log do episódio 150 salvos em: 4.11\\model_episode_150.pth e 4.11\\log_episode_150.csv\n",
      "\n",
      "Episode 151/200, Total Reward: -83037.75, Win Rate: 0.53, Wins: 492, Losses: 442, Epsilon: 0.1096, Steps: 36754, Time: 125.97s\n",
      "Ações: Manter=12583, Comprar=13339, Vender=10832\n",
      "Ganhos Totais: 30672.50, Perdas Totais: -113710.25\n",
      "Modelo e log do episódio 151 salvos em: 4.11\\model_episode_151.pth e 4.11\\log_episode_151.csv\n",
      "\n",
      "Episode 152/200, Total Reward: -110727.50, Win Rate: 0.51, Wins: 538, Losses: 513, Epsilon: 0.1085, Steps: 36754, Time: 124.73s\n",
      "Ações: Manter=14299, Comprar=11161, Vender=11294\n",
      "Ganhos Totais: 27579.25, Perdas Totais: -138306.75\n",
      "Episode 153/200, Total Reward: -113951.50, Win Rate: 0.55, Wins: 524, Losses: 437, Epsilon: 0.1074, Steps: 36754, Time: 124.98s\n",
      "Ações: Manter=14122, Comprar=11967, Vender=10665\n",
      "Ganhos Totais: 27430.50, Perdas Totais: -141382.00\n",
      "Episode 154/200, Total Reward: -106871.50, Win Rate: 0.52, Wins: 544, Losses: 497, Epsilon: 0.1064, Steps: 36754, Time: 124.49s\n",
      "Ações: Manter=13744, Comprar=11509, Vender=11501\n",
      "Ganhos Totais: 28430.25, Perdas Totais: -135301.75\n",
      "Modelo e log do episódio 154 salvos em: 4.11\\model_episode_154.pth e 4.11\\log_episode_154.csv\n",
      "\n",
      "Episode 155/200, Total Reward: -125010.25, Win Rate: 0.53, Wins: 552, Losses: 496, Epsilon: 0.1053, Steps: 36754, Time: 124.72s\n",
      "Ações: Manter=13810, Comprar=11758, Vender=11186\n",
      "Ganhos Totais: 26428.75, Perdas Totais: -151439.00\n",
      "Episode 156/200, Total Reward: -110544.00, Win Rate: 0.52, Wins: 542, Losses: 492, Epsilon: 0.1042, Steps: 36754, Time: 124.84s\n",
      "Ações: Manter=15199, Comprar=10941, Vender=10614\n",
      "Ganhos Totais: 28189.25, Perdas Totais: -138733.25\n",
      "Episode 157/200, Total Reward: -109638.75, Win Rate: 0.50, Wins: 465, Losses: 462, Epsilon: 0.1032, Steps: 36754, Time: 125.08s\n",
      "Ações: Manter=15600, Comprar=10730, Vender=10424\n",
      "Ganhos Totais: 23860.00, Perdas Totais: -133498.75\n",
      "Episode 158/200, Total Reward: -91180.00, Win Rate: 0.51, Wins: 473, Losses: 451, Epsilon: 0.1022, Steps: 36754, Time: 125.26s\n",
      "Ações: Manter=14141, Comprar=12253, Vender=10360\n",
      "Ganhos Totais: 26341.25, Perdas Totais: -117521.25\n",
      "Modelo e log do episódio 158 salvos em: 4.11\\model_episode_158.pth e 4.11\\log_episode_158.csv\n",
      "\n",
      "Episode 159/200, Total Reward: -116464.75, Win Rate: 0.53, Wins: 536, Losses: 482, Epsilon: 0.1012, Steps: 36754, Time: 125.18s\n",
      "Ações: Manter=15062, Comprar=10609, Vender=11083\n",
      "Ganhos Totais: 23798.75, Perdas Totais: -140263.50\n",
      "Episode 160/200, Total Reward: -100443.75, Win Rate: 0.52, Wins: 530, Losses: 488, Epsilon: 0.1001, Steps: 36754, Time: 125.35s\n",
      "Ações: Manter=15128, Comprar=10000, Vender=11626\n",
      "Ganhos Totais: 25567.50, Perdas Totais: -126011.25\n",
      "Modelo e log do episódio 160 salvos em: 4.11\\model_episode_160.pth e 4.11\\log_episode_160.csv\n",
      "\n",
      "Episode 161/200, Total Reward: -94863.50, Win Rate: 0.53, Wins: 516, Losses: 464, Epsilon: 0.0991, Steps: 36754, Time: 125.21s\n",
      "Ações: Manter=14459, Comprar=11422, Vender=10873\n",
      "Ganhos Totais: 27783.25, Perdas Totais: -122646.75\n",
      "Modelo e log do episódio 161 salvos em: 4.11\\model_episode_161.pth e 4.11\\log_episode_161.csv\n",
      "\n",
      "Episode 162/200, Total Reward: -67821.00, Win Rate: 0.60, Wins: 540, Losses: 367, Epsilon: 0.0981, Steps: 36754, Time: 125.23s\n",
      "Ações: Manter=12965, Comprar=12642, Vender=11147\n",
      "Ganhos Totais: 27782.00, Perdas Totais: -95603.00\n",
      "Modelo e log do episódio 162 salvos em: 4.11\\model_episode_162.pth e 4.11\\log_episode_162.csv\n",
      "\n",
      "Episode 163/200, Total Reward: -117184.75, Win Rate: 0.47, Wins: 394, Losses: 448, Epsilon: 0.0972, Steps: 36754, Time: 125.65s\n",
      "Ações: Manter=13303, Comprar=10195, Vender=13256\n",
      "Ganhos Totais: 21728.25, Perdas Totais: -138913.00\n",
      "Episode 164/200, Total Reward: -83998.75, Win Rate: 0.53, Wins: 511, Losses: 453, Epsilon: 0.0962, Steps: 36754, Time: 125.30s\n",
      "Ações: Manter=13022, Comprar=9913, Vender=13819\n",
      "Ganhos Totais: 29127.75, Perdas Totais: -113126.50\n",
      "Modelo e log do episódio 164 salvos em: 4.11\\model_episode_164.pth e 4.11\\log_episode_164.csv\n",
      "\n",
      "Episode 165/200, Total Reward: -94292.75, Win Rate: 0.53, Wins: 462, Losses: 405, Epsilon: 0.0952, Steps: 36754, Time: 125.06s\n",
      "Ações: Manter=15126, Comprar=11130, Vender=10498\n",
      "Ganhos Totais: 25345.00, Perdas Totais: -119637.75\n",
      "Modelo e log do episódio 165 salvos em: 4.11\\model_episode_165.pth e 4.11\\log_episode_165.csv\n",
      "\n",
      "Episode 166/200, Total Reward: -96343.75, Win Rate: 0.51, Wins: 432, Losses: 412, Epsilon: 0.0943, Steps: 36754, Time: 125.20s\n",
      "Ações: Manter=14128, Comprar=10931, Vender=11695\n",
      "Ganhos Totais: 23518.00, Perdas Totais: -119861.75\n",
      "Modelo e log do episódio 166 salvos em: 4.11\\model_episode_166.pth e 4.11\\log_episode_166.csv\n",
      "\n",
      "Episode 167/200, Total Reward: -93762.75, Win Rate: 0.49, Wins: 436, Losses: 455, Epsilon: 0.0933, Steps: 36754, Time: 125.76s\n",
      "Ações: Manter=14946, Comprar=9843, Vender=11965\n",
      "Ganhos Totais: 22873.50, Perdas Totais: -116636.25\n",
      "Modelo e log do episódio 167 salvos em: 4.11\\model_episode_167.pth e 4.11\\log_episode_167.csv\n",
      "\n",
      "Episode 168/200, Total Reward: -89856.00, Win Rate: 0.50, Wins: 465, Losses: 460, Epsilon: 0.0924, Steps: 36754, Time: 125.38s\n",
      "Ações: Manter=14179, Comprar=10273, Vender=12302\n",
      "Ganhos Totais: 24840.50, Perdas Totais: -114696.50\n",
      "Modelo e log do episódio 168 salvos em: 4.11\\model_episode_168.pth e 4.11\\log_episode_168.csv\n",
      "\n",
      "Episode 169/200, Total Reward: -88042.00, Win Rate: 0.53, Wins: 488, Losses: 440, Epsilon: 0.0915, Steps: 36754, Time: 124.86s\n",
      "Ações: Manter=15214, Comprar=10764, Vender=10776\n",
      "Ganhos Totais: 27909.50, Perdas Totais: -115951.50\n",
      "Modelo e log do episódio 169 salvos em: 4.11\\model_episode_169.pth e 4.11\\log_episode_169.csv\n",
      "\n",
      "Episode 170/200, Total Reward: -98989.00, Win Rate: 0.51, Wins: 469, Losses: 455, Epsilon: 0.0906, Steps: 36754, Time: 125.32s\n",
      "Ações: Manter=14805, Comprar=10299, Vender=11650\n",
      "Ganhos Totais: 23030.50, Perdas Totais: -122019.50\n",
      "Episode 171/200, Total Reward: -96116.50, Win Rate: 0.52, Wins: 472, Losses: 444, Epsilon: 0.0897, Steps: 36754, Time: 125.08s\n",
      "Ações: Manter=13544, Comprar=9120, Vender=14090\n",
      "Ganhos Totais: 25170.25, Perdas Totais: -121286.75\n",
      "Episode 172/200, Total Reward: -88058.50, Win Rate: 0.49, Wins: 450, Losses: 460, Epsilon: 0.0888, Steps: 36754, Time: 125.11s\n",
      "Ações: Manter=12778, Comprar=9722, Vender=14254\n",
      "Ganhos Totais: 25854.50, Perdas Totais: -113913.00\n",
      "Modelo e log do episódio 172 salvos em: 4.11\\model_episode_172.pth e 4.11\\log_episode_172.csv\n",
      "\n",
      "Episode 173/200, Total Reward: -83497.00, Win Rate: 0.50, Wins: 432, Losses: 435, Epsilon: 0.0879, Steps: 36754, Time: 124.89s\n",
      "Ações: Manter=13922, Comprar=8863, Vender=13969\n",
      "Ganhos Totais: 23124.00, Perdas Totais: -106621.00\n",
      "Modelo e log do episódio 173 salvos em: 4.11\\model_episode_173.pth e 4.11\\log_episode_173.csv\n",
      "\n",
      "Episode 174/200, Total Reward: -76640.00, Win Rate: 0.50, Wins: 419, Losses: 414, Epsilon: 0.0870, Steps: 36754, Time: 124.77s\n",
      "Ações: Manter=13111, Comprar=8775, Vender=14868\n",
      "Ganhos Totais: 24746.50, Perdas Totais: -101386.50\n",
      "Modelo e log do episódio 174 salvos em: 4.11\\model_episode_174.pth e 4.11\\log_episode_174.csv\n",
      "\n",
      "Episode 175/200, Total Reward: -91520.25, Win Rate: 0.51, Wins: 457, Losses: 431, Epsilon: 0.0861, Steps: 36754, Time: 125.17s\n",
      "Ações: Manter=11797, Comprar=9821, Vender=15136\n",
      "Ganhos Totais: 26118.75, Perdas Totais: -117639.00\n",
      "Episode 176/200, Total Reward: -83302.25, Win Rate: 0.51, Wins: 458, Losses: 435, Epsilon: 0.0853, Steps: 36754, Time: 125.10s\n",
      "Ações: Manter=13223, Comprar=8779, Vender=14752\n",
      "Ganhos Totais: 25872.50, Perdas Totais: -109174.75\n",
      "Modelo e log do episódio 176 salvos em: 4.11\\model_episode_176.pth e 4.11\\log_episode_176.csv\n",
      "\n",
      "Episode 177/200, Total Reward: -91638.75, Win Rate: 0.52, Wins: 465, Losses: 435, Epsilon: 0.0844, Steps: 36754, Time: 124.73s\n",
      "Ações: Manter=12663, Comprar=7426, Vender=16665\n",
      "Ganhos Totais: 28086.75, Perdas Totais: -119725.50\n",
      "Episode 178/200, Total Reward: -93577.75, Win Rate: 0.51, Wins: 486, Losses: 463, Epsilon: 0.0836, Steps: 36754, Time: 124.82s\n",
      "Ações: Manter=12826, Comprar=9770, Vender=14158\n",
      "Ganhos Totais: 28140.25, Perdas Totais: -121718.00\n",
      "Episode 179/200, Total Reward: -75858.75, Win Rate: 0.55, Wins: 505, Losses: 412, Epsilon: 0.0827, Steps: 36754, Time: 124.83s\n",
      "Ações: Manter=12276, Comprar=11366, Vender=13112\n",
      "Ganhos Totais: 25700.75, Perdas Totais: -101559.50\n",
      "Modelo e log do episódio 179 salvos em: 4.11\\model_episode_179.pth e 4.11\\log_episode_179.csv\n",
      "\n",
      "Episode 180/200, Total Reward: -67968.50, Win Rate: 0.50, Wins: 454, Losses: 457, Epsilon: 0.0819, Steps: 36754, Time: 125.24s\n",
      "Ações: Manter=12720, Comprar=8983, Vender=15051\n",
      "Ganhos Totais: 25426.00, Perdas Totais: -93394.50\n",
      "Modelo e log do episódio 180 salvos em: 4.11\\model_episode_180.pth e 4.11\\log_episode_180.csv\n",
      "\n",
      "Episode 181/200, Total Reward: -74972.25, Win Rate: 0.50, Wins: 437, Losses: 435, Epsilon: 0.0811, Steps: 36754, Time: 124.83s\n",
      "Ações: Manter=12216, Comprar=10455, Vender=14083\n",
      "Ganhos Totais: 24620.00, Perdas Totais: -99592.25\n",
      "Modelo e log do episódio 181 salvos em: 4.11\\model_episode_181.pth e 4.11\\log_episode_181.csv\n",
      "\n",
      "Episode 182/200, Total Reward: -83388.00, Win Rate: 0.53, Wins: 498, Losses: 438, Epsilon: 0.0803, Steps: 36754, Time: 124.89s\n",
      "Ações: Manter=15782, Comprar=12114, Vender=8858\n",
      "Ganhos Totais: 25759.25, Perdas Totais: -109147.25\n",
      "Modelo e log do episódio 182 salvos em: 4.11\\model_episode_182.pth e 4.11\\log_episode_182.csv\n",
      "\n",
      "Episode 183/200, Total Reward: -76306.00, Win Rate: 0.54, Wins: 496, Losses: 423, Epsilon: 0.0795, Steps: 36754, Time: 124.53s\n",
      "Ações: Manter=13304, Comprar=11389, Vender=12061\n",
      "Ganhos Totais: 25940.50, Perdas Totais: -102246.50\n",
      "Modelo e log do episódio 183 salvos em: 4.11\\model_episode_183.pth e 4.11\\log_episode_183.csv\n",
      "\n",
      "Episode 184/200, Total Reward: -70782.25, Win Rate: 0.55, Wins: 469, Losses: 389, Epsilon: 0.0787, Steps: 36754, Time: 124.51s\n",
      "Ações: Manter=14910, Comprar=9432, Vender=12412\n",
      "Ganhos Totais: 25131.50, Perdas Totais: -95913.75\n",
      "Modelo e log do episódio 184 salvos em: 4.11\\model_episode_184.pth e 4.11\\log_episode_184.csv\n",
      "\n",
      "Episode 185/200, Total Reward: -99752.25, Win Rate: 0.52, Wins: 475, Losses: 436, Epsilon: 0.0779, Steps: 36754, Time: 124.74s\n",
      "Ações: Manter=14552, Comprar=8588, Vender=13614\n",
      "Ganhos Totais: 25989.25, Perdas Totais: -125741.50\n",
      "Episode 186/200, Total Reward: -92628.50, Win Rate: 0.51, Wins: 446, Losses: 434, Epsilon: 0.0771, Steps: 36754, Time: 124.80s\n",
      "Ações: Manter=13937, Comprar=9795, Vender=13022\n",
      "Ganhos Totais: 25187.75, Perdas Totais: -117816.25\n",
      "Episode 187/200, Total Reward: -83495.75, Win Rate: 0.50, Wins: 402, Losses: 402, Epsilon: 0.0763, Steps: 36754, Time: 125.15s\n",
      "Ações: Manter=14336, Comprar=9955, Vender=12463\n",
      "Ganhos Totais: 23460.00, Perdas Totais: -106955.75\n",
      "Episode 188/200, Total Reward: -71382.00, Win Rate: 0.54, Wins: 479, Losses: 413, Epsilon: 0.0756, Steps: 36754, Time: 124.64s\n",
      "Ações: Manter=12039, Comprar=10701, Vender=14014\n",
      "Ganhos Totais: 27002.00, Perdas Totais: -98384.00\n",
      "Modelo e log do episódio 188 salvos em: 4.11\\model_episode_188.pth e 4.11\\log_episode_188.csv\n",
      "\n",
      "Episode 189/200, Total Reward: -73603.75, Win Rate: 0.54, Wins: 462, Losses: 386, Epsilon: 0.0748, Steps: 36754, Time: 126.11s\n",
      "Ações: Manter=14912, Comprar=11120, Vender=10722\n",
      "Ganhos Totais: 27068.00, Perdas Totais: -100671.75\n",
      "Modelo e log do episódio 189 salvos em: 4.11\\model_episode_189.pth e 4.11\\log_episode_189.csv\n",
      "\n",
      "Episode 190/200, Total Reward: -89366.25, Win Rate: 0.53, Wins: 479, Losses: 426, Epsilon: 0.0741, Steps: 36754, Time: 124.43s\n",
      "Ações: Manter=13473, Comprar=11506, Vender=11775\n",
      "Ganhos Totais: 25724.50, Perdas Totais: -115090.75\n",
      "Episode 191/200, Total Reward: -97902.00, Win Rate: 0.52, Wins: 477, Losses: 438, Epsilon: 0.0733, Steps: 36754, Time: 124.56s\n",
      "Ações: Manter=15899, Comprar=10578, Vender=10277\n",
      "Ganhos Totais: 25172.50, Perdas Totais: -123074.50\n",
      "Episode 192/200, Total Reward: -76160.00, Win Rate: 0.53, Wins: 447, Losses: 401, Epsilon: 0.0726, Steps: 36754, Time: 125.25s\n",
      "Ações: Manter=14986, Comprar=10759, Vender=11009\n",
      "Ganhos Totais: 25489.75, Perdas Totais: -101649.75\n",
      "Modelo e log do episódio 192 salvos em: 4.11\\model_episode_192.pth e 4.11\\log_episode_192.csv\n",
      "\n",
      "Episode 193/200, Total Reward: -83529.50, Win Rate: 0.52, Wins: 475, Losses: 447, Epsilon: 0.0719, Steps: 36754, Time: 124.72s\n",
      "Ações: Manter=15390, Comprar=10289, Vender=11075\n",
      "Ganhos Totais: 25890.25, Perdas Totais: -109419.75\n",
      "Episode 194/200, Total Reward: -74007.25, Win Rate: 0.54, Wins: 457, Losses: 390, Epsilon: 0.0712, Steps: 36754, Time: 124.96s\n",
      "Ações: Manter=13196, Comprar=9444, Vender=14114\n",
      "Ganhos Totais: 26510.00, Perdas Totais: -100517.25\n",
      "Modelo e log do episódio 194 salvos em: 4.11\\model_episode_194.pth e 4.11\\log_episode_194.csv\n",
      "\n",
      "Episode 195/200, Total Reward: -71446.50, Win Rate: 0.52, Wins: 434, Losses: 403, Epsilon: 0.0704, Steps: 36754, Time: 124.99s\n",
      "Ações: Manter=13151, Comprar=11694, Vender=11909\n",
      "Ganhos Totais: 25713.25, Perdas Totais: -97159.75\n",
      "Modelo e log do episódio 195 salvos em: 4.11\\model_episode_195.pth e 4.11\\log_episode_195.csv\n",
      "\n",
      "Episode 196/200, Total Reward: -79845.25, Win Rate: 0.48, Wins: 364, Losses: 401, Epsilon: 0.0697, Steps: 36754, Time: 124.84s\n",
      "Ações: Manter=13591, Comprar=11196, Vender=11967\n",
      "Ganhos Totais: 24136.75, Perdas Totais: -103982.00\n",
      "Episode 197/200, Total Reward: -73347.50, Win Rate: 0.48, Wins: 412, Losses: 441, Epsilon: 0.0690, Steps: 36754, Time: 125.01s\n",
      "Ações: Manter=12417, Comprar=11154, Vender=13183\n",
      "Ganhos Totais: 23352.00, Perdas Totais: -96699.50\n",
      "Modelo e log do episódio 197 salvos em: 4.11\\model_episode_197.pth e 4.11\\log_episode_197.csv\n",
      "\n",
      "Episode 198/200, Total Reward: -90479.00, Win Rate: 0.51, Wins: 443, Losses: 427, Epsilon: 0.0684, Steps: 36754, Time: 132.75s\n",
      "Ações: Manter=12546, Comprar=9847, Vender=14361\n",
      "Ganhos Totais: 23839.50, Perdas Totais: -114318.50\n",
      "Episode 199/200, Total Reward: -67849.25, Win Rate: 0.51, Wins: 384, Losses: 375, Epsilon: 0.0677, Steps: 36754, Time: 133.95s\n",
      "Ações: Manter=14279, Comprar=8438, Vender=14037\n",
      "Ganhos Totais: 22691.50, Perdas Totais: -90540.75\n",
      "Modelo e log do episódio 199 salvos em: 4.11\\model_episode_199.pth e 4.11\\log_episode_199.csv\n",
      "\n",
      "Episode 200/200, Total Reward: -72723.50, Win Rate: 0.53, Wins: 513, Losses: 446, Epsilon: 0.0670, Steps: 36754, Time: 125.80s\n",
      "Ações: Manter=13449, Comprar=11253, Vender=12052\n",
      "Ganhos Totais: 28187.75, Perdas Totais: -100911.25\n",
      "Modelo e log do episódio 200 salvos em: 4.11\\model_episode_200.pth e 4.11\\log_episode_200.csv\n",
      "\n",
      "\n",
      "Treinamento finalizado.\n",
      "Top 10 Melhores Episódios:\n",
      "Rank 1: Episode 162, Total Reward: -67821.00, Win Rate: 0.60, Wins: 540, Losses: 367, Ações: {0: 12965, 1: 12642, 2: 11147}, Steps: 36754, Time: 125.23s\n",
      "Rank 2: Episode 199, Total Reward: -67849.25, Win Rate: 0.51, Wins: 384, Losses: 375, Ações: {0: 14279, 1: 8438, 2: 14037}, Steps: 36754, Time: 133.95s\n",
      "Rank 3: Episode 180, Total Reward: -67968.50, Win Rate: 0.50, Wins: 454, Losses: 457, Ações: {0: 12720, 1: 8983, 2: 15051}, Steps: 36754, Time: 125.24s\n",
      "Rank 4: Episode 184, Total Reward: -70782.25, Win Rate: 0.55, Wins: 469, Losses: 389, Ações: {0: 14910, 1: 9432, 2: 12412}, Steps: 36754, Time: 124.51s\n",
      "Rank 5: Episode 188, Total Reward: -71382.00, Win Rate: 0.54, Wins: 479, Losses: 413, Ações: {0: 12039, 1: 10701, 2: 14014}, Steps: 36754, Time: 124.64s\n",
      "Rank 6: Episode 195, Total Reward: -71446.50, Win Rate: 0.52, Wins: 434, Losses: 403, Ações: {0: 13151, 1: 11694, 2: 11909}, Steps: 36754, Time: 124.99s\n",
      "Rank 7: Episode 200, Total Reward: -72723.50, Win Rate: 0.53, Wins: 513, Losses: 446, Ações: {0: 13449, 1: 11253, 2: 12052}, Steps: 36754, Time: 125.80s\n",
      "Rank 8: Episode 197, Total Reward: -73347.50, Win Rate: 0.48, Wins: 412, Losses: 441, Ações: {0: 12417, 1: 11154, 2: 13183}, Steps: 36754, Time: 125.01s\n",
      "Rank 9: Episode 189, Total Reward: -73603.75, Win Rate: 0.54, Wins: 462, Losses: 386, Ações: {0: 14912, 1: 11120, 2: 10722}, Steps: 36754, Time: 126.11s\n",
      "Rank 10: Episode 194, Total Reward: -74007.25, Win Rate: 0.54, Wins: 457, Losses: 390, Ações: {0: 13196, 1: 9444, 2: 14114}, Steps: 36754, Time: 124.96s\n"
     ]
    }
   ],
   "source": [
    "# Bloco 1: Preparar os Dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import os\n",
    "data = pd.read_csv('D:\\\\dados\\\\bar_M15_V02_data_01-01-2023_a_31-08-2024.csv')\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "# filtra o dataframe para pegar apenas o mês de 08 de 2024\n",
    "#data = data[(data['DateTime'] >= '2024-08-01') & (data['DateTime'] <= '2024-08-31')]\n",
    "\n",
    "# Criar a coluna \"Valor\", que é uma cópia de \"Close\" e não será normalizada\n",
    "data['Valor'] = data['Close']\n",
    "\n",
    "# Normalizar as colunas necessárias (exceto \"Valor\" e \"Gatilho\")\n",
    "scaler = MinMaxScaler()\n",
    "cols_to_normalize = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'PavioSuperior', 'PavioInferior',\n",
    "    'Corpo', 'Range','SMA4','SMA8','SMA12','SMA20', 'SMA50', 'SMA100', 'SMA200', 'StochasticoK',\n",
    "    'StochasticoD', 'RSI', 'MACD', 'MACDSignal', 'MACDHistogram','atr8','atr14','atr28'\n",
    "]\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "# Converter todos os valores para tipo float32 para evitar problemas de tipo\n",
    "data = data.astype({col: 'float32' for col in cols_to_normalize + ['Valor']})\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.current_step = 0\n",
    "        self.position = 0  # 0 = neutro, 1 = comprado, -1 = vendido\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None\n",
    "        self.entry_datetime = None  # Novo atributo para armazenar o DateTime de entrada\n",
    "        self.action_space = spaces.Discrete(3)  # 0 = Manter, 1 = Comprar, 2 = Vender\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(len(data.columns) - 3 + 1,), dtype=np.float32\n",
    "        )\n",
    "        self.trades = []  # Lista para armazenar as operações realizadas\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None\n",
    "        self.entry_datetime = None\n",
    "        self.trades = []\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = self.data.iloc[self.current_step].drop(['Valor', 'DateTime', 'Gatilho']).values\n",
    "        obs = np.append(obs, self.position)  # Incluir a posição atual na observação\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        done = self.current_step >= len(self.data) - 2  # Ajustado para evitar índice fora do intervalo\n",
    "        reward = 0\n",
    "        info = {}\n",
    "\n",
    "        # Obter o valor atual e o próximo valor\n",
    "        current_price = self.data['Valor'].iloc[self.current_step]\n",
    "        next_price = self.data['Valor'].iloc[self.current_step + 1]\n",
    "        price_change = next_price - current_price\n",
    "\n",
    "        # Obter o valor do gatilho no passo atual\n",
    "        gatilho = int(self.data['Gatilho'].iloc[self.current_step])\n",
    "\n",
    "        # Se o gatilho estiver ativo, o agente pode executar todas as ações\n",
    "        if gatilho == 1:\n",
    "            if action == 1:  # Comprar\n",
    "                if self.position == 0:\n",
    "                    self.position = 1  # Abrir posição comprada\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step\n",
    "                    self.entry_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime\n",
    "                    }\n",
    "                elif self.position == -1:\n",
    "                    # Fechar posição vendida\n",
    "                    self.exit_price = current_price\n",
    "                    profit = self.entry_price - self.exit_price - 0.25  # Ganho da posição vendida\n",
    "                    self.exit_step = self.current_step\n",
    "                    self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    # se o profit for negativo, multipliuca por 10\n",
    "                    if profit < 0:\n",
    "                        profit = profit * 10\n",
    "                    reward += profit\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_short',\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime,\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    })\n",
    "                    # Resetar posição\n",
    "                    self.position = 0\n",
    "                    self.entry_step = None\n",
    "                    self.entry_datetime = None\n",
    "            elif action == 2:  # Vender\n",
    "                if self.position == 0:\n",
    "                    self.position = -1  # Abrir posição vendida\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step\n",
    "                    self.entry_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime\n",
    "                    }\n",
    "                elif self.position == 1:\n",
    "                    # Fechar posição comprada\n",
    "                    self.exit_price = current_price\n",
    "                    profit = self.exit_price - self.entry_price - 0.25  # Ganho da posição comprada\n",
    "                    self.exit_step = self.current_step\n",
    "                    self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    # se o profit for negativo, multipliuca por 10\n",
    "                    if profit < 0:\n",
    "                        profit = profit * 10\n",
    "                    reward += profit\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_long',\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime,\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    })\n",
    "                    # Resetar posição\n",
    "                    self.position = 0\n",
    "                    self.entry_step = None\n",
    "                    self.entry_datetime = None\n",
    "            else:  # Manter\n",
    "                pass  # Nenhuma ação necessária\n",
    "        else:  # Gatilho == 0, nenhuma posição deve ser mantida\n",
    "            # Se há uma posição aberta, fechá-la\n",
    "            if self.position == 1:  # Fechar posição comprada\n",
    "                self.exit_price = current_price\n",
    "                profit = self.exit_price - self.entry_price - 0.25  # Ganho da posição comprada\n",
    "                self.exit_step = self.current_step\n",
    "                self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                reward += profit\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_long',\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                }\n",
    "                # Registrar a operação\n",
    "                self.trades.append({\n",
    "                    'type': 'buy',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'entry_datetime': self.entry_datetime,\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                })\n",
    "                # Resetar posição\n",
    "                self.position = 0\n",
    "                self.entry_step = None\n",
    "                self.entry_datetime = None\n",
    "            elif self.position == -1:  # Fechar posição vendida\n",
    "                self.exit_price = current_price\n",
    "                profit = self.entry_price - self.exit_price - 0.25  # Ganho da posição vendida\n",
    "                self.exit_step = self.current_step\n",
    "                self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                reward += profit\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_short',\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                }\n",
    "                # Registrar a operação\n",
    "                self.trades.append({\n",
    "                    'type': 'sell',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'entry_datetime': self.entry_datetime,\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                })\n",
    "                # Resetar posição\n",
    "                self.position = 0\n",
    "                self.entry_step = None\n",
    "                self.entry_datetime = None\n",
    "\n",
    "        # Atualizar o passo atual\n",
    "        self.current_step += 1\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        return obs, reward, done, info\n",
    "\n",
    "# Bloco 3: Criar o Agente DQN usando PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import random\n",
    "\n",
    "# Configurações do dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Criar o ambiente\n",
    "env = TradingEnv(data)\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Definir a rede DQN\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, obs_size, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(obs_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instanciar a rede\n",
    "q_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "# Definir o otimizador\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Hiperparâmetros para DQN\n",
    "memory_size = 10000\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "epsilon_start = 0.5\n",
    "epsilon_end = 0.05\n",
    "epsilon_decay = 0.99\n",
    "target_update = 10  # Atualizar a rede alvo a cada 10 episódios\n",
    "\n",
    "# Inicializar a memória de replay\n",
    "memory = collections.deque(maxlen=memory_size)\n",
    "\n",
    "# Função para selecionar ação usando epsilon-greedy\n",
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice([0, 1, 2])\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = q_net(state)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "# Bloco 4: Treinamento do Agente DQN com Salvamento dos Melhores Episódios Após Cada Episódio\n",
    "\n",
    "num_episodes = 200  # Defina o número de episódios de treinamento\n",
    "epsilon = epsilon_start\n",
    "best_episodes = []\n",
    "\n",
    "save_dir = \"4.11\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    start_time = time.time()\n",
    "    obs = env.reset()\n",
    "    obs = torch.FloatTensor(obs).unsqueeze(0).to(device)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    actions_count = {0: 0, 1: 0, 2: 0}\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    win_total = 0\n",
    "    lose_total = 0\n",
    "    trades = []\n",
    "    current_trade = None\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "\n",
    "        # Selecionar ação\n",
    "        action = select_action(obs, epsilon)\n",
    "\n",
    "        # Executar ação no ambiente\n",
    "        obs_next, reward, done, info = env.step(action)\n",
    "        obs_next = torch.FloatTensor(obs_next).unsqueeze(0).to(device)\n",
    "\n",
    "        # Armazenar na memória de replay\n",
    "        memory.append((obs, action, reward, obs_next, done))\n",
    "\n",
    "        # Atualizar o estado\n",
    "        obs = obs_next\n",
    "\n",
    "        # Atualizar contagem de ações\n",
    "        actions_count[action] += 1\n",
    "\n",
    "        # Processar informações de trade\n",
    "        if 'trade' in info:\n",
    "            trade_info = info['trade']\n",
    "            if trade_info['type'] in ['buy', 'sell']:\n",
    "                # Início de uma nova operação\n",
    "                current_trade = {\n",
    "                    'type': trade_info['type'],\n",
    "                    'entry_step': trade_info['entry_step'],\n",
    "                    'entry_price': trade_info['entry_price'],\n",
    "                    'entry_datetime': trade_info['entry_datetime'],\n",
    "                    'exit_step': None,\n",
    "                    'exit_price': None,\n",
    "                    'exit_datetime': None,\n",
    "                    'profit': None\n",
    "                }\n",
    "            elif trade_info['type'] in ['close_long', 'close_short']:\n",
    "                # Fechamento de uma operação existente\n",
    "                current_trade['exit_step'] = trade_info['exit_step']\n",
    "                current_trade['exit_price'] = trade_info['exit_price']\n",
    "                current_trade['exit_datetime'] = trade_info['exit_datetime']\n",
    "                current_trade['profit'] = trade_info['profit']\n",
    "                trades.append(current_trade.copy())\n",
    "                # Atualizar ganhos e perdas\n",
    "                if current_trade['profit'] > 0:\n",
    "                    wins += 1\n",
    "                    win_total += current_trade['profit']\n",
    "                elif current_trade['profit'] < 0:\n",
    "                    losses += 1\n",
    "                    lose_total += current_trade['profit']\n",
    "                # Atualizar recompensa total\n",
    "                total_reward += current_trade['profit']\n",
    "                current_trade = None\n",
    "\n",
    "        # Treinar a rede se a memória tiver tamanho suficiente\n",
    "        if len(memory) >= batch_size:\n",
    "            batch = random.sample(memory, batch_size)\n",
    "            states, actions_batch, rewards_batch, next_states, dones = zip(*batch)\n",
    "\n",
    "            states = torch.cat(states).to(device)\n",
    "            actions_batch = torch.tensor(actions_batch, dtype=torch.long, device=device).unsqueeze(1)\n",
    "            rewards_batch = torch.tensor(rewards_batch, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            next_states = torch.cat(next_states).to(device)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            # Computar Q-valor atual\n",
    "            q_values = q_net(states).gather(1, actions_batch)\n",
    "\n",
    "            # Computar Q-valor alvo usando a rede alvo\n",
    "            with torch.no_grad():\n",
    "                next_q_values = target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "            target_q_values = rewards_batch + gamma * next_q_values * (1 - dones)\n",
    "\n",
    "            # Calcular a perda\n",
    "            loss = nn.MSELoss()(q_values, target_q_values)\n",
    "\n",
    "            # Otimizar a rede\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Decaimento de epsilon\n",
    "    epsilon = max(epsilon_end, epsilon_decay * epsilon)\n",
    "\n",
    "    # Atualizar a rede alvo\n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    # Cálculo do tempo de treinamento do episódio\n",
    "    end_time = time.time()\n",
    "    episode_time = end_time - start_time\n",
    "\n",
    "    win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "    print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward:.2f}, Win Rate: {win_rate:.2f}, \"\n",
    "          f\"Wins: {wins}, Losses: {losses}, Epsilon: {epsilon:.4f}, Steps: {steps}, Time: {episode_time:.2f}s\")\n",
    "    print(f\"Ações: Manter={actions_count[0]}, Comprar={actions_count[1]}, Vender={actions_count[2]}\")\n",
    "    print(f\"Ganhos Totais: {win_total:.2f}, Perdas Totais: {lose_total:.2f}\")\n",
    "\n",
    "    # Salvar informações do episódio\n",
    "    episode_info = {\n",
    "        'episode': episode + 1,\n",
    "        'total_reward': total_reward,\n",
    "        'win_rate': win_rate,\n",
    "        'wins': wins,\n",
    "        'losses': losses,\n",
    "        'actions_count': actions_count.copy(),\n",
    "        'win_total': win_total,\n",
    "        'lose_total': lose_total,\n",
    "        'steps': steps,\n",
    "        'episode_time': episode_time,\n",
    "        'model_state_dict': q_net.state_dict(),\n",
    "        'trades': trades.copy()  # Salvar as operações do episódio\n",
    "    }\n",
    "\n",
    "    # Adicionar o episódio à lista e manter os top 10\n",
    "    best_episodes.append(episode_info)\n",
    "    best_episodes = sorted(best_episodes, key=lambda x: x['total_reward'], reverse=True)[:10]\n",
    "\n",
    "    # Salvar o modelo e log se o episódio for um dos top 10\n",
    "    if episode_info in best_episodes:\n",
    "        model_path = os.path.join(save_dir, f\"model_episode_{episode_info['episode']}.pth\")\n",
    "        torch.save(episode_info['model_state_dict'], model_path)\n",
    "        episode_info['model_path'] = model_path\n",
    "\n",
    "        # Salvar o log completo das operações\n",
    "        log_path = os.path.join(save_dir, f\"log_episode_{episode_info['episode']}.csv\")\n",
    "        trades_df = pd.DataFrame(episode_info['trades'])\n",
    "        trades_df.to_csv(log_path, index=False)\n",
    "        episode_info['log_path'] = log_path\n",
    "\n",
    "        print(f\"Modelo e log do episódio {episode_info['episode']} salvos em: {model_path} e {log_path}\\n\")\n",
    "\n",
    "print(\"\\nTreinamento finalizado.\")\n",
    "print(\"Top 10 Melhores Episódios:\")\n",
    "for idx, ep in enumerate(best_episodes, 1):\n",
    "    print(f\"Rank {idx}: Episode {ep['episode']}, Total Reward: {ep['total_reward']:.2f}, \"\n",
    "          f\"Win Rate: {ep['win_rate']:.2f}, Wins: {ep['wins']}, Losses: {ep['losses']}, \"\n",
    "          f\"Ações: {ep['actions_count']}, Steps: {ep['steps']}, Time: {ep['episode_time']:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
