{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/200, Total Reward: 33.75, Win Rate: 0.34, Wins: 2814, Losses: 5420, Epsilon: 0.4950, Steps: 36754, Time: 124.04s\n",
      "Ações: Manter=12571, Comprar=11737, Vender=12446\n",
      "Ganhos Totais: 46671.25, Perdas Totais: -46637.50\n",
      "\n",
      "Modelo e log do episódio 1 salvos em: 4.6\\model_episode_1.pth e 4.6\\log_episode_1.csv\n",
      "Episode 2/200, Total Reward: -2275.50, Win Rate: 0.34, Wins: 2611, Losses: 5164, Epsilon: 0.4900, Steps: 36754, Time: 123.73s\n",
      "Ações: Manter=11880, Comprar=12727, Vender=12147\n",
      "Ganhos Totais: 42724.25, Perdas Totais: -44999.75\n",
      "\n",
      "Modelo e log do episódio 2 salvos em: 4.6\\model_episode_2.pth e 4.6\\log_episode_2.csv\n",
      "Episode 3/200, Total Reward: -478.25, Win Rate: 0.34, Wins: 2615, Losses: 5124, Epsilon: 0.4851, Steps: 36754, Time: 119.40s\n",
      "Ações: Manter=13173, Comprar=12472, Vender=11109\n",
      "Ganhos Totais: 43378.25, Perdas Totais: -43856.50\n",
      "\n",
      "Modelo e log do episódio 3 salvos em: 4.6\\model_episode_3.pth e 4.6\\log_episode_3.csv\n",
      "Episode 4/200, Total Reward: -2323.00, Win Rate: 0.34, Wins: 2638, Losses: 5235, Epsilon: 0.4803, Steps: 36754, Time: 111.43s\n",
      "Ações: Manter=12277, Comprar=11923, Vender=12554\n",
      "Ganhos Totais: 41898.75, Perdas Totais: -44221.75\n",
      "\n",
      "Modelo e log do episódio 4 salvos em: 4.6\\model_episode_4.pth e 4.6\\log_episode_4.csv\n",
      "Episode 5/200, Total Reward: 1195.75, Win Rate: 0.35, Wins: 2753, Losses: 5156, Epsilon: 0.4755, Steps: 36754, Time: 112.34s\n",
      "Ações: Manter=14281, Comprar=11009, Vender=11464\n",
      "Ganhos Totais: 46840.50, Perdas Totais: -45644.75\n",
      "\n",
      "Modelo e log do episódio 5 salvos em: 4.6\\model_episode_5.pth e 4.6\\log_episode_5.csv\n",
      "Episode 6/200, Total Reward: -2218.25, Win Rate: 0.33, Wins: 2570, Losses: 5174, Epsilon: 0.4707, Steps: 36754, Time: 112.40s\n",
      "Ações: Manter=12416, Comprar=11342, Vender=12996\n",
      "Ganhos Totais: 42316.50, Perdas Totais: -44534.75\n",
      "\n",
      "Modelo e log do episódio 6 salvos em: 4.6\\model_episode_6.pth e 4.6\\log_episode_6.csv\n",
      "Episode 7/200, Total Reward: 1535.50, Win Rate: 0.35, Wins: 2845, Losses: 5283, Epsilon: 0.4660, Steps: 36754, Time: 112.54s\n",
      "Ações: Manter=15051, Comprar=10876, Vender=10827\n",
      "Ganhos Totais: 47945.50, Perdas Totais: -46410.00\n",
      "\n",
      "Modelo e log do episódio 7 salvos em: 4.6\\model_episode_7.pth e 4.6\\log_episode_7.csv\n",
      "Episode 8/200, Total Reward: -1826.25, Win Rate: 0.34, Wins: 2797, Losses: 5355, Epsilon: 0.4614, Steps: 36754, Time: 112.00s\n",
      "Ações: Manter=13227, Comprar=12939, Vender=10588\n",
      "Ganhos Totais: 45002.75, Perdas Totais: -46829.00\n",
      "\n",
      "Modelo e log do episódio 8 salvos em: 4.6\\model_episode_8.pth e 4.6\\log_episode_8.csv\n",
      "Episode 9/200, Total Reward: -2596.00, Win Rate: 0.33, Wins: 2558, Losses: 5257, Epsilon: 0.4568, Steps: 36754, Time: 112.35s\n",
      "Ações: Manter=12251, Comprar=12021, Vender=12482\n",
      "Ganhos Totais: 41482.25, Perdas Totais: -44078.25\n",
      "\n",
      "Modelo e log do episódio 9 salvos em: 4.6\\model_episode_9.pth e 4.6\\log_episode_9.csv\n",
      "Episode 10/200, Total Reward: 2114.25, Win Rate: 0.34, Wins: 2695, Losses: 5274, Epsilon: 0.4522, Steps: 36754, Time: 113.05s\n",
      "Ações: Manter=13150, Comprar=11366, Vender=12238\n",
      "Ganhos Totais: 45711.75, Perdas Totais: -43597.50\n",
      "\n",
      "Modelo e log do episódio 10 salvos em: 4.6\\model_episode_10.pth e 4.6\\log_episode_10.csv\n",
      "Episode 11/200, Total Reward: -1652.25, Win Rate: 0.32, Wins: 2546, Losses: 5348, Epsilon: 0.4477, Steps: 36754, Time: 114.19s\n",
      "Ações: Manter=11227, Comprar=14136, Vender=11391\n",
      "Ganhos Totais: 42595.50, Perdas Totais: -44247.75\n",
      "\n",
      "Modelo e log do episódio 11 salvos em: 4.6\\model_episode_11.pth e 4.6\\log_episode_11.csv\n",
      "Episode 12/200, Total Reward: -2080.50, Win Rate: 0.33, Wins: 2662, Losses: 5485, Epsilon: 0.4432, Steps: 36754, Time: 112.85s\n",
      "Ações: Manter=11375, Comprar=12779, Vender=12600\n",
      "Ganhos Totais: 43703.75, Perdas Totais: -45784.25\n",
      "\n",
      "Modelo e log do episódio 12 salvos em: 4.6\\model_episode_12.pth e 4.6\\log_episode_12.csv\n",
      "Episode 13/200, Total Reward: -4564.00, Win Rate: 0.33, Wins: 2610, Losses: 5220, Epsilon: 0.4388, Steps: 36754, Time: 113.10s\n",
      "Ações: Manter=13127, Comprar=12817, Vender=10810\n",
      "Ganhos Totais: 40737.75, Perdas Totais: -45301.75\n",
      "\n",
      "Episode 14/200, Total Reward: 1537.75, Win Rate: 0.35, Wins: 2658, Losses: 5018, Epsilon: 0.4344, Steps: 36754, Time: 112.49s\n",
      "Ações: Manter=13409, Comprar=12120, Vender=11225\n",
      "Ganhos Totais: 44860.25, Perdas Totais: -43322.50\n",
      "\n",
      "Modelo e log do episódio 14 salvos em: 4.6\\model_episode_14.pth e 4.6\\log_episode_14.csv\n",
      "Episode 15/200, Total Reward: 75.00, Win Rate: 0.34, Wins: 2759, Losses: 5351, Epsilon: 0.4300, Steps: 36754, Time: 112.55s\n",
      "Ações: Manter=11784, Comprar=11973, Vender=12997\n",
      "Ganhos Totais: 45380.25, Perdas Totais: -45305.25\n",
      "\n",
      "Modelo e log do episódio 15 salvos em: 4.6\\model_episode_15.pth e 4.6\\log_episode_15.csv\n",
      "Episode 16/200, Total Reward: -599.25, Win Rate: 0.33, Wins: 2683, Losses: 5334, Epsilon: 0.4257, Steps: 36754, Time: 112.93s\n",
      "Ações: Manter=13296, Comprar=13790, Vender=9668\n",
      "Ganhos Totais: 43977.25, Perdas Totais: -44576.50\n",
      "\n",
      "Modelo e log do episódio 16 salvos em: 4.6\\model_episode_16.pth e 4.6\\log_episode_16.csv\n",
      "Episode 17/200, Total Reward: -497.75, Win Rate: 0.34, Wins: 2668, Losses: 5190, Epsilon: 0.4215, Steps: 36754, Time: 113.29s\n",
      "Ações: Manter=14257, Comprar=12426, Vender=10071\n",
      "Ganhos Totais: 44227.50, Perdas Totais: -44725.25\n",
      "\n",
      "Modelo e log do episódio 17 salvos em: 4.6\\model_episode_17.pth e 4.6\\log_episode_17.csv\n",
      "Episode 18/200, Total Reward: -6497.75, Win Rate: 0.33, Wins: 2549, Losses: 5204, Epsilon: 0.4173, Steps: 36754, Time: 112.75s\n",
      "Ações: Manter=12265, Comprar=12315, Vender=12174\n",
      "Ganhos Totais: 39898.50, Perdas Totais: -46396.25\n",
      "\n",
      "Episode 19/200, Total Reward: -636.50, Win Rate: 0.33, Wins: 2561, Losses: 5123, Epsilon: 0.4131, Steps: 36754, Time: 113.48s\n",
      "Ações: Manter=13053, Comprar=12063, Vender=11638\n",
      "Ganhos Totais: 41623.00, Perdas Totais: -42259.50\n",
      "\n",
      "Modelo e log do episódio 19 salvos em: 4.6\\model_episode_19.pth e 4.6\\log_episode_19.csv\n",
      "Episode 20/200, Total Reward: 795.25, Win Rate: 0.35, Wins: 2677, Losses: 5034, Epsilon: 0.4090, Steps: 36754, Time: 113.79s\n",
      "Ações: Manter=15093, Comprar=10815, Vender=10846\n",
      "Ganhos Totais: 44510.25, Perdas Totais: -43715.00\n",
      "\n",
      "Modelo e log do episódio 20 salvos em: 4.6\\model_episode_20.pth e 4.6\\log_episode_20.csv\n",
      "Episode 21/200, Total Reward: -2180.75, Win Rate: 0.33, Wins: 2650, Losses: 5296, Epsilon: 0.4049, Steps: 36754, Time: 112.84s\n",
      "Ações: Manter=12683, Comprar=11289, Vender=12782\n",
      "Ganhos Totais: 43449.50, Perdas Totais: -45630.25\n",
      "\n",
      "Episode 22/200, Total Reward: -675.50, Win Rate: 0.34, Wins: 2583, Losses: 5047, Epsilon: 0.4008, Steps: 36754, Time: 113.46s\n",
      "Ações: Manter=11618, Comprar=10870, Vender=14266\n",
      "Ganhos Totais: 42874.50, Perdas Totais: -43550.00\n",
      "\n",
      "Episode 23/200, Total Reward: -3300.75, Win Rate: 0.32, Wins: 2416, Losses: 5129, Epsilon: 0.3968, Steps: 36754, Time: 113.19s\n",
      "Ações: Manter=9995, Comprar=12680, Vender=14079\n",
      "Ganhos Totais: 39223.00, Perdas Totais: -42523.75\n",
      "\n",
      "Episode 24/200, Total Reward: -2460.00, Win Rate: 0.34, Wins: 2642, Losses: 5218, Epsilon: 0.3928, Steps: 36754, Time: 112.26s\n",
      "Ações: Manter=9830, Comprar=11869, Vender=15055\n",
      "Ganhos Totais: 43669.50, Perdas Totais: -46129.50\n",
      "\n",
      "Episode 25/200, Total Reward: -841.75, Win Rate: 0.33, Wins: 2419, Losses: 5001, Epsilon: 0.3889, Steps: 36754, Time: 112.22s\n",
      "Ações: Manter=9602, Comprar=10607, Vender=16545\n",
      "Ganhos Totais: 41175.50, Perdas Totais: -42017.25\n",
      "\n",
      "Episode 26/200, Total Reward: -634.00, Win Rate: 0.35, Wins: 2789, Losses: 5068, Epsilon: 0.3850, Steps: 36754, Time: 114.10s\n",
      "Ações: Manter=14441, Comprar=9340, Vender=12973\n",
      "Ganhos Totais: 46990.75, Perdas Totais: -47624.75\n",
      "\n",
      "Episode 27/200, Total Reward: 111.25, Win Rate: 0.33, Wins: 2401, Losses: 4828, Epsilon: 0.3812, Steps: 36754, Time: 113.67s\n",
      "Ações: Manter=10857, Comprar=9414, Vender=16483\n",
      "Ganhos Totais: 40406.50, Perdas Totais: -40295.25\n",
      "\n",
      "Modelo e log do episódio 27 salvos em: 4.6\\model_episode_27.pth e 4.6\\log_episode_27.csv\n",
      "Episode 28/200, Total Reward: -3591.50, Win Rate: 0.34, Wins: 2514, Losses: 4908, Epsilon: 0.3774, Steps: 36754, Time: 113.78s\n",
      "Ações: Manter=10621, Comprar=12246, Vender=13887\n",
      "Ganhos Totais: 40379.25, Perdas Totais: -43970.75\n",
      "\n",
      "Episode 29/200, Total Reward: 202.00, Win Rate: 0.34, Wins: 2569, Losses: 4987, Epsilon: 0.3736, Steps: 36754, Time: 114.68s\n",
      "Ações: Manter=11286, Comprar=14083, Vender=11385\n",
      "Ganhos Totais: 42650.75, Perdas Totais: -42448.75\n",
      "\n",
      "Modelo e log do episódio 29 salvos em: 4.6\\model_episode_29.pth e 4.6\\log_episode_29.csv\n",
      "Episode 30/200, Total Reward: 2287.50, Win Rate: 0.36, Wins: 2740, Losses: 4908, Epsilon: 0.3699, Steps: 36754, Time: 115.08s\n",
      "Ações: Manter=15264, Comprar=8265, Vender=13225\n",
      "Ganhos Totais: 46760.00, Perdas Totais: -44472.50\n",
      "\n",
      "Modelo e log do episódio 30 salvos em: 4.6\\model_episode_30.pth e 4.6\\log_episode_30.csv\n",
      "Episode 31/200, Total Reward: -1159.75, Win Rate: 0.34, Wins: 2505, Losses: 4898, Epsilon: 0.3662, Steps: 36754, Time: 113.96s\n",
      "Ações: Manter=12284, Comprar=11369, Vender=13101\n",
      "Ganhos Totais: 41501.50, Perdas Totais: -42661.25\n",
      "\n",
      "Episode 32/200, Total Reward: 1937.25, Win Rate: 0.33, Wins: 2624, Losses: 5214, Epsilon: 0.3625, Steps: 36754, Time: 114.63s\n",
      "Ações: Manter=8702, Comprar=12446, Vender=15606\n",
      "Ganhos Totais: 45904.50, Perdas Totais: -43967.25\n",
      "\n",
      "Modelo e log do episódio 32 salvos em: 4.6\\model_episode_32.pth e 4.6\\log_episode_32.csv\n",
      "Episode 33/200, Total Reward: -2046.50, Win Rate: 0.35, Wins: 2807, Losses: 5106, Epsilon: 0.3589, Steps: 36754, Time: 114.77s\n",
      "Ações: Manter=13050, Comprar=14201, Vender=9503\n",
      "Ganhos Totais: 46120.50, Perdas Totais: -48167.00\n",
      "\n",
      "Episode 34/200, Total Reward: 2095.25, Win Rate: 0.34, Wins: 2525, Losses: 4974, Epsilon: 0.3553, Steps: 36754, Time: 113.90s\n",
      "Ações: Manter=9469, Comprar=11573, Vender=15712\n",
      "Ganhos Totais: 44158.75, Perdas Totais: -42063.50\n",
      "\n",
      "Modelo e log do episódio 34 salvos em: 4.6\\model_episode_34.pth e 4.6\\log_episode_34.csv\n",
      "Episode 35/200, Total Reward: -3336.75, Win Rate: 0.33, Wins: 2346, Losses: 4829, Epsilon: 0.3517, Steps: 36754, Time: 117.60s\n",
      "Ações: Manter=11248, Comprar=9565, Vender=15941\n",
      "Ganhos Totais: 38674.50, Perdas Totais: -42011.25\n",
      "\n",
      "Episode 36/200, Total Reward: 494.50, Win Rate: 0.35, Wins: 2503, Losses: 4677, Epsilon: 0.3482, Steps: 36754, Time: 111.61s\n",
      "Ações: Manter=12170, Comprar=10469, Vender=14115\n",
      "Ganhos Totais: 41804.25, Perdas Totais: -41309.75\n",
      "\n",
      "Modelo e log do episódio 36 salvos em: 4.6\\model_episode_36.pth e 4.6\\log_episode_36.csv\n",
      "Episode 37/200, Total Reward: -864.75, Win Rate: 0.35, Wins: 2677, Losses: 4978, Epsilon: 0.3447, Steps: 36754, Time: 112.16s\n",
      "Ações: Manter=12910, Comprar=12589, Vender=11255\n",
      "Ganhos Totais: 44013.75, Perdas Totais: -44878.50\n",
      "\n",
      "Episode 38/200, Total Reward: 1997.00, Win Rate: 0.35, Wins: 2538, Losses: 4724, Epsilon: 0.3413, Steps: 36754, Time: 112.75s\n",
      "Ações: Manter=12844, Comprar=9528, Vender=14382\n",
      "Ganhos Totais: 44111.25, Perdas Totais: -42114.25\n",
      "\n",
      "Modelo e log do episódio 38 salvos em: 4.6\\model_episode_38.pth e 4.6\\log_episode_38.csv\n",
      "Episode 39/200, Total Reward: -2763.50, Win Rate: 0.34, Wins: 2364, Losses: 4593, Epsilon: 0.3379, Steps: 36754, Time: 112.12s\n",
      "Ações: Manter=10130, Comprar=16326, Vender=10298\n",
      "Ganhos Totais: 39081.75, Perdas Totais: -41845.25\n",
      "\n",
      "Episode 40/200, Total Reward: -598.50, Win Rate: 0.34, Wins: 2416, Losses: 4770, Epsilon: 0.3345, Steps: 36754, Time: 111.78s\n",
      "Ações: Manter=11230, Comprar=13872, Vender=11652\n",
      "Ganhos Totais: 39351.00, Perdas Totais: -39949.50\n",
      "\n",
      "Episode 41/200, Total Reward: -344.00, Win Rate: 0.34, Wins: 2533, Losses: 5008, Epsilon: 0.3311, Steps: 36754, Time: 111.51s\n",
      "Ações: Manter=10354, Comprar=11905, Vender=14495\n",
      "Ganhos Totais: 42168.50, Perdas Totais: -42512.50\n",
      "\n",
      "Episode 42/200, Total Reward: -1731.50, Win Rate: 0.34, Wins: 2409, Losses: 4722, Epsilon: 0.3278, Steps: 36754, Time: 111.52s\n",
      "Ações: Manter=12216, Comprar=11008, Vender=13530\n",
      "Ganhos Totais: 40162.25, Perdas Totais: -41893.75\n",
      "\n",
      "Episode 43/200, Total Reward: -1831.75, Win Rate: 0.35, Wins: 2480, Losses: 4639, Epsilon: 0.3246, Steps: 36754, Time: 112.34s\n",
      "Ações: Manter=10622, Comprar=11781, Vender=14351\n",
      "Ganhos Totais: 40304.00, Perdas Totais: -42135.75\n",
      "\n",
      "Episode 44/200, Total Reward: -322.50, Win Rate: 0.35, Wins: 2589, Losses: 4852, Epsilon: 0.3213, Steps: 36754, Time: 111.77s\n",
      "Ações: Manter=11040, Comprar=15440, Vender=10274\n",
      "Ganhos Totais: 42392.75, Perdas Totais: -42715.25\n",
      "\n",
      "Episode 45/200, Total Reward: -1207.75, Win Rate: 0.32, Wins: 2179, Losses: 4637, Epsilon: 0.3181, Steps: 36754, Time: 111.53s\n",
      "Ações: Manter=8420, Comprar=11831, Vender=16503\n",
      "Ganhos Totais: 36942.00, Perdas Totais: -38149.75\n",
      "\n",
      "Episode 46/200, Total Reward: -1179.25, Win Rate: 0.34, Wins: 2461, Losses: 4839, Epsilon: 0.3149, Steps: 36754, Time: 112.05s\n",
      "Ações: Manter=12383, Comprar=7766, Vender=16605\n",
      "Ganhos Totais: 41759.25, Perdas Totais: -42938.50\n",
      "\n",
      "Episode 47/200, Total Reward: -1729.00, Win Rate: 0.32, Wins: 1941, Losses: 4072, Epsilon: 0.3118, Steps: 36754, Time: 111.60s\n",
      "Ações: Manter=7341, Comprar=8159, Vender=21254\n",
      "Ganhos Totais: 33490.00, Perdas Totais: -35219.00\n",
      "\n",
      "Episode 48/200, Total Reward: -2498.00, Win Rate: 0.34, Wins: 2168, Losses: 4217, Epsilon: 0.3086, Steps: 36754, Time: 111.62s\n",
      "Ações: Manter=8884, Comprar=9123, Vender=18747\n",
      "Ganhos Totais: 35516.75, Perdas Totais: -38014.75\n",
      "\n",
      "Episode 49/200, Total Reward: -2223.75, Win Rate: 0.32, Wins: 1998, Losses: 4256, Epsilon: 0.3056, Steps: 36754, Time: 112.68s\n",
      "Ações: Manter=8155, Comprar=14702, Vender=13897\n",
      "Ganhos Totais: 31932.50, Perdas Totais: -34156.25\n",
      "\n",
      "Episode 50/200, Total Reward: 531.75, Win Rate: 0.35, Wins: 2101, Losses: 3935, Epsilon: 0.3025, Steps: 36754, Time: 113.03s\n",
      "Ações: Manter=10387, Comprar=8510, Vender=17857\n",
      "Ganhos Totais: 35181.00, Perdas Totais: -34649.25\n",
      "\n",
      "Modelo e log do episódio 50 salvos em: 4.6\\model_episode_50.pth e 4.6\\log_episode_50.csv\n",
      "Episode 51/200, Total Reward: -1031.75, Win Rate: 0.35, Wins: 2313, Losses: 4390, Epsilon: 0.2995, Steps: 36754, Time: 112.47s\n",
      "Ações: Manter=12367, Comprar=8950, Vender=15437\n",
      "Ganhos Totais: 39623.25, Perdas Totais: -40655.00\n",
      "\n",
      "Episode 52/200, Total Reward: -1197.50, Win Rate: 0.35, Wins: 2440, Losses: 4511, Epsilon: 0.2965, Steps: 36754, Time: 112.73s\n",
      "Ações: Manter=12795, Comprar=9081, Vender=14878\n",
      "Ganhos Totais: 40833.50, Perdas Totais: -42031.00\n",
      "\n",
      "Episode 53/200, Total Reward: 131.25, Win Rate: 0.36, Wins: 2472, Losses: 4324, Epsilon: 0.2935, Steps: 36754, Time: 112.33s\n",
      "Ações: Manter=11522, Comprar=16207, Vender=9025\n",
      "Ganhos Totais: 40956.75, Perdas Totais: -40825.50\n",
      "\n",
      "Episode 54/200, Total Reward: 1086.25, Win Rate: 0.37, Wins: 2636, Losses: 4423, Epsilon: 0.2906, Steps: 36754, Time: 112.14s\n",
      "Ações: Manter=12553, Comprar=10151, Vender=14050\n",
      "Ganhos Totais: 45659.75, Perdas Totais: -44573.50\n",
      "\n",
      "Modelo e log do episódio 54 salvos em: 4.6\\model_episode_54.pth e 4.6\\log_episode_54.csv\n",
      "Episode 55/200, Total Reward: 2489.00, Win Rate: 0.38, Wins: 2962, Losses: 4920, Epsilon: 0.2877, Steps: 36754, Time: 112.30s\n",
      "Ações: Manter=13317, Comprar=9451, Vender=13986\n",
      "Ganhos Totais: 48614.00, Perdas Totais: -46125.00\n",
      "\n",
      "Modelo e log do episódio 55 salvos em: 4.6\\model_episode_55.pth e 4.6\\log_episode_55.csv\n",
      "Episode 56/200, Total Reward: -1114.00, Win Rate: 0.34, Wins: 2612, Losses: 5061, Epsilon: 0.2848, Steps: 36754, Time: 112.74s\n",
      "Ações: Manter=10643, Comprar=11603, Vender=14508\n",
      "Ganhos Totais: 42355.75, Perdas Totais: -43469.75\n",
      "\n",
      "Episode 57/200, Total Reward: -223.50, Win Rate: 0.35, Wins: 2277, Losses: 4278, Epsilon: 0.2820, Steps: 36754, Time: 112.39s\n",
      "Ações: Manter=10544, Comprar=7371, Vender=18839\n",
      "Ganhos Totais: 40112.50, Perdas Totais: -40336.00\n",
      "\n",
      "Episode 58/200, Total Reward: -1353.00, Win Rate: 0.36, Wins: 2537, Losses: 4546, Epsilon: 0.2791, Steps: 36754, Time: 113.44s\n",
      "Ações: Manter=10441, Comprar=11371, Vender=14942\n",
      "Ganhos Totais: 42874.00, Perdas Totais: -44227.00\n",
      "\n",
      "Episode 59/200, Total Reward: -302.50, Win Rate: 0.34, Wins: 2081, Losses: 4078, Epsilon: 0.2763, Steps: 36754, Time: 114.17s\n",
      "Ações: Manter=8976, Comprar=10796, Vender=16982\n",
      "Ganhos Totais: 36198.00, Perdas Totais: -36500.50\n",
      "\n",
      "Episode 60/200, Total Reward: 1417.00, Win Rate: 0.37, Wins: 2347, Losses: 3975, Epsilon: 0.2736, Steps: 36754, Time: 112.60s\n",
      "Ações: Manter=11113, Comprar=6609, Vender=19032\n",
      "Ganhos Totais: 40445.25, Perdas Totais: -39028.25\n",
      "\n",
      "Modelo e log do episódio 60 salvos em: 4.6\\model_episode_60.pth e 4.6\\log_episode_60.csv\n",
      "Episode 61/200, Total Reward: -2079.75, Win Rate: 0.34, Wins: 1927, Losses: 3766, Epsilon: 0.2708, Steps: 36754, Time: 112.62s\n",
      "Ações: Manter=7730, Comprar=11168, Vender=17856\n",
      "Ganhos Totais: 31396.25, Perdas Totais: -33476.00\n",
      "\n",
      "Episode 62/200, Total Reward: -1098.75, Win Rate: 0.33, Wins: 2059, Losses: 4243, Epsilon: 0.2681, Steps: 36754, Time: 113.67s\n",
      "Ações: Manter=8711, Comprar=10015, Vender=18028\n",
      "Ganhos Totais: 33921.25, Perdas Totais: -35020.00\n",
      "\n",
      "Episode 63/200, Total Reward: -1565.75, Win Rate: 0.36, Wins: 2289, Losses: 3998, Epsilon: 0.2655, Steps: 36754, Time: 112.96s\n",
      "Ações: Manter=12682, Comprar=6359, Vender=17713\n",
      "Ganhos Totais: 37956.25, Perdas Totais: -39522.00\n",
      "\n",
      "Episode 64/200, Total Reward: -219.25, Win Rate: 0.35, Wins: 2322, Losses: 4293, Epsilon: 0.2628, Steps: 36754, Time: 113.54s\n",
      "Ações: Manter=11768, Comprar=8508, Vender=16478\n",
      "Ganhos Totais: 39756.75, Perdas Totais: -39976.00\n",
      "\n",
      "Episode 65/200, Total Reward: -2040.75, Win Rate: 0.32, Wins: 1757, Losses: 3733, Epsilon: 0.2602, Steps: 36754, Time: 112.59s\n",
      "Ações: Manter=7872, Comprar=7761, Vender=21121\n",
      "Ganhos Totais: 29998.00, Perdas Totais: -32038.75\n",
      "\n",
      "Episode 66/200, Total Reward: 855.50, Win Rate: 0.35, Wins: 2058, Losses: 3893, Epsilon: 0.2576, Steps: 36754, Time: 113.31s\n",
      "Ações: Manter=10606, Comprar=10641, Vender=15507\n",
      "Ganhos Totais: 34153.00, Perdas Totais: -33297.50\n",
      "\n",
      "Episode 67/200, Total Reward: 151.25, Win Rate: 0.33, Wins: 1889, Losses: 3767, Epsilon: 0.2550, Steps: 36754, Time: 112.90s\n",
      "Ações: Manter=6751, Comprar=10435, Vender=19568\n",
      "Ganhos Totais: 31478.25, Perdas Totais: -31327.00\n",
      "\n",
      "Episode 68/200, Total Reward: 1449.00, Win Rate: 0.35, Wins: 1920, Losses: 3641, Epsilon: 0.2524, Steps: 36754, Time: 112.59s\n",
      "Ações: Manter=10330, Comprar=9467, Vender=16957\n",
      "Ganhos Totais: 33342.50, Perdas Totais: -31893.50\n",
      "\n",
      "Modelo e log do episódio 68 salvos em: 4.6\\model_episode_68.pth e 4.6\\log_episode_68.csv\n",
      "Episode 69/200, Total Reward: -2865.75, Win Rate: 0.36, Wins: 2491, Losses: 4385, Epsilon: 0.2499, Steps: 36754, Time: 112.68s\n",
      "Ações: Manter=15763, Comprar=8671, Vender=12320\n",
      "Ganhos Totais: 41036.75, Perdas Totais: -43902.50\n",
      "\n",
      "Episode 70/200, Total Reward: -246.25, Win Rate: 0.36, Wins: 2600, Losses: 4598, Epsilon: 0.2474, Steps: 36754, Time: 113.15s\n",
      "Ações: Manter=14058, Comprar=8268, Vender=14428\n",
      "Ganhos Totais: 43715.25, Perdas Totais: -43961.50\n",
      "\n",
      "Episode 71/200, Total Reward: 1922.50, Win Rate: 0.32, Wins: 2124, Losses: 4506, Epsilon: 0.2449, Steps: 36754, Time: 113.19s\n",
      "Ações: Manter=8243, Comprar=9848, Vender=18663\n",
      "Ganhos Totais: 37216.00, Perdas Totais: -35293.50\n",
      "\n",
      "Modelo e log do episódio 71 salvos em: 4.6\\model_episode_71.pth e 4.6\\log_episode_71.csv\n",
      "Episode 72/200, Total Reward: 1321.75, Win Rate: 0.39, Wins: 2406, Losses: 3836, Epsilon: 0.2425, Steps: 36754, Time: 113.43s\n",
      "Ações: Manter=13600, Comprar=11887, Vender=11267\n",
      "Ganhos Totais: 41438.50, Perdas Totais: -40116.75\n",
      "\n",
      "Episode 73/200, Total Reward: -3866.50, Win Rate: 0.36, Wins: 2149, Losses: 3784, Epsilon: 0.2401, Steps: 36754, Time: 113.39s\n",
      "Ações: Manter=13274, Comprar=5522, Vender=17958\n",
      "Ganhos Totais: 35884.25, Perdas Totais: -39750.75\n",
      "\n",
      "Episode 74/200, Total Reward: -428.00, Win Rate: 0.34, Wins: 2337, Losses: 4571, Epsilon: 0.2377, Steps: 36754, Time: 113.19s\n",
      "Ações: Manter=11592, Comprar=8687, Vender=16475\n",
      "Ganhos Totais: 38345.50, Perdas Totais: -38773.50\n",
      "\n",
      "Episode 75/200, Total Reward: -3204.25, Win Rate: 0.32, Wins: 1746, Losses: 3628, Epsilon: 0.2353, Steps: 36754, Time: 113.11s\n",
      "Ações: Manter=8325, Comprar=8489, Vender=19940\n",
      "Ganhos Totais: 27648.50, Perdas Totais: -30852.75\n",
      "\n",
      "Episode 76/200, Total Reward: 1456.25, Win Rate: 0.37, Wins: 2534, Losses: 4388, Epsilon: 0.2329, Steps: 36754, Time: 114.53s\n",
      "Ações: Manter=14170, Comprar=14125, Vender=8459\n",
      "Ganhos Totais: 42449.75, Perdas Totais: -40993.50\n",
      "\n",
      "Modelo e log do episódio 76 salvos em: 4.6\\model_episode_76.pth e 4.6\\log_episode_76.csv\n",
      "Episode 77/200, Total Reward: -209.00, Win Rate: 0.37, Wins: 2289, Losses: 3971, Epsilon: 0.2306, Steps: 36754, Time: 113.76s\n",
      "Ações: Manter=14036, Comprar=8748, Vender=13970\n",
      "Ganhos Totais: 40088.25, Perdas Totais: -40297.25\n",
      "\n",
      "Episode 78/200, Total Reward: -128.50, Win Rate: 0.35, Wins: 1949, Losses: 3579, Epsilon: 0.2283, Steps: 36754, Time: 113.16s\n",
      "Ações: Manter=9203, Comprar=9069, Vender=18482\n",
      "Ganhos Totais: 32869.50, Perdas Totais: -32998.00\n",
      "\n",
      "Episode 79/200, Total Reward: -1698.75, Win Rate: 0.33, Wins: 2105, Losses: 4270, Epsilon: 0.2260, Steps: 36754, Time: 113.92s\n",
      "Ações: Manter=9263, Comprar=9200, Vender=18291\n",
      "Ganhos Totais: 34789.00, Perdas Totais: -36487.75\n",
      "\n",
      "Episode 80/200, Total Reward: 2843.50, Win Rate: 0.38, Wins: 2496, Losses: 3997, Epsilon: 0.2238, Steps: 36754, Time: 113.20s\n",
      "Ações: Manter=13333, Comprar=10631, Vender=12790\n",
      "Ganhos Totais: 43915.75, Perdas Totais: -41072.25\n",
      "\n",
      "Modelo e log do episódio 80 salvos em: 4.6\\model_episode_80.pth e 4.6\\log_episode_80.csv\n",
      "Episode 81/200, Total Reward: -2182.50, Win Rate: 0.38, Wins: 2438, Losses: 3896, Epsilon: 0.2215, Steps: 36754, Time: 113.49s\n",
      "Ações: Manter=14402, Comprar=11087, Vender=11265\n",
      "Ganhos Totais: 40772.75, Perdas Totais: -42955.25\n",
      "\n",
      "Episode 82/200, Total Reward: -680.00, Win Rate: 0.34, Wins: 2074, Losses: 4040, Epsilon: 0.2193, Steps: 36754, Time: 113.01s\n",
      "Ações: Manter=9370, Comprar=9401, Vender=17983\n",
      "Ganhos Totais: 36290.75, Perdas Totais: -36970.75\n",
      "\n",
      "Episode 83/200, Total Reward: 1138.75, Win Rate: 0.39, Wins: 2584, Losses: 4059, Epsilon: 0.2171, Steps: 36754, Time: 113.79s\n",
      "Ações: Manter=15714, Comprar=10107, Vender=10933\n",
      "Ganhos Totais: 46560.75, Perdas Totais: -45422.00\n",
      "\n",
      "Episode 84/200, Total Reward: -1319.50, Win Rate: 0.36, Wins: 2067, Losses: 3681, Epsilon: 0.2149, Steps: 36754, Time: 113.72s\n",
      "Ações: Manter=12300, Comprar=10648, Vender=13806\n",
      "Ganhos Totais: 36301.75, Perdas Totais: -37621.25\n",
      "\n",
      "Episode 85/200, Total Reward: 531.75, Win Rate: 0.36, Wins: 2174, Losses: 3798, Epsilon: 0.2128, Steps: 36754, Time: 113.05s\n",
      "Ações: Manter=12218, Comprar=8630, Vender=15906\n",
      "Ganhos Totais: 35950.50, Perdas Totais: -35418.75\n",
      "\n",
      "Episode 86/200, Total Reward: 355.25, Win Rate: 0.33, Wins: 1736, Losses: 3478, Epsilon: 0.2107, Steps: 36754, Time: 113.52s\n",
      "Ações: Manter=8596, Comprar=12287, Vender=15871\n",
      "Ganhos Totais: 29342.00, Perdas Totais: -28986.75\n",
      "\n",
      "Episode 87/200, Total Reward: -416.00, Win Rate: 0.33, Wins: 1732, Losses: 3571, Epsilon: 0.2086, Steps: 36754, Time: 113.37s\n",
      "Ações: Manter=6447, Comprar=12965, Vender=17342\n",
      "Ganhos Totais: 31935.75, Perdas Totais: -32351.75\n",
      "\n",
      "Episode 88/200, Total Reward: 941.25, Win Rate: 0.36, Wins: 2006, Losses: 3556, Epsilon: 0.2065, Steps: 36754, Time: 112.97s\n",
      "Ações: Manter=9582, Comprar=9381, Vender=17791\n",
      "Ganhos Totais: 36403.50, Perdas Totais: -35462.25\n",
      "\n",
      "Episode 89/200, Total Reward: 1541.50, Win Rate: 0.35, Wins: 1685, Losses: 3071, Epsilon: 0.2044, Steps: 36754, Time: 113.93s\n",
      "Ações: Manter=8657, Comprar=11628, Vender=16469\n",
      "Ganhos Totais: 27257.25, Perdas Totais: -25715.75\n",
      "\n",
      "Modelo e log do episódio 89 salvos em: 4.6\\model_episode_89.pth e 4.6\\log_episode_89.csv\n",
      "Episode 90/200, Total Reward: -2647.00, Win Rate: 0.36, Wins: 2025, Losses: 3557, Epsilon: 0.2024, Steps: 36754, Time: 113.79s\n",
      "Ações: Manter=11305, Comprar=8609, Vender=16840\n",
      "Ganhos Totais: 33514.00, Perdas Totais: -36161.00\n",
      "\n",
      "Episode 91/200, Total Reward: 284.25, Win Rate: 0.36, Wins: 1834, Losses: 3290, Epsilon: 0.2003, Steps: 36754, Time: 113.18s\n",
      "Ações: Manter=7895, Comprar=15680, Vender=13179\n",
      "Ganhos Totais: 31475.00, Perdas Totais: -31190.75\n",
      "\n",
      "Episode 92/200, Total Reward: -1307.75, Win Rate: 0.37, Wins: 2016, Losses: 3435, Epsilon: 0.1983, Steps: 36754, Time: 114.00s\n",
      "Ações: Manter=11014, Comprar=9325, Vender=16415\n",
      "Ganhos Totais: 33671.25, Perdas Totais: -34979.00\n",
      "\n",
      "Episode 93/200, Total Reward: 2056.75, Win Rate: 0.38, Wins: 2391, Losses: 3983, Epsilon: 0.1964, Steps: 36754, Time: 113.71s\n",
      "Ações: Manter=13569, Comprar=6946, Vender=16239\n",
      "Ganhos Totais: 40299.75, Perdas Totais: -38243.00\n",
      "\n",
      "Modelo e log do episódio 93 salvos em: 4.6\\model_episode_93.pth e 4.6\\log_episode_93.csv\n",
      "Episode 94/200, Total Reward: 1330.00, Win Rate: 0.37, Wins: 2215, Losses: 3779, Epsilon: 0.1944, Steps: 36754, Time: 114.66s\n",
      "Ações: Manter=12935, Comprar=7155, Vender=16664\n",
      "Ganhos Totais: 39048.25, Perdas Totais: -37718.25\n",
      "\n",
      "Episode 95/200, Total Reward: 1632.00, Win Rate: 0.34, Wins: 2132, Losses: 4207, Epsilon: 0.1924, Steps: 36754, Time: 113.47s\n",
      "Ações: Manter=10616, Comprar=8311, Vender=17827\n",
      "Ganhos Totais: 37231.00, Perdas Totais: -35599.00\n",
      "\n",
      "Modelo e log do episódio 95 salvos em: 4.6\\model_episode_95.pth e 4.6\\log_episode_95.csv\n",
      "Episode 96/200, Total Reward: 2805.00, Win Rate: 0.35, Wins: 2214, Losses: 4061, Epsilon: 0.1905, Steps: 36754, Time: 114.72s\n",
      "Ações: Manter=11664, Comprar=5451, Vender=19639\n",
      "Ganhos Totais: 37905.00, Perdas Totais: -35100.00\n",
      "\n",
      "Modelo e log do episódio 96 salvos em: 4.6\\model_episode_96.pth e 4.6\\log_episode_96.csv\n",
      "Episode 97/200, Total Reward: 1693.50, Win Rate: 0.40, Wins: 2274, Losses: 3386, Epsilon: 0.1886, Steps: 36754, Time: 113.98s\n",
      "Ações: Manter=14032, Comprar=4939, Vender=17783\n",
      "Ganhos Totais: 38841.50, Perdas Totais: -37148.00\n",
      "\n",
      "Episode 98/200, Total Reward: 804.00, Win Rate: 0.39, Wins: 2015, Losses: 3164, Epsilon: 0.1867, Steps: 36754, Time: 113.68s\n",
      "Ações: Manter=10452, Comprar=8710, Vender=17592\n",
      "Ganhos Totais: 35689.50, Perdas Totais: -34885.50\n",
      "\n",
      "Episode 99/200, Total Reward: -2659.00, Win Rate: 0.37, Wins: 2031, Losses: 3386, Epsilon: 0.1849, Steps: 36754, Time: 113.96s\n",
      "Ações: Manter=10827, Comprar=8880, Vender=17047\n",
      "Ganhos Totais: 34192.75, Perdas Totais: -36851.75\n",
      "\n",
      "Episode 100/200, Total Reward: 1304.00, Win Rate: 0.36, Wins: 2154, Losses: 3851, Epsilon: 0.1830, Steps: 36754, Time: 113.99s\n",
      "Ações: Manter=12413, Comprar=7577, Vender=16764\n",
      "Ganhos Totais: 37406.25, Perdas Totais: -36102.25\n",
      "\n",
      "Episode 101/200, Total Reward: 2254.00, Win Rate: 0.36, Wins: 1905, Losses: 3399, Epsilon: 0.1812, Steps: 36754, Time: 113.59s\n",
      "Ações: Manter=6963, Comprar=8381, Vender=21410\n",
      "Ganhos Totais: 33084.00, Perdas Totais: -30830.00\n",
      "\n",
      "Modelo e log do episódio 101 salvos em: 4.6\\model_episode_101.pth e 4.6\\log_episode_101.csv\n",
      "Episode 102/200, Total Reward: -120.25, Win Rate: 0.34, Wins: 1834, Losses: 3619, Epsilon: 0.1794, Steps: 36754, Time: 113.83s\n",
      "Ações: Manter=6682, Comprar=4122, Vender=25950\n",
      "Ganhos Totais: 33774.00, Perdas Totais: -33894.25\n",
      "\n",
      "Episode 103/200, Total Reward: -1074.50, Win Rate: 0.34, Wins: 1954, Losses: 3800, Epsilon: 0.1776, Steps: 36754, Time: 114.29s\n",
      "Ações: Manter=10637, Comprar=5607, Vender=20510\n",
      "Ganhos Totais: 33181.25, Perdas Totais: -34255.75\n",
      "\n",
      "Episode 104/200, Total Reward: -1672.00, Win Rate: 0.39, Wins: 2473, Losses: 3893, Epsilon: 0.1758, Steps: 36754, Time: 114.18s\n",
      "Ações: Manter=11686, Comprar=7383, Vender=17685\n",
      "Ganhos Totais: 43674.75, Perdas Totais: -45346.75\n",
      "\n",
      "Episode 105/200, Total Reward: 1345.50, Win Rate: 0.34, Wins: 1867, Losses: 3685, Epsilon: 0.1740, Steps: 36754, Time: 114.31s\n",
      "Ações: Manter=6166, Comprar=8234, Vender=22354\n",
      "Ganhos Totais: 34632.00, Perdas Totais: -33286.50\n",
      "\n",
      "Episode 106/200, Total Reward: -602.75, Win Rate: 0.36, Wins: 1924, Losses: 3458, Epsilon: 0.1723, Steps: 36754, Time: 114.10s\n",
      "Ações: Manter=8018, Comprar=5555, Vender=23181\n",
      "Ganhos Totais: 36222.75, Perdas Totais: -36825.50\n",
      "\n",
      "Episode 107/200, Total Reward: -545.50, Win Rate: 0.36, Wins: 1902, Losses: 3326, Epsilon: 0.1706, Steps: 36754, Time: 114.59s\n",
      "Ações: Manter=11758, Comprar=4675, Vender=20321\n",
      "Ganhos Totais: 32837.50, Perdas Totais: -33383.00\n",
      "\n",
      "Episode 108/200, Total Reward: 1679.25, Win Rate: 0.36, Wins: 1962, Losses: 3512, Epsilon: 0.1689, Steps: 36754, Time: 114.15s\n",
      "Ações: Manter=9360, Comprar=6722, Vender=20672\n",
      "Ganhos Totais: 34785.75, Perdas Totais: -33106.50\n",
      "\n",
      "Episode 109/200, Total Reward: 1403.75, Win Rate: 0.38, Wins: 2097, Losses: 3396, Epsilon: 0.1672, Steps: 36754, Time: 114.60s\n",
      "Ações: Manter=11974, Comprar=3963, Vender=20817\n",
      "Ganhos Totais: 37720.25, Perdas Totais: -36316.50\n",
      "\n",
      "Episode 110/200, Total Reward: -789.50, Win Rate: 0.34, Wins: 1635, Losses: 3237, Epsilon: 0.1655, Steps: 36754, Time: 114.59s\n",
      "Ações: Manter=6633, Comprar=6932, Vender=23189\n",
      "Ganhos Totais: 26339.75, Perdas Totais: -27129.25\n",
      "\n",
      "Episode 111/200, Total Reward: -2512.00, Win Rate: 0.34, Wins: 1658, Losses: 3264, Epsilon: 0.1639, Steps: 36754, Time: 114.26s\n",
      "Ações: Manter=9073, Comprar=5010, Vender=22671\n",
      "Ganhos Totais: 25889.50, Perdas Totais: -28401.50\n",
      "\n",
      "Episode 112/200, Total Reward: 2939.25, Win Rate: 0.36, Wins: 1946, Losses: 3416, Epsilon: 0.1622, Steps: 36754, Time: 114.04s\n",
      "Ações: Manter=9246, Comprar=4789, Vender=22719\n",
      "Ganhos Totais: 35455.50, Perdas Totais: -32516.25\n",
      "\n",
      "Modelo e log do episódio 112 salvos em: 4.6\\model_episode_112.pth e 4.6\\log_episode_112.csv\n",
      "Episode 113/200, Total Reward: 2536.75, Win Rate: 0.35, Wins: 1661, Losses: 3133, Epsilon: 0.1606, Steps: 36754, Time: 115.38s\n",
      "Ações: Manter=8940, Comprar=5382, Vender=22432\n",
      "Ganhos Totais: 29072.00, Perdas Totais: -26535.25\n",
      "\n",
      "Modelo e log do episódio 113 salvos em: 4.6\\model_episode_113.pth e 4.6\\log_episode_113.csv\n",
      "Episode 114/200, Total Reward: -786.75, Win Rate: 0.35, Wins: 1891, Losses: 3445, Epsilon: 0.1590, Steps: 36754, Time: 113.68s\n",
      "Ações: Manter=11266, Comprar=4060, Vender=21428\n",
      "Ganhos Totais: 29825.25, Perdas Totais: -30612.00\n",
      "\n",
      "Episode 115/200, Total Reward: 2865.00, Win Rate: 0.38, Wins: 1968, Losses: 3168, Epsilon: 0.1574, Steps: 36754, Time: 114.08s\n",
      "Ações: Manter=15038, Comprar=6553, Vender=15163\n",
      "Ganhos Totais: 33233.50, Perdas Totais: -30368.50\n",
      "\n",
      "Modelo e log do episódio 115 salvos em: 4.6\\model_episode_115.pth e 4.6\\log_episode_115.csv\n",
      "Episode 116/200, Total Reward: 231.25, Win Rate: 0.42, Wins: 2633, Losses: 3709, Epsilon: 0.1558, Steps: 36754, Time: 114.16s\n",
      "Ações: Manter=14446, Comprar=2652, Vender=19656\n",
      "Ganhos Totais: 46494.00, Perdas Totais: -46262.75\n",
      "\n",
      "Episode 117/200, Total Reward: 1934.00, Win Rate: 0.38, Wins: 2102, Losses: 3400, Epsilon: 0.1543, Steps: 36754, Time: 114.64s\n",
      "Ações: Manter=12582, Comprar=4365, Vender=19807\n",
      "Ganhos Totais: 37234.00, Perdas Totais: -35300.00\n",
      "\n",
      "Episode 118/200, Total Reward: 1651.00, Win Rate: 0.36, Wins: 1940, Losses: 3404, Epsilon: 0.1527, Steps: 36754, Time: 113.88s\n",
      "Ações: Manter=9507, Comprar=6023, Vender=21224\n",
      "Ganhos Totais: 33452.25, Perdas Totais: -31801.25\n",
      "\n",
      "Episode 119/200, Total Reward: 111.50, Win Rate: 0.39, Wins: 2117, Losses: 3359, Epsilon: 0.1512, Steps: 36754, Time: 114.50s\n",
      "Ações: Manter=12683, Comprar=3949, Vender=20122\n",
      "Ganhos Totais: 35825.75, Perdas Totais: -35714.25\n",
      "\n",
      "Episode 120/200, Total Reward: 1328.75, Win Rate: 0.40, Wins: 2260, Losses: 3459, Epsilon: 0.1497, Steps: 36754, Time: 114.44s\n",
      "Ações: Manter=13020, Comprar=5980, Vender=17754\n",
      "Ganhos Totais: 42189.75, Perdas Totais: -40861.00\n",
      "\n",
      "Episode 121/200, Total Reward: 176.75, Win Rate: 0.31, Wins: 1255, Losses: 2803, Epsilon: 0.1482, Steps: 36754, Time: 114.06s\n",
      "Ações: Manter=4168, Comprar=6094, Vender=26492\n",
      "Ganhos Totais: 21785.00, Perdas Totais: -21608.25\n",
      "\n",
      "Episode 122/200, Total Reward: -1343.50, Win Rate: 0.34, Wins: 1463, Losses: 2842, Epsilon: 0.1467, Steps: 36754, Time: 114.25s\n",
      "Ações: Manter=8391, Comprar=5062, Vender=23301\n",
      "Ganhos Totais: 22535.75, Perdas Totais: -23879.25\n",
      "\n",
      "Episode 123/200, Total Reward: 1783.75, Win Rate: 0.37, Wins: 1979, Losses: 3363, Epsilon: 0.1452, Steps: 36754, Time: 114.87s\n",
      "Ações: Manter=8899, Comprar=4438, Vender=23417\n",
      "Ganhos Totais: 34263.50, Perdas Totais: -32479.75\n",
      "\n",
      "Episode 124/200, Total Reward: -2266.25, Win Rate: 0.35, Wins: 1729, Losses: 3186, Epsilon: 0.1438, Steps: 36754, Time: 114.16s\n",
      "Ações: Manter=7831, Comprar=8846, Vender=20077\n",
      "Ganhos Totais: 28331.75, Perdas Totais: -30598.00\n",
      "\n",
      "Episode 125/200, Total Reward: 621.25, Win Rate: 0.39, Wins: 2031, Losses: 3214, Epsilon: 0.1424, Steps: 36754, Time: 113.53s\n",
      "Ações: Manter=11061, Comprar=2674, Vender=23019\n",
      "Ganhos Totais: 36444.75, Perdas Totais: -35823.50\n",
      "\n",
      "Episode 126/200, Total Reward: 771.25, Win Rate: 0.33, Wins: 1659, Losses: 3310, Epsilon: 0.1409, Steps: 36754, Time: 115.15s\n",
      "Ações: Manter=8641, Comprar=3588, Vender=24525\n",
      "Ganhos Totais: 28454.75, Perdas Totais: -27683.50\n",
      "\n",
      "Episode 127/200, Total Reward: 896.50, Win Rate: 0.38, Wins: 2059, Losses: 3339, Epsilon: 0.1395, Steps: 36754, Time: 117.04s\n",
      "Ações: Manter=11117, Comprar=3121, Vender=22516\n",
      "Ganhos Totais: 34399.00, Perdas Totais: -33502.50\n",
      "\n",
      "Episode 128/200, Total Reward: 2306.00, Win Rate: 0.36, Wins: 1831, Losses: 3227, Epsilon: 0.1381, Steps: 36754, Time: 114.73s\n",
      "Ações: Manter=10040, Comprar=2799, Vender=23915\n",
      "Ganhos Totais: 31911.75, Perdas Totais: -29605.75\n",
      "\n",
      "Modelo e log do episódio 128 salvos em: 4.6\\model_episode_128.pth e 4.6\\log_episode_128.csv\n",
      "Episode 129/200, Total Reward: -15.50, Win Rate: 0.39, Wins: 2340, Losses: 3691, Epsilon: 0.1367, Steps: 36754, Time: 115.11s\n",
      "Ações: Manter=11667, Comprar=4323, Vender=20764\n",
      "Ganhos Totais: 40009.75, Perdas Totais: -40025.25\n",
      "\n",
      "Episode 130/200, Total Reward: 4319.25, Win Rate: 0.42, Wins: 2713, Losses: 3784, Epsilon: 0.1354, Steps: 36754, Time: 114.59s\n",
      "Ações: Manter=14407, Comprar=4429, Vender=17918\n",
      "Ganhos Totais: 50243.50, Perdas Totais: -45924.25\n",
      "\n",
      "Modelo e log do episódio 130 salvos em: 4.6\\model_episode_130.pth e 4.6\\log_episode_130.csv\n",
      "Episode 131/200, Total Reward: 3004.50, Win Rate: 0.42, Wins: 2334, Losses: 3243, Epsilon: 0.1340, Steps: 36754, Time: 114.05s\n",
      "Ações: Manter=13041, Comprar=1821, Vender=21892\n",
      "Ganhos Totais: 43186.75, Perdas Totais: -40182.25\n",
      "\n",
      "Modelo e log do episódio 131 salvos em: 4.6\\model_episode_131.pth e 4.6\\log_episode_131.csv\n",
      "Episode 132/200, Total Reward: 323.25, Win Rate: 0.39, Wins: 1839, Losses: 2916, Epsilon: 0.1327, Steps: 36754, Time: 114.33s\n",
      "Ações: Manter=10514, Comprar=4019, Vender=22221\n",
      "Ganhos Totais: 32363.00, Perdas Totais: -32039.75\n",
      "\n",
      "Episode 133/200, Total Reward: 3235.00, Win Rate: 0.39, Wins: 1994, Losses: 3142, Epsilon: 0.1314, Steps: 36754, Time: 114.69s\n",
      "Ações: Manter=7672, Comprar=6140, Vender=22942\n",
      "Ganhos Totais: 37737.50, Perdas Totais: -34502.50\n",
      "\n",
      "Modelo e log do episódio 133 salvos em: 4.6\\model_episode_133.pth e 4.6\\log_episode_133.csv\n",
      "Episode 134/200, Total Reward: 4317.50, Win Rate: 0.41, Wins: 2137, Losses: 3086, Epsilon: 0.1300, Steps: 36754, Time: 115.48s\n",
      "Ações: Manter=11212, Comprar=1873, Vender=23669\n",
      "Ganhos Totais: 40723.25, Perdas Totais: -36405.75\n",
      "\n",
      "Modelo e log do episódio 134 salvos em: 4.6\\model_episode_134.pth e 4.6\\log_episode_134.csv\n",
      "Episode 135/200, Total Reward: 1826.75, Win Rate: 0.42, Wins: 2839, Losses: 3864, Epsilon: 0.1287, Steps: 36754, Time: 114.75s\n",
      "Ações: Manter=13227, Comprar=2810, Vender=20717\n",
      "Ganhos Totais: 52509.75, Perdas Totais: -50683.00\n",
      "\n",
      "Episode 136/200, Total Reward: 874.75, Win Rate: 0.38, Wins: 1876, Losses: 3123, Epsilon: 0.1275, Steps: 36754, Time: 115.93s\n",
      "Ações: Manter=5651, Comprar=2296, Vender=28807\n",
      "Ganhos Totais: 34682.75, Perdas Totais: -33808.00\n",
      "\n",
      "Episode 137/200, Total Reward: 1196.50, Win Rate: 0.42, Wins: 2632, Losses: 3628, Epsilon: 0.1262, Steps: 36754, Time: 114.81s\n",
      "Ações: Manter=15087, Comprar=4177, Vender=17490\n",
      "Ganhos Totais: 47541.00, Perdas Totais: -46344.50\n",
      "\n",
      "Episode 138/200, Total Reward: 306.00, Win Rate: 0.39, Wins: 2075, Losses: 3221, Epsilon: 0.1249, Steps: 36754, Time: 114.79s\n",
      "Ações: Manter=9367, Comprar=6473, Vender=20914\n",
      "Ganhos Totais: 38617.00, Perdas Totais: -38311.00\n",
      "\n",
      "Episode 139/200, Total Reward: 1121.50, Win Rate: 0.38, Wins: 1883, Losses: 3060, Epsilon: 0.1237, Steps: 36754, Time: 115.37s\n",
      "Ações: Manter=9002, Comprar=2293, Vender=25459\n",
      "Ganhos Totais: 34901.75, Perdas Totais: -33780.25\n",
      "\n",
      "Episode 140/200, Total Reward: 1856.00, Win Rate: 0.41, Wins: 2409, Losses: 3455, Epsilon: 0.1224, Steps: 36754, Time: 114.72s\n",
      "Ações: Manter=10673, Comprar=4343, Vender=21738\n",
      "Ganhos Totais: 43534.25, Perdas Totais: -41678.25\n",
      "\n",
      "Episode 141/200, Total Reward: -933.25, Win Rate: 0.34, Wins: 1229, Losses: 2346, Epsilon: 0.1212, Steps: 36754, Time: 114.44s\n",
      "Ações: Manter=3290, Comprar=1849, Vender=31615\n",
      "Ganhos Totais: 21774.25, Perdas Totais: -22707.50\n",
      "\n",
      "Episode 142/200, Total Reward: -250.50, Win Rate: 0.37, Wins: 1644, Losses: 2786, Epsilon: 0.1200, Steps: 36754, Time: 115.02s\n",
      "Ações: Manter=6727, Comprar=5448, Vender=24579\n",
      "Ganhos Totais: 30808.00, Perdas Totais: -31058.50\n",
      "\n",
      "Episode 143/200, Total Reward: 646.75, Win Rate: 0.39, Wins: 1906, Losses: 3005, Epsilon: 0.1188, Steps: 36754, Time: 114.83s\n",
      "Ações: Manter=7323, Comprar=5498, Vender=23933\n",
      "Ganhos Totais: 35777.75, Perdas Totais: -35131.00\n",
      "\n",
      "Episode 144/200, Total Reward: 238.50, Win Rate: 0.38, Wins: 1707, Losses: 2802, Epsilon: 0.1176, Steps: 36754, Time: 115.57s\n",
      "Ações: Manter=7951, Comprar=4933, Vender=23870\n",
      "Ganhos Totais: 30167.75, Perdas Totais: -29929.25\n",
      "\n",
      "Episode 145/200, Total Reward: -1431.25, Win Rate: 0.40, Wins: 2083, Losses: 3174, Epsilon: 0.1164, Steps: 36754, Time: 115.22s\n",
      "Ações: Manter=8974, Comprar=1905, Vender=25875\n",
      "Ganhos Totais: 37637.00, Perdas Totais: -39068.25\n",
      "\n",
      "Episode 146/200, Total Reward: 1181.75, Win Rate: 0.41, Wins: 2188, Losses: 3195, Epsilon: 0.1153, Steps: 36754, Time: 114.70s\n",
      "Ações: Manter=10641, Comprar=1504, Vender=24609\n",
      "Ganhos Totais: 42629.75, Perdas Totais: -41448.00\n",
      "\n",
      "Episode 147/200, Total Reward: -577.75, Win Rate: 0.41, Wins: 2409, Losses: 3460, Epsilon: 0.1141, Steps: 36754, Time: 115.00s\n",
      "Ações: Manter=11198, Comprar=1977, Vender=23579\n",
      "Ganhos Totais: 45819.75, Perdas Totais: -46397.50\n",
      "\n",
      "Episode 148/200, Total Reward: -1539.50, Win Rate: 0.40, Wins: 2345, Losses: 3448, Epsilon: 0.1130, Steps: 36754, Time: 114.79s\n",
      "Ações: Manter=11065, Comprar=1744, Vender=23945\n",
      "Ganhos Totais: 43872.00, Perdas Totais: -45411.50\n",
      "\n",
      "Episode 149/200, Total Reward: -37.75, Win Rate: 0.38, Wins: 1715, Losses: 2766, Epsilon: 0.1118, Steps: 36754, Time: 114.73s\n",
      "Ações: Manter=6661, Comprar=1992, Vender=28101\n",
      "Ganhos Totais: 33642.50, Perdas Totais: -33680.25\n",
      "\n",
      "Episode 150/200, Total Reward: -2233.25, Win Rate: 0.39, Wins: 2058, Losses: 3245, Epsilon: 0.1107, Steps: 36754, Time: 114.53s\n",
      "Ações: Manter=8727, Comprar=4900, Vender=23127\n",
      "Ganhos Totais: 37428.00, Perdas Totais: -39661.25\n",
      "\n",
      "Episode 151/200, Total Reward: -2204.50, Win Rate: 0.40, Wins: 2289, Losses: 3416, Epsilon: 0.1096, Steps: 36754, Time: 114.87s\n",
      "Ações: Manter=9893, Comprar=1980, Vender=24881\n",
      "Ganhos Totais: 40926.25, Perdas Totais: -43130.75\n",
      "\n",
      "Episode 152/200, Total Reward: -842.50, Win Rate: 0.37, Wins: 1508, Losses: 2526, Epsilon: 0.1085, Steps: 36754, Time: 114.88s\n",
      "Ações: Manter=6510, Comprar=1834, Vender=28410\n",
      "Ganhos Totais: 26885.75, Perdas Totais: -27728.25\n",
      "\n",
      "Episode 153/200, Total Reward: 1317.00, Win Rate: 0.40, Wins: 2012, Losses: 2985, Epsilon: 0.1074, Steps: 36754, Time: 114.49s\n",
      "Ações: Manter=8164, Comprar=1593, Vender=26997\n",
      "Ganhos Totais: 39508.50, Perdas Totais: -38191.50\n",
      "\n",
      "Episode 154/200, Total Reward: -971.25, Win Rate: 0.35, Wins: 1173, Losses: 2183, Epsilon: 0.1064, Steps: 36754, Time: 114.27s\n",
      "Ações: Manter=3529, Comprar=1547, Vender=31678\n",
      "Ganhos Totais: 23712.50, Perdas Totais: -24683.75\n",
      "\n",
      "Episode 155/200, Total Reward: -920.75, Win Rate: 0.39, Wins: 1680, Losses: 2669, Epsilon: 0.1053, Steps: 36754, Time: 114.67s\n",
      "Ações: Manter=8642, Comprar=1468, Vender=26644\n",
      "Ganhos Totais: 32693.75, Perdas Totais: -33614.50\n",
      "\n",
      "Episode 156/200, Total Reward: 503.50, Win Rate: 0.40, Wins: 2154, Losses: 3178, Epsilon: 0.1042, Steps: 36754, Time: 115.07s\n",
      "Ações: Manter=9382, Comprar=1601, Vender=25771\n",
      "Ganhos Totais: 40881.00, Perdas Totais: -40377.50\n",
      "\n",
      "Episode 157/200, Total Reward: 355.50, Win Rate: 0.34, Wins: 1206, Losses: 2362, Epsilon: 0.1032, Steps: 36754, Time: 115.25s\n",
      "Ações: Manter=3249, Comprar=2695, Vender=30810\n",
      "Ganhos Totais: 23730.25, Perdas Totais: -23374.75\n",
      "\n",
      "Episode 158/200, Total Reward: -1513.25, Win Rate: 0.40, Wins: 1927, Losses: 2881, Epsilon: 0.1022, Steps: 36754, Time: 114.95s\n",
      "Ações: Manter=9189, Comprar=1518, Vender=26047\n",
      "Ganhos Totais: 33265.50, Perdas Totais: -34778.75\n",
      "\n",
      "Episode 159/200, Total Reward: 353.75, Win Rate: 0.39, Wins: 1895, Losses: 2906, Epsilon: 0.1012, Steps: 36754, Time: 115.90s\n",
      "Ações: Manter=6665, Comprar=2830, Vender=27259\n",
      "Ganhos Totais: 35066.75, Perdas Totais: -34713.00\n",
      "\n",
      "Episode 160/200, Total Reward: 223.75, Win Rate: 0.40, Wins: 1751, Losses: 2615, Epsilon: 0.1001, Steps: 36754, Time: 115.27s\n",
      "Ações: Manter=8380, Comprar=1567, Vender=26807\n",
      "Ganhos Totais: 32662.25, Perdas Totais: -32438.50\n",
      "\n",
      "Episode 161/200, Total Reward: -1028.00, Win Rate: 0.40, Wins: 1951, Losses: 2916, Epsilon: 0.0991, Steps: 36754, Time: 115.71s\n",
      "Ações: Manter=7574, Comprar=1630, Vender=27550\n",
      "Ganhos Totais: 34449.00, Perdas Totais: -35477.00\n",
      "\n",
      "Episode 162/200, Total Reward: 552.50, Win Rate: 0.39, Wins: 1952, Losses: 3051, Epsilon: 0.0981, Steps: 36754, Time: 115.36s\n",
      "Ações: Manter=7503, Comprar=4595, Vender=24656\n",
      "Ganhos Totais: 37694.00, Perdas Totais: -37141.50\n",
      "\n",
      "Episode 163/200, Total Reward: -504.50, Win Rate: 0.39, Wins: 1738, Losses: 2689, Epsilon: 0.0972, Steps: 36754, Time: 115.26s\n",
      "Ações: Manter=6618, Comprar=5124, Vender=25012\n",
      "Ganhos Totais: 31592.50, Perdas Totais: -32097.00\n",
      "\n",
      "Episode 164/200, Total Reward: 2079.50, Win Rate: 0.40, Wins: 1917, Losses: 2830, Epsilon: 0.0962, Steps: 36754, Time: 114.71s\n",
      "Ações: Manter=7546, Comprar=4959, Vender=24249\n",
      "Ganhos Totais: 37456.50, Perdas Totais: -35377.00\n",
      "\n",
      "Episode 165/200, Total Reward: 936.75, Win Rate: 0.41, Wins: 2119, Losses: 3050, Epsilon: 0.0952, Steps: 36754, Time: 115.83s\n",
      "Ações: Manter=8782, Comprar=2938, Vender=25034\n",
      "Ganhos Totais: 39765.75, Perdas Totais: -38829.00\n",
      "\n",
      "Episode 166/200, Total Reward: -284.75, Win Rate: 0.39, Wins: 1562, Losses: 2479, Epsilon: 0.0943, Steps: 36754, Time: 115.69s\n",
      "Ações: Manter=7259, Comprar=2788, Vender=26707\n",
      "Ganhos Totais: 28932.00, Perdas Totais: -29216.75\n",
      "\n",
      "Episode 167/200, Total Reward: 2180.00, Win Rate: 0.41, Wins: 2143, Losses: 3056, Epsilon: 0.0933, Steps: 36754, Time: 115.31s\n",
      "Ações: Manter=11097, Comprar=1839, Vender=23818\n",
      "Ganhos Totais: 42322.25, Perdas Totais: -40142.25\n",
      "\n",
      "Episode 168/200, Total Reward: 562.25, Win Rate: 0.39, Wins: 1635, Losses: 2550, Epsilon: 0.0924, Steps: 36754, Time: 115.43s\n",
      "Ações: Manter=6251, Comprar=2631, Vender=27872\n",
      "Ganhos Totais: 30633.25, Perdas Totais: -30071.00\n",
      "\n",
      "Episode 169/200, Total Reward: -577.25, Win Rate: 0.39, Wins: 1795, Losses: 2791, Epsilon: 0.0915, Steps: 36754, Time: 115.82s\n",
      "Ações: Manter=6915, Comprar=1354, Vender=28485\n",
      "Ganhos Totais: 33722.25, Perdas Totais: -34299.50\n",
      "\n",
      "Episode 170/200, Total Reward: 2787.25, Win Rate: 0.44, Wins: 2704, Losses: 3495, Epsilon: 0.0906, Steps: 36754, Time: 116.25s\n",
      "Ações: Manter=12064, Comprar=2332, Vender=22358\n",
      "Ganhos Totais: 49663.75, Perdas Totais: -46876.50\n",
      "\n",
      "Modelo e log do episódio 170 salvos em: 4.6\\model_episode_170.pth e 4.6\\log_episode_170.csv\n",
      "Episode 171/200, Total Reward: 732.25, Win Rate: 0.39, Wins: 1646, Losses: 2562, Epsilon: 0.0897, Steps: 36754, Time: 115.13s\n",
      "Ações: Manter=6802, Comprar=5138, Vender=24814\n",
      "Ganhos Totais: 30734.00, Perdas Totais: -30001.75\n",
      "\n",
      "Episode 172/200, Total Reward: 1386.50, Win Rate: 0.40, Wins: 1777, Losses: 2710, Epsilon: 0.0888, Steps: 36754, Time: 115.61s\n",
      "Ações: Manter=9229, Comprar=1907, Vender=25618\n",
      "Ganhos Totais: 34796.50, Perdas Totais: -33410.00\n",
      "\n",
      "Episode 173/200, Total Reward: -1156.00, Win Rate: 0.40, Wins: 1954, Losses: 2902, Epsilon: 0.0879, Steps: 36754, Time: 115.73s\n",
      "Ações: Manter=10588, Comprar=3143, Vender=23023\n",
      "Ganhos Totais: 36425.75, Perdas Totais: -37581.75\n",
      "\n",
      "Episode 174/200, Total Reward: 718.50, Win Rate: 0.40, Wins: 1867, Losses: 2745, Epsilon: 0.0870, Steps: 36754, Time: 115.48s\n",
      "Ações: Manter=6560, Comprar=5092, Vender=25102\n",
      "Ganhos Totais: 34007.75, Perdas Totais: -33289.25\n",
      "\n",
      "Episode 175/200, Total Reward: 402.00, Win Rate: 0.40, Wins: 1932, Losses: 2850, Epsilon: 0.0861, Steps: 36754, Time: 116.06s\n",
      "Ações: Manter=8097, Comprar=3146, Vender=25511\n",
      "Ganhos Totais: 35376.50, Perdas Totais: -34974.50\n",
      "\n",
      "Episode 176/200, Total Reward: 245.50, Win Rate: 0.39, Wins: 1665, Losses: 2575, Epsilon: 0.0853, Steps: 36754, Time: 114.74s\n",
      "Ações: Manter=8304, Comprar=1320, Vender=27130\n",
      "Ganhos Totais: 31575.00, Perdas Totais: -31329.50\n",
      "\n",
      "Episode 177/200, Total Reward: 1266.25, Win Rate: 0.42, Wins: 2232, Losses: 3071, Epsilon: 0.0844, Steps: 36754, Time: 115.34s\n",
      "Ações: Manter=9454, Comprar=4713, Vender=22587\n",
      "Ganhos Totais: 39012.00, Perdas Totais: -37745.75\n",
      "\n",
      "Episode 178/200, Total Reward: 1679.50, Win Rate: 0.42, Wins: 2022, Losses: 2802, Epsilon: 0.0836, Steps: 36754, Time: 116.06s\n",
      "Ações: Manter=9040, Comprar=2851, Vender=24863\n",
      "Ganhos Totais: 38638.50, Perdas Totais: -36959.00\n",
      "\n",
      "Episode 179/200, Total Reward: -423.50, Win Rate: 0.40, Wins: 2017, Losses: 2981, Epsilon: 0.0827, Steps: 36754, Time: 115.75s\n",
      "Ações: Manter=9622, Comprar=1664, Vender=25468\n",
      "Ganhos Totais: 36757.75, Perdas Totais: -37181.25\n",
      "\n",
      "Episode 180/200, Total Reward: 698.50, Win Rate: 0.39, Wins: 1692, Losses: 2604, Epsilon: 0.0819, Steps: 36754, Time: 116.13s\n",
      "Ações: Manter=5957, Comprar=3449, Vender=27348\n",
      "Ganhos Totais: 30374.00, Perdas Totais: -29675.50\n",
      "\n",
      "Episode 181/200, Total Reward: 1777.75, Win Rate: 0.41, Wins: 1910, Losses: 2711, Epsilon: 0.0811, Steps: 36754, Time: 115.55s\n",
      "Ações: Manter=6424, Comprar=4621, Vender=25709\n",
      "Ganhos Totais: 35493.50, Perdas Totais: -33715.75\n",
      "\n",
      "Episode 182/200, Total Reward: 253.00, Win Rate: 0.42, Wins: 2355, Losses: 3204, Epsilon: 0.0803, Steps: 36754, Time: 116.10s\n",
      "Ações: Manter=12095, Comprar=1194, Vender=23465\n",
      "Ganhos Totais: 43079.75, Perdas Totais: -42826.75\n",
      "\n",
      "Episode 183/200, Total Reward: 349.75, Win Rate: 0.40, Wins: 1634, Losses: 2473, Epsilon: 0.0795, Steps: 36754, Time: 115.54s\n",
      "Ações: Manter=8328, Comprar=4985, Vender=23441\n",
      "Ganhos Totais: 32664.25, Perdas Totais: -32314.50\n",
      "\n",
      "Episode 184/200, Total Reward: 877.00, Win Rate: 0.36, Wins: 1249, Losses: 2199, Epsilon: 0.0787, Steps: 36754, Time: 115.89s\n",
      "Ações: Manter=3859, Comprar=5177, Vender=27718\n",
      "Ganhos Totais: 25684.00, Perdas Totais: -24807.00\n",
      "\n",
      "Episode 185/200, Total Reward: 1466.50, Win Rate: 0.42, Wins: 2255, Losses: 3122, Epsilon: 0.0779, Steps: 36754, Time: 115.79s\n",
      "Ações: Manter=8218, Comprar=1263, Vender=27273\n",
      "Ganhos Totais: 42460.00, Perdas Totais: -40993.50\n",
      "\n",
      "Episode 186/200, Total Reward: 3119.00, Win Rate: 0.43, Wins: 2393, Losses: 3216, Epsilon: 0.0771, Steps: 36754, Time: 116.04s\n",
      "Ações: Manter=10729, Comprar=2034, Vender=23991\n",
      "Ganhos Totais: 44624.75, Perdas Totais: -41505.75\n",
      "\n",
      "Modelo e log do episódio 186 salvos em: 4.6\\model_episode_186.pth e 4.6\\log_episode_186.csv\n",
      "Episode 187/200, Total Reward: -31.25, Win Rate: 0.42, Wins: 2218, Losses: 3055, Epsilon: 0.0763, Steps: 36754, Time: 114.93s\n",
      "Ações: Manter=8901, Comprar=2771, Vender=25082\n",
      "Ganhos Totais: 38374.50, Perdas Totais: -38405.75\n",
      "\n",
      "Episode 188/200, Total Reward: 1189.50, Win Rate: 0.42, Wins: 2124, Losses: 2940, Epsilon: 0.0756, Steps: 36754, Time: 116.62s\n",
      "Ações: Manter=8853, Comprar=2189, Vender=25712\n",
      "Ganhos Totais: 38898.50, Perdas Totais: -37709.00\n",
      "\n",
      "Episode 189/200, Total Reward: 2142.75, Win Rate: 0.43, Wins: 2429, Losses: 3239, Epsilon: 0.0748, Steps: 36754, Time: 115.73s\n",
      "Ações: Manter=9341, Comprar=4459, Vender=22954\n",
      "Ganhos Totais: 44259.00, Perdas Totais: -42116.25\n",
      "\n",
      "Episode 190/200, Total Reward: 1392.50, Win Rate: 0.43, Wins: 2871, Losses: 3740, Epsilon: 0.0741, Steps: 36754, Time: 116.34s\n",
      "Ações: Manter=13418, Comprar=1064, Vender=22272\n",
      "Ganhos Totais: 52190.75, Perdas Totais: -50798.25\n",
      "\n",
      "Episode 191/200, Total Reward: 2345.00, Win Rate: 0.42, Wins: 2169, Losses: 2973, Epsilon: 0.0733, Steps: 36754, Time: 115.51s\n",
      "Ações: Manter=7721, Comprar=10044, Vender=18989\n",
      "Ganhos Totais: 41770.00, Perdas Totais: -39425.00\n",
      "\n",
      "Episode 192/200, Total Reward: 3007.50, Win Rate: 0.42, Wins: 2159, Losses: 2943, Epsilon: 0.0726, Steps: 36754, Time: 116.20s\n",
      "Ações: Manter=9583, Comprar=3296, Vender=23875\n",
      "Ganhos Totais: 41368.75, Perdas Totais: -38361.25\n",
      "\n",
      "Modelo e log do episódio 192 salvos em: 4.6\\model_episode_192.pth e 4.6\\log_episode_192.csv\n",
      "Episode 193/200, Total Reward: 2754.50, Win Rate: 0.42, Wins: 2169, Losses: 2940, Epsilon: 0.0719, Steps: 36754, Time: 115.63s\n",
      "Ações: Manter=9800, Comprar=1400, Vender=25554\n",
      "Ganhos Totais: 40728.75, Perdas Totais: -37974.25\n",
      "\n",
      "Episode 194/200, Total Reward: 4277.50, Win Rate: 0.43, Wins: 2764, Losses: 3611, Epsilon: 0.0712, Steps: 36754, Time: 116.23s\n",
      "Ações: Manter=9158, Comprar=5912, Vender=21684\n",
      "Ganhos Totais: 52936.00, Perdas Totais: -48658.50\n",
      "\n",
      "Modelo e log do episódio 194 salvos em: 4.6\\model_episode_194.pth e 4.6\\log_episode_194.csv\n",
      "Episode 195/200, Total Reward: 369.50, Win Rate: 0.41, Wins: 1993, Losses: 2813, Epsilon: 0.0704, Steps: 36754, Time: 115.59s\n",
      "Ações: Manter=9574, Comprar=1365, Vender=25815\n",
      "Ganhos Totais: 37879.75, Perdas Totais: -37510.25\n",
      "\n",
      "Episode 196/200, Total Reward: 3240.25, Win Rate: 0.43, Wins: 2504, Losses: 3308, Epsilon: 0.0697, Steps: 36754, Time: 116.65s\n",
      "Ações: Manter=8607, Comprar=3679, Vender=24468\n",
      "Ganhos Totais: 46546.25, Perdas Totais: -43306.00\n",
      "\n",
      "Modelo e log do episódio 196 salvos em: 4.6\\model_episode_196.pth e 4.6\\log_episode_196.csv\n",
      "Episode 197/200, Total Reward: 3991.50, Win Rate: 0.44, Wins: 2514, Losses: 3246, Epsilon: 0.0690, Steps: 36754, Time: 116.75s\n",
      "Ações: Manter=7478, Comprar=7610, Vender=21666\n",
      "Ganhos Totais: 45705.00, Perdas Totais: -41713.50\n",
      "\n",
      "Modelo e log do episódio 197 salvos em: 4.6\\model_episode_197.pth e 4.6\\log_episode_197.csv\n",
      "Episode 198/200, Total Reward: 1893.25, Win Rate: 0.41, Wins: 1862, Losses: 2641, Epsilon: 0.0684, Steps: 36754, Time: 116.21s\n",
      "Ações: Manter=5659, Comprar=5286, Vender=25809\n",
      "Ganhos Totais: 36867.50, Perdas Totais: -34974.25\n",
      "\n",
      "Episode 199/200, Total Reward: 2192.25, Win Rate: 0.42, Wins: 2078, Losses: 2877, Epsilon: 0.0677, Steps: 36754, Time: 115.42s\n",
      "Ações: Manter=6061, Comprar=6981, Vender=23712\n",
      "Ganhos Totais: 38681.50, Perdas Totais: -36489.25\n",
      "\n",
      "Episode 200/200, Total Reward: 2477.50, Win Rate: 0.43, Wins: 2279, Losses: 3050, Epsilon: 0.0670, Steps: 36754, Time: 116.14s\n",
      "Ações: Manter=6881, Comprar=3740, Vender=26133\n",
      "Ganhos Totais: 43434.50, Perdas Totais: -40957.00\n",
      "\n",
      "\n",
      "Treinamento finalizado.\n",
      "Top 10 Melhores Episódios:\n",
      "Rank 1: Episode 130, Total Reward: 4319.25, Win Rate: 0.42, Wins: 2713, Losses: 3784, Ações: {0: 14407, 1: 4429, 2: 17918}, Steps: 36754, Time: 114.59s\n",
      "Rank 2: Episode 134, Total Reward: 4317.50, Win Rate: 0.41, Wins: 2137, Losses: 3086, Ações: {0: 11212, 1: 1873, 2: 23669}, Steps: 36754, Time: 115.48s\n",
      "Rank 3: Episode 194, Total Reward: 4277.50, Win Rate: 0.43, Wins: 2764, Losses: 3611, Ações: {0: 9158, 1: 5912, 2: 21684}, Steps: 36754, Time: 116.23s\n",
      "Rank 4: Episode 197, Total Reward: 3991.50, Win Rate: 0.44, Wins: 2514, Losses: 3246, Ações: {0: 7478, 1: 7610, 2: 21666}, Steps: 36754, Time: 116.75s\n",
      "Rank 5: Episode 196, Total Reward: 3240.25, Win Rate: 0.43, Wins: 2504, Losses: 3308, Ações: {0: 8607, 1: 3679, 2: 24468}, Steps: 36754, Time: 116.65s\n",
      "Rank 6: Episode 133, Total Reward: 3235.00, Win Rate: 0.39, Wins: 1994, Losses: 3142, Ações: {0: 7672, 1: 6140, 2: 22942}, Steps: 36754, Time: 114.69s\n",
      "Rank 7: Episode 186, Total Reward: 3119.00, Win Rate: 0.43, Wins: 2393, Losses: 3216, Ações: {0: 10729, 1: 2034, 2: 23991}, Steps: 36754, Time: 116.04s\n",
      "Rank 8: Episode 192, Total Reward: 3007.50, Win Rate: 0.42, Wins: 2159, Losses: 2943, Ações: {0: 9583, 1: 3296, 2: 23875}, Steps: 36754, Time: 116.20s\n",
      "Rank 9: Episode 131, Total Reward: 3004.50, Win Rate: 0.42, Wins: 2334, Losses: 3243, Ações: {0: 13041, 1: 1821, 2: 21892}, Steps: 36754, Time: 114.05s\n",
      "Rank 10: Episode 112, Total Reward: 2939.25, Win Rate: 0.36, Wins: 1946, Losses: 3416, Ações: {0: 9246, 1: 4789, 2: 22719}, Steps: 36754, Time: 114.04s\n"
     ]
    }
   ],
   "source": [
    "# Bloco 1: Preparar os Dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import os\n",
    "data = pd.read_csv('D:\\\\dados\\\\bar_M15_V02_data_01-01-2023_a_31-08-2024.csv')\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "\n",
    "# Criar a coluna \"Valor\", que é uma cópia de \"Close\" e não será normalizada\n",
    "data['Valor'] = data['Close']\n",
    "\n",
    "# Normalizar as colunas necessárias (exceto \"Valor\" e \"Gatilho\")\n",
    "scaler = MinMaxScaler()\n",
    "cols_to_normalize = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'PavioSuperior', 'PavioInferior',\n",
    "    'Corpo', 'Range','SMA4','SMA8','SMA12','SMA20', 'SMA50', 'SMA100', 'SMA200', 'StochasticoK',\n",
    "    'StochasticoD', 'RSI', 'MACD', 'MACDSignal', 'MACDHistogram','atr8','atr14','atr28'\n",
    "]\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "# Converter todos os valores para tipo float32 para evitar problemas de tipo\n",
    "data = data.astype({col: 'float32' for col in cols_to_normalize + ['Valor']})\n",
    "# Bloco 2 : Ambiente de Negociação Personalizado\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.current_step = 0\n",
    "        self.position = 0  # 0 = neutro, 1 = comprado, -1 = vendido\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None  # Inicializar entry_step\n",
    "        self.action_space = spaces.Discrete(3)  # 0 = Manter, 1 = Comprar, 2 = Vender\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(len(data.columns) - 3 + 1,), dtype=np.float32\n",
    "        )\n",
    "        self.trades = []  # Lista para armazenar as operações realizadas\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None  # Resetar entry_step\n",
    "        self.trades = []\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = self.data.iloc[self.current_step].drop(['Valor', 'DateTime', 'Gatilho']).values\n",
    "        obs = np.append(obs, self.position)  # Incluir a posição atual na observação\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        done = self.current_step >= len(self.data) - 2  # Ajustado para evitar índice fora do intervalo\n",
    "        reward = 0\n",
    "        info = {}\n",
    "\n",
    "        # Obter o valor atual e o próximo valor\n",
    "        current_price = self.data['Valor'].iloc[self.current_step]\n",
    "        next_price = self.data['Valor'].iloc[self.current_step + 1]\n",
    "        price_change = next_price - current_price\n",
    "\n",
    "        # Obter o valor do gatilho no passo atual\n",
    "        gatilho = int(self.data['Gatilho'].iloc[self.current_step])\n",
    "\n",
    "        # Se o gatilho estiver ativo, o agente pode executar todas as ações\n",
    "        if gatilho == 1:\n",
    "            if action == 1:  # Comprar\n",
    "                if self.position == 0:\n",
    "                    self.position = 1  # Abrir posição comprada\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step  # Registrar o passo de entrada\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price\n",
    "                    }\n",
    "                elif self.position == -1:\n",
    "                    # Fechar posição vendida\n",
    "                    self.position = 0\n",
    "                    self.exit_price = current_price\n",
    "                    reward += -price_change - 0.25  # Ganho da posição vendida\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_short',\n",
    "                        'exit_step': self.current_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'profit': -price_change - 0.25\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'short',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'exit_step': self.current_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'profit': -price_change - 0.25\n",
    "                    })\n",
    "                    # Resetar entry_step após fechar a posição\n",
    "                    self.entry_step = None\n",
    "            elif action == 2:  # Vender\n",
    "                if self.position == 0:\n",
    "                    self.position = -1  # Abrir posição vendida\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step  # Registrar o passo de entrada\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price\n",
    "                    }\n",
    "                elif self.position == 1:\n",
    "                    # Fechar posição comprada\n",
    "                    self.position = 0\n",
    "                    self.exit_price = current_price\n",
    "                    reward += price_change - 0.25  # Ganho da posição comprada\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_long',\n",
    "                        'exit_step': self.current_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'profit': price_change - 0.25\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'long',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'exit_step': self.current_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'profit': price_change - 0.25\n",
    "                    })\n",
    "                    # Resetar entry_step após fechar a posição\n",
    "                    self.entry_step = None\n",
    "            else:  # Manter\n",
    "                if self.position == 1:\n",
    "                    reward += price_change  # Ganho da posição comprada\n",
    "                elif self.position == -1:\n",
    "                    reward += -price_change  # Ganho da posição vendida\n",
    "\n",
    "        else:  # Gatilho == 0, nenhuma posição deve ser mantida\n",
    "            # Se há uma posição aberta, fechá-la\n",
    "            if self.position == 1:  # Fechar posição comprada\n",
    "                self.exit_price = current_price\n",
    "                reward += price_change - 0.25  # Ganho da posição comprada\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_long',\n",
    "                    'exit_step': self.current_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'profit': price_change - 0.25\n",
    "                }\n",
    "                # Registrar a operação\n",
    "                self.trades.append({\n",
    "                    'type': 'long',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'exit_step': self.current_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'profit': price_change - 0.25\n",
    "                })\n",
    "                # Resetar entry_step após fechar a posição\n",
    "                self.entry_step = None\n",
    "                self.position = 0  # Fechar a posição\n",
    "\n",
    "            elif self.position == -1:  # Fechar posição vendida\n",
    "                self.exit_price = current_price\n",
    "                reward += -price_change - 0.25  # Ganho da posição vendida\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_short',\n",
    "                    'exit_step': self.current_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'profit': -price_change - 0.25\n",
    "                }\n",
    "                # Registrar a operação\n",
    "                self.trades.append({\n",
    "                    'type': 'short',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'exit_step': self.current_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'profit': -price_change - 0.25\n",
    "                })\n",
    "                # Resetar entry_step após fechar a posição\n",
    "                self.entry_step = None\n",
    "                self.position = 0  # Fechar a posição\n",
    "\n",
    "        # Atualizar o passo atual\n",
    "        self.current_step += 1\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        return obs, reward, done, info\n",
    "\n",
    "\n",
    "# Bloco 3: Criar o Agente DQN usando PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import random\n",
    "\n",
    "# Configurações do dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Criar o ambiente\n",
    "env = TradingEnv(data)\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Definir a rede DQN\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, obs_size, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(obs_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instanciar a rede\n",
    "q_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "# Definir o otimizador\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Hiperparâmetros para DQN\n",
    "memory_size = 10000\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "epsilon_start = 0.5 # Valor inicial de epsilon, mais baixo para menos ações aleatórias no início\n",
    "epsilon_end = 0.05 # Valor final de epsilon, mais alto para mais exploração\n",
    "epsilon_decay = 0.99 # Decaimento mais rápido para o agente confiar mais nas ações aprendidas\n",
    "target_update = 10  # Atualizar a rede alvo a cada 10 episódios\n",
    "\n",
    "# Inicializar a memória de replay\n",
    "memory = collections.deque(maxlen=memory_size)\n",
    "\n",
    "# Função para selecionar ação usando epsilon-greedy\n",
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice([0, 1, 2])\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = q_net(state)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "# Bloco 4: Treinamento do Agente DQN com Salvamento dos Melhores Episódios Após Cada Episódio\n",
    "\n",
    "num_episodes = 200  # Defina o número de episódios de treinamento\n",
    "epsilon = epsilon_start\n",
    "best_episodes = []\n",
    "\n",
    "save_dir = \"4.6\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    start_time = time.time()\n",
    "    obs = env.reset()\n",
    "    obs = torch.FloatTensor(obs).unsqueeze(0).to(device)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    actions_count = {0: 0, 1: 0, 2: 0}\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    win_total = 0\n",
    "    lose_total = 0\n",
    "    trades = []  # Lista para armazenar as operações do episódio atual\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "\n",
    "        # Selecionar ação\n",
    "        action = select_action(obs, epsilon)\n",
    "\n",
    "        # Executar ação no ambiente\n",
    "        obs_next, reward, done, info = env.step(action)\n",
    "        obs_next = torch.FloatTensor(obs_next).unsqueeze(0).to(device)\n",
    "\n",
    "        # Armazenar na memória de replay\n",
    "        memory.append((obs, action, reward, obs_next, done))\n",
    "\n",
    "        # Atualizar o estado\n",
    "        obs = obs_next\n",
    "        total_reward += reward\n",
    "\n",
    "        # Atualizar contagem de ações\n",
    "        actions_count[action] += 1\n",
    "\n",
    "        # Atualizar ganhos e perdas\n",
    "        if reward > 0:\n",
    "            wins += 1\n",
    "            win_total += reward\n",
    "        elif reward < 0:\n",
    "            losses += 1\n",
    "            lose_total += reward\n",
    "\n",
    "        # Registrar a operação se houver uma\n",
    "        if 'trade' in info:\n",
    "            trade_info = info['trade']\n",
    "            if trade_info['type'] in ['buy', 'sell']:\n",
    "                # Início de uma nova operação\n",
    "                current_trade = {\n",
    "                    'type': trade_info['type'],\n",
    "                    'entry_step': trade_info['entry_step'],\n",
    "                    'entry_price': trade_info['entry_price'],\n",
    "                    'exit_step': None,\n",
    "                    'exit_price': None,\n",
    "                    'profit': None\n",
    "                }\n",
    "            else:\n",
    "                # Fechamento de uma operação existente\n",
    "                current_trade['exit_step'] = trade_info['exit_step']\n",
    "                current_trade['exit_price'] = trade_info['exit_price']\n",
    "                current_trade['profit'] = trade_info['profit']\n",
    "                trades.append(current_trade)\n",
    "                current_trade = None  # Resetar a operação atual\n",
    "\n",
    "        # Treinar a rede se a memória tiver tamanho suficiente\n",
    "        if len(memory) >= batch_size:\n",
    "            batch = random.sample(memory, batch_size)\n",
    "            states, actions_batch, rewards_batch, next_states, dones = zip(*batch)\n",
    "\n",
    "            states = torch.cat(states).to(device)\n",
    "            actions_batch = torch.tensor(actions_batch, dtype=torch.long, device=device).unsqueeze(1)\n",
    "            rewards_batch = torch.tensor(rewards_batch, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            next_states = torch.cat(next_states).to(device)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            # Computar Q-valor atual\n",
    "            q_values = q_net(states).gather(1, actions_batch)\n",
    "\n",
    "            # Computar Q-valor alvo usando a rede alvo\n",
    "            with torch.no_grad():\n",
    "                next_q_values = target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "            target_q_values = rewards_batch + gamma * next_q_values * (1 - dones)\n",
    "\n",
    "            # Calcular a perda\n",
    "            loss = nn.MSELoss()(q_values, target_q_values)\n",
    "\n",
    "            # Otimizar a rede\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Decaimento de epsilon\n",
    "    epsilon = max(epsilon_end, epsilon_decay * epsilon)\n",
    "\n",
    "    # Atualizar a rede alvo\n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    # Cálculo do tempo de treinamento do episódio\n",
    "    end_time = time.time()\n",
    "    episode_time = end_time - start_time\n",
    "\n",
    "    win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "    print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward:.2f}, Win Rate: {win_rate:.2f}, \"\n",
    "          f\"Wins: {wins}, Losses: {losses}, Epsilon: {epsilon:.4f}, Steps: {steps}, Time: {episode_time:.2f}s\")\n",
    "    print(f\"Ações: Manter={actions_count[0]}, Comprar={actions_count[1]}, Vender={actions_count[2]}\")\n",
    "    print(f\"Ganhos Totais: {win_total:.2f}, Perdas Totais: {lose_total:.2f}\\n\")\n",
    "\n",
    "    # Salvar informações do episódio\n",
    "    episode_info = {\n",
    "        'episode': episode + 1,\n",
    "        'total_reward': total_reward,\n",
    "        'win_rate': win_rate,\n",
    "        'wins': wins,\n",
    "        'losses': losses,\n",
    "        'actions_count': actions_count.copy(),\n",
    "        'win_total': win_total,\n",
    "        'lose_total': lose_total,\n",
    "        'steps': steps,\n",
    "        'episode_time': episode_time,\n",
    "        'model_state_dict': q_net.state_dict(),\n",
    "        'trades': trades.copy()  # Salvar as operações do episódio\n",
    "    }\n",
    "\n",
    "    # Adicionar o episódio à lista e manter os top 10\n",
    "    best_episodes.append(episode_info)\n",
    "    best_episodes = sorted(best_episodes, key=lambda x: x['total_reward'], reverse=True)[:10]\n",
    "\n",
    "    # Salvar o modelo e log se o episódio for um dos top 10\n",
    "    if episode_info in best_episodes:\n",
    "        model_path = os.path.join(save_dir, f\"model_episode_{episode_info['episode']}.pth\")\n",
    "        torch.save(episode_info['model_state_dict'], model_path)\n",
    "        episode_info['model_path'] = model_path\n",
    "\n",
    "        # Salvar o log completo das operações\n",
    "        log_path = os.path.join(save_dir, f\"log_episode_{episode_info['episode']}.csv\")\n",
    "        trades_df = pd.DataFrame(episode_info['trades'])\n",
    "        trades_df.to_csv(log_path, index=False)\n",
    "        episode_info['log_path'] = log_path\n",
    "\n",
    "        print(f\"Modelo e log do episódio {episode_info['episode']} salvos em: {model_path} e {log_path}\")\n",
    "\n",
    "print(\"\\nTreinamento finalizado.\")\n",
    "print(\"Top 10 Melhores Episódios:\")\n",
    "for idx, ep in enumerate(best_episodes, 1):\n",
    "    print(f\"Rank {idx}: Episode {ep['episode']}, Total Reward: {ep['total_reward']:.2f}, \"\n",
    "          f\"Win Rate: {ep['win_rate']:.2f}, Wins: {ep['wins']}, Losses: {ep['losses']}, \"\n",
    "          f\"Ações: {ep['actions_count']}, Steps: {ep['steps']}, Time: {ep['episode_time']:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
