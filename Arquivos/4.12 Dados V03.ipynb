{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/200, Total Reward: -261734.50, Win Rate: 0.49, Wins: 995, Losses: 1039, Epsilon: 0.4950, Steps: 36754, Time: 124.71s\n",
      "Ações: Manter=15560, Comprar=11931, Vender=9263\n",
      "Ganhos Totais: 31209.25, Perdas Totais: -292943.75\n",
      "Modelo e log do episódio 1 salvos em: 4.12\\model_episode_1.pth e 4.12\\log_episode_1.csv\n",
      "\n",
      "Episode 2/200, Total Reward: -256376.50, Win Rate: 0.49, Wins: 941, Losses: 964, Epsilon: 0.4900, Steps: 36754, Time: 120.93s\n",
      "Ações: Manter=13052, Comprar=12448, Vender=11254\n",
      "Ganhos Totais: 30284.25, Perdas Totais: -286660.75\n",
      "Modelo e log do episódio 2 salvos em: 4.12\\model_episode_2.pth e 4.12\\log_episode_2.csv\n",
      "\n",
      "Episode 3/200, Total Reward: -244860.75, Win Rate: 0.49, Wins: 875, Losses: 925, Epsilon: 0.4851, Steps: 36754, Time: 117.49s\n",
      "Ações: Manter=13771, Comprar=11284, Vender=11699\n",
      "Ganhos Totais: 28436.00, Perdas Totais: -273296.75\n",
      "Modelo e log do episódio 3 salvos em: 4.12\\model_episode_3.pth e 4.12\\log_episode_3.csv\n",
      "\n",
      "Episode 4/200, Total Reward: -250442.25, Win Rate: 0.48, Wins: 885, Losses: 965, Epsilon: 0.4803, Steps: 36754, Time: 118.79s\n",
      "Ações: Manter=13458, Comprar=10876, Vender=12420\n",
      "Ganhos Totais: 30861.50, Perdas Totais: -281303.75\n",
      "Modelo e log do episódio 4 salvos em: 4.12\\model_episode_4.pth e 4.12\\log_episode_4.csv\n",
      "\n",
      "Episode 5/200, Total Reward: -228767.25, Win Rate: 0.50, Wins: 964, Losses: 966, Epsilon: 0.4755, Steps: 36754, Time: 117.82s\n",
      "Ações: Manter=12892, Comprar=10959, Vender=12903\n",
      "Ganhos Totais: 33041.75, Perdas Totais: -261809.00\n",
      "Modelo e log do episódio 5 salvos em: 4.12\\model_episode_5.pth e 4.12\\log_episode_5.csv\n",
      "\n",
      "Episode 6/200, Total Reward: -252137.00, Win Rate: 0.50, Wins: 960, Losses: 960, Epsilon: 0.4707, Steps: 36754, Time: 122.70s\n",
      "Ações: Manter=13099, Comprar=10777, Vender=12878\n",
      "Ganhos Totais: 32402.50, Perdas Totais: -284539.50\n",
      "Modelo e log do episódio 6 salvos em: 4.12\\model_episode_6.pth e 4.12\\log_episode_6.csv\n",
      "\n",
      "Episode 7/200, Total Reward: -248805.75, Win Rate: 0.50, Wins: 962, Losses: 944, Epsilon: 0.4660, Steps: 36754, Time: 116.42s\n",
      "Ações: Manter=13374, Comprar=10893, Vender=12487\n",
      "Ganhos Totais: 33679.25, Perdas Totais: -282485.00\n",
      "Modelo e log do episódio 7 salvos em: 4.12\\model_episode_7.pth e 4.12\\log_episode_7.csv\n",
      "\n",
      "Episode 8/200, Total Reward: -248737.50, Win Rate: 0.48, Wins: 916, Losses: 1001, Epsilon: 0.4614, Steps: 36754, Time: 118.54s\n",
      "Ações: Manter=13129, Comprar=11292, Vender=12333\n",
      "Ganhos Totais: 31914.50, Perdas Totais: -280652.00\n",
      "Modelo e log do episódio 8 salvos em: 4.12\\model_episode_8.pth e 4.12\\log_episode_8.csv\n",
      "\n",
      "Episode 9/200, Total Reward: -240597.75, Win Rate: 0.51, Wins: 968, Losses: 936, Epsilon: 0.4568, Steps: 36754, Time: 116.43s\n",
      "Ações: Manter=13668, Comprar=10846, Vender=12240\n",
      "Ganhos Totais: 32785.75, Perdas Totais: -273383.50\n",
      "Modelo e log do episódio 9 salvos em: 4.12\\model_episode_9.pth e 4.12\\log_episode_9.csv\n",
      "\n",
      "Episode 10/200, Total Reward: -236509.25, Win Rate: 0.49, Wins: 906, Losses: 959, Epsilon: 0.4522, Steps: 36754, Time: 116.68s\n",
      "Ações: Manter=12766, Comprar=11395, Vender=12593\n",
      "Ganhos Totais: 31946.50, Perdas Totais: -268455.75\n",
      "Modelo e log do episódio 10 salvos em: 4.12\\model_episode_10.pth e 4.12\\log_episode_10.csv\n",
      "\n",
      "Episode 11/200, Total Reward: -222445.50, Win Rate: 0.51, Wins: 961, Losses: 937, Epsilon: 0.4477, Steps: 36754, Time: 116.92s\n",
      "Ações: Manter=13873, Comprar=10938, Vender=11943\n",
      "Ganhos Totais: 33306.25, Perdas Totais: -255751.75\n",
      "Modelo e log do episódio 11 salvos em: 4.12\\model_episode_11.pth e 4.12\\log_episode_11.csv\n",
      "\n",
      "Episode 12/200, Total Reward: -235375.25, Win Rate: 0.49, Wins: 948, Losses: 990, Epsilon: 0.4432, Steps: 36754, Time: 117.14s\n",
      "Ações: Manter=13265, Comprar=11324, Vender=12165\n",
      "Ganhos Totais: 32027.25, Perdas Totais: -267402.50\n",
      "Modelo e log do episódio 12 salvos em: 4.12\\model_episode_12.pth e 4.12\\log_episode_12.csv\n",
      "\n",
      "Episode 13/200, Total Reward: -258960.25, Win Rate: 0.50, Wins: 921, Losses: 929, Epsilon: 0.4388, Steps: 36754, Time: 117.12s\n",
      "Ações: Manter=13595, Comprar=10827, Vender=12332\n",
      "Ganhos Totais: 32020.75, Perdas Totais: -290981.00\n",
      "Episode 14/200, Total Reward: -235303.50, Win Rate: 0.50, Wins: 935, Losses: 945, Epsilon: 0.4344, Steps: 36754, Time: 117.47s\n",
      "Ações: Manter=13302, Comprar=11399, Vender=12053\n",
      "Ganhos Totais: 33286.00, Perdas Totais: -268589.50\n",
      "Modelo e log do episódio 14 salvos em: 4.12\\model_episode_14.pth e 4.12\\log_episode_14.csv\n",
      "\n",
      "Episode 15/200, Total Reward: -224935.25, Win Rate: 0.51, Wins: 968, Losses: 926, Epsilon: 0.4300, Steps: 36754, Time: 117.03s\n",
      "Ações: Manter=13200, Comprar=11600, Vender=11954\n",
      "Ganhos Totais: 34274.00, Perdas Totais: -259209.25\n",
      "Modelo e log do episódio 15 salvos em: 4.12\\model_episode_15.pth e 4.12\\log_episode_15.csv\n",
      "\n",
      "Episode 16/200, Total Reward: -234081.75, Win Rate: 0.53, Wins: 995, Losses: 887, Epsilon: 0.4257, Steps: 36754, Time: 117.05s\n",
      "Ações: Manter=13050, Comprar=11744, Vender=11960\n",
      "Ganhos Totais: 34877.50, Perdas Totais: -268959.25\n",
      "Modelo e log do episódio 16 salvos em: 4.12\\model_episode_16.pth e 4.12\\log_episode_16.csv\n",
      "\n",
      "Episode 17/200, Total Reward: -228998.25, Win Rate: 0.51, Wins: 960, Losses: 909, Epsilon: 0.4215, Steps: 36754, Time: 117.00s\n",
      "Ações: Manter=12826, Comprar=11174, Vender=12754\n",
      "Ganhos Totais: 32378.75, Perdas Totais: -261377.00\n",
      "Modelo e log do episódio 17 salvos em: 4.12\\model_episode_17.pth e 4.12\\log_episode_17.csv\n",
      "\n",
      "Episode 18/200, Total Reward: -210795.50, Win Rate: 0.51, Wins: 899, Losses: 877, Epsilon: 0.4173, Steps: 36754, Time: 117.93s\n",
      "Ações: Manter=14225, Comprar=11150, Vender=11379\n",
      "Ganhos Totais: 32409.50, Perdas Totais: -243205.00\n",
      "Modelo e log do episódio 18 salvos em: 4.12\\model_episode_18.pth e 4.12\\log_episode_18.csv\n",
      "\n",
      "Episode 19/200, Total Reward: -242143.25, Win Rate: 0.49, Wins: 915, Losses: 957, Epsilon: 0.4131, Steps: 36754, Time: 117.48s\n",
      "Ações: Manter=13163, Comprar=11824, Vender=11767\n",
      "Ganhos Totais: 30979.25, Perdas Totais: -273122.50\n",
      "Episode 20/200, Total Reward: -229236.75, Win Rate: 0.50, Wins: 910, Losses: 924, Epsilon: 0.4090, Steps: 36754, Time: 117.42s\n",
      "Ações: Manter=13113, Comprar=11648, Vender=11993\n",
      "Ganhos Totais: 31683.50, Perdas Totais: -260920.25\n",
      "Modelo e log do episódio 20 salvos em: 4.12\\model_episode_20.pth e 4.12\\log_episode_20.csv\n",
      "\n",
      "Episode 21/200, Total Reward: -215560.75, Win Rate: 0.54, Wins: 1005, Losses: 871, Epsilon: 0.4049, Steps: 36754, Time: 117.69s\n",
      "Ações: Manter=13534, Comprar=11739, Vender=11481\n",
      "Ganhos Totais: 34642.50, Perdas Totais: -250203.25\n",
      "Modelo e log do episódio 21 salvos em: 4.12\\model_episode_21.pth e 4.12\\log_episode_21.csv\n",
      "\n",
      "Episode 22/200, Total Reward: -223094.00, Win Rate: 0.50, Wins: 860, Losses: 871, Epsilon: 0.4008, Steps: 36754, Time: 117.89s\n",
      "Ações: Manter=13214, Comprar=11499, Vender=12041\n",
      "Ganhos Totais: 29948.25, Perdas Totais: -253042.25\n",
      "Modelo e log do episódio 22 salvos em: 4.12\\model_episode_22.pth e 4.12\\log_episode_22.csv\n",
      "\n",
      "Episode 23/200, Total Reward: -222028.75, Win Rate: 0.52, Wins: 956, Losses: 884, Epsilon: 0.3968, Steps: 36754, Time: 118.37s\n",
      "Ações: Manter=13668, Comprar=11185, Vender=11901\n",
      "Ganhos Totais: 31957.75, Perdas Totais: -253986.50\n",
      "Modelo e log do episódio 23 salvos em: 4.12\\model_episode_23.pth e 4.12\\log_episode_23.csv\n",
      "\n",
      "Episode 24/200, Total Reward: -220488.25, Win Rate: 0.50, Wins: 898, Losses: 893, Epsilon: 0.3928, Steps: 36754, Time: 117.96s\n",
      "Ações: Manter=13543, Comprar=11334, Vender=11877\n",
      "Ganhos Totais: 31457.00, Perdas Totais: -251945.25\n",
      "Modelo e log do episódio 24 salvos em: 4.12\\model_episode_24.pth e 4.12\\log_episode_24.csv\n",
      "\n",
      "Episode 25/200, Total Reward: -260349.25, Win Rate: 0.49, Wins: 892, Losses: 918, Epsilon: 0.3889, Steps: 36754, Time: 117.73s\n",
      "Ações: Manter=12343, Comprar=12190, Vender=12221\n",
      "Ganhos Totais: 30251.75, Perdas Totais: -290601.00\n",
      "Episode 26/200, Total Reward: -232587.00, Win Rate: 0.50, Wins: 915, Losses: 913, Epsilon: 0.3850, Steps: 36754, Time: 118.56s\n",
      "Ações: Manter=12063, Comprar=12172, Vender=12519\n",
      "Ganhos Totais: 30950.00, Perdas Totais: -263537.00\n",
      "Episode 27/200, Total Reward: -208414.00, Win Rate: 0.50, Wins: 866, Losses: 877, Epsilon: 0.3812, Steps: 36754, Time: 118.71s\n",
      "Ações: Manter=13115, Comprar=11655, Vender=11984\n",
      "Ganhos Totais: 32103.75, Perdas Totais: -240517.75\n",
      "Modelo e log do episódio 27 salvos em: 4.12\\model_episode_27.pth e 4.12\\log_episode_27.csv\n",
      "\n",
      "Episode 28/200, Total Reward: -218539.00, Win Rate: 0.50, Wins: 880, Losses: 880, Epsilon: 0.3774, Steps: 36754, Time: 117.86s\n",
      "Ações: Manter=12869, Comprar=11470, Vender=12415\n",
      "Ganhos Totais: 32518.75, Perdas Totais: -251057.75\n",
      "Modelo e log do episódio 28 salvos em: 4.12\\model_episode_28.pth e 4.12\\log_episode_28.csv\n",
      "\n",
      "Episode 29/200, Total Reward: -202854.00, Win Rate: 0.51, Wins: 913, Losses: 884, Epsilon: 0.3736, Steps: 36754, Time: 117.83s\n",
      "Ações: Manter=13028, Comprar=11569, Vender=12157\n",
      "Ganhos Totais: 32093.50, Perdas Totais: -234947.50\n",
      "Modelo e log do episódio 29 salvos em: 4.12\\model_episode_29.pth e 4.12\\log_episode_29.csv\n",
      "\n",
      "Episode 30/200, Total Reward: -223385.50, Win Rate: 0.48, Wins: 819, Losses: 884, Epsilon: 0.3699, Steps: 36754, Time: 117.56s\n",
      "Ações: Manter=13689, Comprar=12088, Vender=10977\n",
      "Ganhos Totais: 29403.50, Perdas Totais: -252789.00\n",
      "Modelo e log do episódio 30 salvos em: 4.12\\model_episode_30.pth e 4.12\\log_episode_30.csv\n",
      "\n",
      "Episode 31/200, Total Reward: -220067.50, Win Rate: 0.50, Wins: 883, Losses: 874, Epsilon: 0.3662, Steps: 36754, Time: 117.92s\n",
      "Ações: Manter=13529, Comprar=12043, Vender=11182\n",
      "Ganhos Totais: 30992.25, Perdas Totais: -251059.75\n",
      "Modelo e log do episódio 31 salvos em: 4.12\\model_episode_31.pth e 4.12\\log_episode_31.csv\n",
      "\n",
      "Episode 32/200, Total Reward: -195614.75, Win Rate: 0.51, Wins: 857, Losses: 816, Epsilon: 0.3625, Steps: 36754, Time: 118.73s\n",
      "Ações: Manter=13257, Comprar=12106, Vender=11391\n",
      "Ganhos Totais: 33775.00, Perdas Totais: -229389.75\n",
      "Modelo e log do episódio 32 salvos em: 4.12\\model_episode_32.pth e 4.12\\log_episode_32.csv\n",
      "\n",
      "Episode 33/200, Total Reward: -207819.25, Win Rate: 0.52, Wins: 885, Losses: 831, Epsilon: 0.3589, Steps: 36754, Time: 118.09s\n",
      "Ações: Manter=13917, Comprar=12175, Vender=10662\n",
      "Ganhos Totais: 31808.50, Perdas Totais: -239627.75\n",
      "Modelo e log do episódio 33 salvos em: 4.12\\model_episode_33.pth e 4.12\\log_episode_33.csv\n",
      "\n",
      "Episode 34/200, Total Reward: -206553.25, Win Rate: 0.52, Wins: 904, Losses: 819, Epsilon: 0.3553, Steps: 36754, Time: 118.23s\n",
      "Ações: Manter=13180, Comprar=12458, Vender=11116\n",
      "Ganhos Totais: 32330.50, Perdas Totais: -238883.75\n",
      "Modelo e log do episódio 34 salvos em: 4.12\\model_episode_34.pth e 4.12\\log_episode_34.csv\n",
      "\n",
      "Episode 35/200, Total Reward: -209060.00, Win Rate: 0.51, Wins: 858, Losses: 831, Epsilon: 0.3517, Steps: 36754, Time: 118.04s\n",
      "Ações: Manter=13486, Comprar=11874, Vender=11394\n",
      "Ganhos Totais: 30831.00, Perdas Totais: -239891.00\n",
      "Modelo e log do episódio 35 salvos em: 4.12\\model_episode_35.pth e 4.12\\log_episode_35.csv\n",
      "\n",
      "Episode 36/200, Total Reward: -224624.50, Win Rate: 0.50, Wins: 852, Losses: 838, Epsilon: 0.3482, Steps: 36754, Time: 117.89s\n",
      "Ações: Manter=13578, Comprar=12816, Vender=10360\n",
      "Ganhos Totais: 28319.00, Perdas Totais: -252943.50\n",
      "Episode 37/200, Total Reward: -211922.75, Win Rate: 0.51, Wins: 843, Losses: 819, Epsilon: 0.3447, Steps: 36754, Time: 118.19s\n",
      "Ações: Manter=13765, Comprar=12652, Vender=10337\n",
      "Ganhos Totais: 33247.25, Perdas Totais: -245170.00\n",
      "Modelo e log do episódio 37 salvos em: 4.12\\model_episode_37.pth e 4.12\\log_episode_37.csv\n",
      "\n",
      "Episode 38/200, Total Reward: -191105.75, Win Rate: 0.53, Wins: 866, Losses: 777, Epsilon: 0.3413, Steps: 36754, Time: 118.20s\n",
      "Ações: Manter=13393, Comprar=12351, Vender=11010\n",
      "Ganhos Totais: 33734.00, Perdas Totais: -224839.75\n",
      "Modelo e log do episódio 38 salvos em: 4.12\\model_episode_38.pth e 4.12\\log_episode_38.csv\n",
      "\n",
      "Episode 39/200, Total Reward: -192096.75, Win Rate: 0.51, Wins: 832, Losses: 789, Epsilon: 0.3379, Steps: 36754, Time: 118.85s\n",
      "Ações: Manter=14204, Comprar=11729, Vender=10821\n",
      "Ganhos Totais: 30227.25, Perdas Totais: -222324.00\n",
      "Modelo e log do episódio 39 salvos em: 4.12\\model_episode_39.pth e 4.12\\log_episode_39.csv\n",
      "\n",
      "Episode 40/200, Total Reward: -203187.75, Win Rate: 0.52, Wins: 881, Losses: 807, Epsilon: 0.3345, Steps: 36754, Time: 118.55s\n",
      "Ações: Manter=13295, Comprar=12965, Vender=10494\n",
      "Ganhos Totais: 32922.75, Perdas Totais: -236110.50\n",
      "Modelo e log do episódio 40 salvos em: 4.12\\model_episode_40.pth e 4.12\\log_episode_40.csv\n",
      "\n",
      "Episode 41/200, Total Reward: -199551.00, Win Rate: 0.51, Wins: 854, Losses: 814, Epsilon: 0.3311, Steps: 36754, Time: 118.25s\n",
      "Ações: Manter=14052, Comprar=11724, Vender=10978\n",
      "Ganhos Totais: 33468.50, Perdas Totais: -233019.50\n",
      "Modelo e log do episódio 41 salvos em: 4.12\\model_episode_41.pth e 4.12\\log_episode_41.csv\n",
      "\n",
      "Episode 42/200, Total Reward: -214900.00, Win Rate: 0.53, Wins: 887, Losses: 795, Epsilon: 0.3278, Steps: 36754, Time: 118.63s\n",
      "Ações: Manter=13953, Comprar=11492, Vender=11309\n",
      "Ganhos Totais: 30706.50, Perdas Totais: -245606.50\n",
      "Episode 43/200, Total Reward: -200874.50, Win Rate: 0.50, Wins: 811, Losses: 800, Epsilon: 0.3246, Steps: 36754, Time: 118.80s\n",
      "Ações: Manter=13705, Comprar=11955, Vender=11094\n",
      "Ganhos Totais: 30392.25, Perdas Totais: -231266.75\n",
      "Modelo e log do episódio 43 salvos em: 4.12\\model_episode_43.pth e 4.12\\log_episode_43.csv\n",
      "\n",
      "Episode 44/200, Total Reward: -204462.50, Win Rate: 0.51, Wins: 840, Losses: 794, Epsilon: 0.3213, Steps: 36754, Time: 118.37s\n",
      "Ações: Manter=14333, Comprar=12097, Vender=10324\n",
      "Ganhos Totais: 30800.25, Perdas Totais: -235262.75\n",
      "Modelo e log do episódio 44 salvos em: 4.12\\model_episode_44.pth e 4.12\\log_episode_44.csv\n",
      "\n",
      "Episode 45/200, Total Reward: -233161.50, Win Rate: 0.50, Wins: 823, Losses: 812, Epsilon: 0.3181, Steps: 36754, Time: 118.57s\n",
      "Ações: Manter=14139, Comprar=11363, Vender=11252\n",
      "Ganhos Totais: 30605.75, Perdas Totais: -263767.25\n",
      "Episode 46/200, Total Reward: -201830.50, Win Rate: 0.51, Wins: 829, Losses: 789, Epsilon: 0.3149, Steps: 36754, Time: 118.54s\n",
      "Ações: Manter=14008, Comprar=11876, Vender=10870\n",
      "Ganhos Totais: 32621.75, Perdas Totais: -234452.25\n",
      "Modelo e log do episódio 46 salvos em: 4.12\\model_episode_46.pth e 4.12\\log_episode_46.csv\n",
      "\n",
      "Episode 47/200, Total Reward: -231414.50, Win Rate: 0.49, Wins: 767, Losses: 793, Epsilon: 0.3118, Steps: 36754, Time: 118.59s\n",
      "Ações: Manter=14354, Comprar=11500, Vender=10900\n",
      "Ganhos Totais: 27590.00, Perdas Totais: -259004.50\n",
      "Episode 48/200, Total Reward: -199853.00, Win Rate: 0.50, Wins: 788, Losses: 797, Epsilon: 0.3086, Steps: 36754, Time: 119.05s\n",
      "Ações: Manter=14688, Comprar=11301, Vender=10765\n",
      "Ganhos Totais: 30001.25, Perdas Totais: -229854.25\n",
      "Modelo e log do episódio 48 salvos em: 4.12\\model_episode_48.pth e 4.12\\log_episode_48.csv\n",
      "\n",
      "Episode 49/200, Total Reward: -201803.50, Win Rate: 0.49, Wins: 743, Losses: 776, Epsilon: 0.3056, Steps: 36754, Time: 118.70s\n",
      "Ações: Manter=14478, Comprar=11444, Vender=10832\n",
      "Ganhos Totais: 27420.75, Perdas Totais: -229224.25\n",
      "Modelo e log do episódio 49 salvos em: 4.12\\model_episode_49.pth e 4.12\\log_episode_49.csv\n",
      "\n",
      "Episode 50/200, Total Reward: -197385.00, Win Rate: 0.50, Wins: 816, Losses: 811, Epsilon: 0.3025, Steps: 36754, Time: 119.07s\n",
      "Ações: Manter=13853, Comprar=11154, Vender=11747\n",
      "Ganhos Totais: 31449.50, Perdas Totais: -228834.50\n",
      "Modelo e log do episódio 50 salvos em: 4.12\\model_episode_50.pth e 4.12\\log_episode_50.csv\n",
      "\n",
      "Episode 51/200, Total Reward: -205214.00, Win Rate: 0.52, Wins: 800, Losses: 753, Epsilon: 0.2995, Steps: 36754, Time: 119.13s\n",
      "Ações: Manter=14234, Comprar=11708, Vender=10812\n",
      "Ganhos Totais: 29805.00, Perdas Totais: -235019.00\n",
      "Episode 52/200, Total Reward: -169882.25, Win Rate: 0.53, Wins: 836, Losses: 737, Epsilon: 0.2965, Steps: 36754, Time: 119.42s\n",
      "Ações: Manter=14323, Comprar=11020, Vender=11411\n",
      "Ganhos Totais: 31190.50, Perdas Totais: -201072.75\n",
      "Modelo e log do episódio 52 salvos em: 4.12\\model_episode_52.pth e 4.12\\log_episode_52.csv\n",
      "\n",
      "Episode 53/200, Total Reward: -182693.00, Win Rate: 0.53, Wins: 854, Losses: 750, Epsilon: 0.2935, Steps: 36754, Time: 118.98s\n",
      "Ações: Manter=13504, Comprar=11328, Vender=11922\n",
      "Ganhos Totais: 32737.50, Perdas Totais: -215430.50\n",
      "Modelo e log do episódio 53 salvos em: 4.12\\model_episode_53.pth e 4.12\\log_episode_53.csv\n",
      "\n",
      "Episode 54/200, Total Reward: -204916.25, Win Rate: 0.52, Wins: 796, Losses: 739, Epsilon: 0.2906, Steps: 36754, Time: 119.21s\n",
      "Ações: Manter=14109, Comprar=11598, Vender=11047\n",
      "Ganhos Totais: 31148.75, Perdas Totais: -236065.00\n",
      "Episode 55/200, Total Reward: -203659.50, Win Rate: 0.49, Wins: 762, Losses: 780, Epsilon: 0.2877, Steps: 36754, Time: 119.82s\n",
      "Ações: Manter=14273, Comprar=10861, Vender=11620\n",
      "Ganhos Totais: 30287.25, Perdas Totais: -233946.75\n",
      "Episode 56/200, Total Reward: -193485.00, Win Rate: 0.52, Wins: 781, Losses: 729, Epsilon: 0.2848, Steps: 36754, Time: 119.83s\n",
      "Ações: Manter=14332, Comprar=11051, Vender=11371\n",
      "Ganhos Totais: 30247.25, Perdas Totais: -223732.25\n",
      "Modelo e log do episódio 56 salvos em: 4.12\\model_episode_56.pth e 4.12\\log_episode_56.csv\n",
      "\n",
      "Episode 57/200, Total Reward: -188927.25, Win Rate: 0.50, Wins: 822, Losses: 809, Epsilon: 0.2820, Steps: 36754, Time: 119.65s\n",
      "Ações: Manter=14204, Comprar=11322, Vender=11228\n",
      "Ganhos Totais: 31421.50, Perdas Totais: -220348.75\n",
      "Modelo e log do episódio 57 salvos em: 4.12\\model_episode_57.pth e 4.12\\log_episode_57.csv\n",
      "\n",
      "Episode 58/200, Total Reward: -193749.75, Win Rate: 0.52, Wins: 794, Losses: 728, Epsilon: 0.2791, Steps: 36754, Time: 119.65s\n",
      "Ações: Manter=14560, Comprar=11108, Vender=11086\n",
      "Ganhos Totais: 33256.50, Perdas Totais: -227006.25\n",
      "Modelo e log do episódio 58 salvos em: 4.12\\model_episode_58.pth e 4.12\\log_episode_58.csv\n",
      "\n",
      "Episode 59/200, Total Reward: -184134.00, Win Rate: 0.52, Wins: 797, Losses: 744, Epsilon: 0.2763, Steps: 36754, Time: 119.55s\n",
      "Ações: Manter=13818, Comprar=11360, Vender=11576\n",
      "Ganhos Totais: 32242.50, Perdas Totais: -216376.50\n",
      "Modelo e log do episódio 59 salvos em: 4.12\\model_episode_59.pth e 4.12\\log_episode_59.csv\n",
      "\n",
      "Episode 60/200, Total Reward: -172592.00, Win Rate: 0.51, Wins: 783, Losses: 748, Epsilon: 0.2736, Steps: 36754, Time: 119.46s\n",
      "Ações: Manter=14425, Comprar=11674, Vender=10655\n",
      "Ganhos Totais: 30311.00, Perdas Totais: -202903.00\n",
      "Modelo e log do episódio 60 salvos em: 4.12\\model_episode_60.pth e 4.12\\log_episode_60.csv\n",
      "\n",
      "Episode 61/200, Total Reward: -184727.25, Win Rate: 0.52, Wins: 747, Losses: 686, Epsilon: 0.2708, Steps: 36754, Time: 119.33s\n",
      "Ações: Manter=14448, Comprar=11513, Vender=10793\n",
      "Ganhos Totais: 31179.50, Perdas Totais: -215906.75\n",
      "Modelo e log do episódio 61 salvos em: 4.12\\model_episode_61.pth e 4.12\\log_episode_61.csv\n",
      "\n",
      "Episode 62/200, Total Reward: -195682.00, Win Rate: 0.51, Wins: 801, Losses: 779, Epsilon: 0.2681, Steps: 36754, Time: 120.49s\n",
      "Ações: Manter=13804, Comprar=11301, Vender=11649\n",
      "Ganhos Totais: 30243.00, Perdas Totais: -225925.00\n",
      "Episode 63/200, Total Reward: -194601.50, Win Rate: 0.52, Wins: 792, Losses: 742, Epsilon: 0.2655, Steps: 36754, Time: 119.80s\n",
      "Ações: Manter=13675, Comprar=12864, Vender=10215\n",
      "Ganhos Totais: 29603.50, Perdas Totais: -224205.00\n",
      "Episode 64/200, Total Reward: -185584.75, Win Rate: 0.51, Wins: 754, Losses: 712, Epsilon: 0.2628, Steps: 36754, Time: 119.81s\n",
      "Ações: Manter=14975, Comprar=12455, Vender=9324\n",
      "Ganhos Totais: 31073.25, Perdas Totais: -216658.00\n",
      "Modelo e log do episódio 64 salvos em: 4.12\\model_episode_64.pth e 4.12\\log_episode_64.csv\n",
      "\n",
      "Episode 65/200, Total Reward: -182969.50, Win Rate: 0.51, Wins: 761, Losses: 743, Epsilon: 0.2602, Steps: 36754, Time: 119.55s\n",
      "Ações: Manter=13603, Comprar=13107, Vender=10044\n",
      "Ganhos Totais: 29240.75, Perdas Totais: -212210.25\n",
      "Modelo e log do episódio 65 salvos em: 4.12\\model_episode_65.pth e 4.12\\log_episode_65.csv\n",
      "\n",
      "Episode 66/200, Total Reward: -190046.75, Win Rate: 0.52, Wins: 794, Losses: 725, Epsilon: 0.2576, Steps: 36754, Time: 119.60s\n",
      "Ações: Manter=13712, Comprar=12498, Vender=10544\n",
      "Ganhos Totais: 31086.00, Perdas Totais: -221132.75\n",
      "Modelo e log do episódio 66 salvos em: 4.12\\model_episode_66.pth e 4.12\\log_episode_66.csv\n",
      "\n",
      "Episode 67/200, Total Reward: -187451.75, Win Rate: 0.52, Wins: 769, Losses: 709, Epsilon: 0.2550, Steps: 36754, Time: 119.58s\n",
      "Ações: Manter=15317, Comprar=11270, Vender=10167\n",
      "Ganhos Totais: 29715.75, Perdas Totais: -217167.50\n",
      "Modelo e log do episódio 67 salvos em: 4.12\\model_episode_67.pth e 4.12\\log_episode_67.csv\n",
      "\n",
      "Episode 68/200, Total Reward: -180517.00, Win Rate: 0.52, Wins: 787, Losses: 724, Epsilon: 0.2524, Steps: 36754, Time: 119.75s\n",
      "Ações: Manter=13905, Comprar=12629, Vender=10220\n",
      "Ganhos Totais: 29073.75, Perdas Totais: -209590.75\n",
      "Modelo e log do episódio 68 salvos em: 4.12\\model_episode_68.pth e 4.12\\log_episode_68.csv\n",
      "\n",
      "Episode 69/200, Total Reward: -180163.25, Win Rate: 0.53, Wins: 824, Losses: 735, Epsilon: 0.2499, Steps: 36754, Time: 120.16s\n",
      "Ações: Manter=14190, Comprar=11361, Vender=11203\n",
      "Ganhos Totais: 30997.00, Perdas Totais: -211160.25\n",
      "Modelo e log do episódio 69 salvos em: 4.12\\model_episode_69.pth e 4.12\\log_episode_69.csv\n",
      "\n",
      "Episode 70/200, Total Reward: -195389.00, Win Rate: 0.52, Wins: 747, Losses: 685, Epsilon: 0.2474, Steps: 36754, Time: 119.76s\n",
      "Ações: Manter=15856, Comprar=10940, Vender=9958\n",
      "Ganhos Totais: 27565.50, Perdas Totais: -222954.50\n",
      "Episode 71/200, Total Reward: -193140.75, Win Rate: 0.51, Wins: 767, Losses: 731, Epsilon: 0.2449, Steps: 36754, Time: 119.95s\n",
      "Ações: Manter=14045, Comprar=11847, Vender=10862\n",
      "Ganhos Totais: 29172.25, Perdas Totais: -222313.00\n",
      "Episode 72/200, Total Reward: -182621.50, Win Rate: 0.51, Wins: 749, Losses: 709, Epsilon: 0.2425, Steps: 36754, Time: 120.06s\n",
      "Ações: Manter=13320, Comprar=12937, Vender=10497\n",
      "Ganhos Totais: 30097.25, Perdas Totais: -212718.75\n",
      "Modelo e log do episódio 72 salvos em: 4.12\\model_episode_72.pth e 4.12\\log_episode_72.csv\n",
      "\n",
      "Episode 73/200, Total Reward: -173549.00, Win Rate: 0.51, Wins: 715, Losses: 685, Epsilon: 0.2401, Steps: 36754, Time: 120.01s\n",
      "Ações: Manter=14344, Comprar=11931, Vender=10479\n",
      "Ganhos Totais: 28543.50, Perdas Totais: -202092.50\n",
      "Modelo e log do episódio 73 salvos em: 4.12\\model_episode_73.pth e 4.12\\log_episode_73.csv\n",
      "\n",
      "Episode 74/200, Total Reward: -190707.50, Win Rate: 0.51, Wins: 733, Losses: 712, Epsilon: 0.2377, Steps: 36754, Time: 120.09s\n",
      "Ações: Manter=14146, Comprar=11073, Vender=11535\n",
      "Ganhos Totais: 27722.25, Perdas Totais: -218429.75\n",
      "Episode 75/200, Total Reward: -200106.00, Win Rate: 0.50, Wins: 702, Losses: 694, Epsilon: 0.2353, Steps: 36754, Time: 119.78s\n",
      "Ações: Manter=13970, Comprar=11715, Vender=11069\n",
      "Ganhos Totais: 26068.50, Perdas Totais: -226174.50\n",
      "Episode 76/200, Total Reward: -198635.00, Win Rate: 0.49, Wins: 684, Losses: 711, Epsilon: 0.2329, Steps: 36754, Time: 120.19s\n",
      "Ações: Manter=15255, Comprar=10738, Vender=10761\n",
      "Ganhos Totais: 28730.00, Perdas Totais: -227365.00\n",
      "Episode 77/200, Total Reward: -162747.50, Win Rate: 0.53, Wins: 723, Losses: 651, Epsilon: 0.2306, Steps: 36754, Time: 120.06s\n",
      "Ações: Manter=14011, Comprar=12143, Vender=10600\n",
      "Ganhos Totais: 28387.00, Perdas Totais: -191134.50\n",
      "Modelo e log do episódio 77 salvos em: 4.12\\model_episode_77.pth e 4.12\\log_episode_77.csv\n",
      "\n",
      "Episode 78/200, Total Reward: -169053.50, Win Rate: 0.52, Wins: 731, Losses: 678, Epsilon: 0.2283, Steps: 36754, Time: 120.35s\n",
      "Ações: Manter=14834, Comprar=12042, Vender=9878\n",
      "Ganhos Totais: 29823.75, Perdas Totais: -198877.25\n",
      "Modelo e log do episódio 78 salvos em: 4.12\\model_episode_78.pth e 4.12\\log_episode_78.csv\n",
      "\n",
      "Episode 79/200, Total Reward: -167605.75, Win Rate: 0.53, Wins: 742, Losses: 660, Epsilon: 0.2260, Steps: 36754, Time: 120.10s\n",
      "Ações: Manter=13916, Comprar=12441, Vender=10397\n",
      "Ganhos Totais: 30686.50, Perdas Totais: -198292.25\n",
      "Modelo e log do episódio 79 salvos em: 4.12\\model_episode_79.pth e 4.12\\log_episode_79.csv\n",
      "\n",
      "Episode 80/200, Total Reward: -163279.75, Win Rate: 0.52, Wins: 746, Losses: 678, Epsilon: 0.2238, Steps: 36754, Time: 119.99s\n",
      "Ações: Manter=14794, Comprar=12308, Vender=9652\n",
      "Ganhos Totais: 31250.00, Perdas Totais: -194529.75\n",
      "Modelo e log do episódio 80 salvos em: 4.12\\model_episode_80.pth e 4.12\\log_episode_80.csv\n",
      "\n",
      "Episode 81/200, Total Reward: -173552.75, Win Rate: 0.51, Wins: 707, Losses: 689, Epsilon: 0.2215, Steps: 36754, Time: 119.70s\n",
      "Ações: Manter=13411, Comprar=12323, Vender=11020\n",
      "Ganhos Totais: 30856.00, Perdas Totais: -204408.75\n",
      "Modelo e log do episódio 81 salvos em: 4.12\\model_episode_81.pth e 4.12\\log_episode_81.csv\n",
      "\n",
      "Episode 82/200, Total Reward: -171277.75, Win Rate: 0.52, Wins: 717, Losses: 654, Epsilon: 0.2193, Steps: 36754, Time: 120.00s\n",
      "Ações: Manter=13245, Comprar=12740, Vender=10769\n",
      "Ganhos Totais: 30453.00, Perdas Totais: -201730.75\n",
      "Modelo e log do episódio 82 salvos em: 4.12\\model_episode_82.pth e 4.12\\log_episode_82.csv\n",
      "\n",
      "Episode 83/200, Total Reward: -182079.50, Win Rate: 0.52, Wins: 717, Losses: 675, Epsilon: 0.2171, Steps: 36754, Time: 119.90s\n",
      "Ações: Manter=11667, Comprar=12995, Vender=12092\n",
      "Ganhos Totais: 29873.50, Perdas Totais: -211953.00\n",
      "Episode 84/200, Total Reward: -175534.50, Win Rate: 0.51, Wins: 735, Losses: 705, Epsilon: 0.2149, Steps: 36754, Time: 120.29s\n",
      "Ações: Manter=11034, Comprar=12378, Vender=13342\n",
      "Ganhos Totais: 28019.75, Perdas Totais: -203554.25\n",
      "Modelo e log do episódio 84 salvos em: 4.12\\model_episode_84.pth e 4.12\\log_episode_84.csv\n",
      "\n",
      "Episode 85/200, Total Reward: -162313.75, Win Rate: 0.50, Wins: 703, Losses: 692, Epsilon: 0.2128, Steps: 36754, Time: 120.13s\n",
      "Ações: Manter=12639, Comprar=11619, Vender=12496\n",
      "Ganhos Totais: 28776.00, Perdas Totais: -191089.75\n",
      "Modelo e log do episódio 85 salvos em: 4.12\\model_episode_85.pth e 4.12\\log_episode_85.csv\n",
      "\n",
      "Episode 86/200, Total Reward: -164201.75, Win Rate: 0.52, Wins: 738, Losses: 669, Epsilon: 0.2107, Steps: 36754, Time: 120.77s\n",
      "Ações: Manter=11944, Comprar=12247, Vender=12563\n",
      "Ganhos Totais: 28660.75, Perdas Totais: -192862.50\n",
      "Modelo e log do episódio 86 salvos em: 4.12\\model_episode_86.pth e 4.12\\log_episode_86.csv\n",
      "\n",
      "Episode 87/200, Total Reward: -158550.00, Win Rate: 0.52, Wins: 697, Losses: 644, Epsilon: 0.2086, Steps: 36754, Time: 120.56s\n",
      "Ações: Manter=14084, Comprar=11134, Vender=11536\n",
      "Ganhos Totais: 29177.50, Perdas Totais: -187727.50\n",
      "Modelo e log do episódio 87 salvos em: 4.12\\model_episode_87.pth e 4.12\\log_episode_87.csv\n",
      "\n",
      "Episode 88/200, Total Reward: -162785.25, Win Rate: 0.51, Wins: 654, Losses: 636, Epsilon: 0.2065, Steps: 36754, Time: 120.68s\n",
      "Ações: Manter=13356, Comprar=11497, Vender=11901\n",
      "Ganhos Totais: 26621.00, Perdas Totais: -189406.25\n",
      "Modelo e log do episódio 88 salvos em: 4.12\\model_episode_88.pth e 4.12\\log_episode_88.csv\n",
      "\n",
      "Episode 89/200, Total Reward: -146949.00, Win Rate: 0.52, Wins: 728, Losses: 666, Epsilon: 0.2044, Steps: 36754, Time: 119.85s\n",
      "Ações: Manter=12949, Comprar=10307, Vender=13498\n",
      "Ganhos Totais: 28648.00, Perdas Totais: -175597.00\n",
      "Modelo e log do episódio 89 salvos em: 4.12\\model_episode_89.pth e 4.12\\log_episode_89.csv\n",
      "\n",
      "Episode 90/200, Total Reward: -140071.50, Win Rate: 0.53, Wins: 674, Losses: 606, Epsilon: 0.2024, Steps: 36754, Time: 120.13s\n",
      "Ações: Manter=14447, Comprar=10610, Vender=11697\n",
      "Ganhos Totais: 29307.75, Perdas Totais: -169379.25\n",
      "Modelo e log do episódio 90 salvos em: 4.12\\model_episode_90.pth e 4.12\\log_episode_90.csv\n",
      "\n",
      "Episode 91/200, Total Reward: -145144.25, Win Rate: 0.53, Wins: 702, Losses: 628, Epsilon: 0.2003, Steps: 36754, Time: 120.12s\n",
      "Ações: Manter=14430, Comprar=10305, Vender=12019\n",
      "Ganhos Totais: 28803.75, Perdas Totais: -173948.00\n",
      "Modelo e log do episódio 91 salvos em: 4.12\\model_episode_91.pth e 4.12\\log_episode_91.csv\n",
      "\n",
      "Episode 92/200, Total Reward: -160409.25, Win Rate: 0.52, Wins: 686, Losses: 623, Epsilon: 0.1983, Steps: 36754, Time: 121.15s\n",
      "Ações: Manter=14460, Comprar=11821, Vender=10473\n",
      "Ganhos Totais: 28253.50, Perdas Totais: -188662.75\n",
      "Modelo e log do episódio 92 salvos em: 4.12\\model_episode_92.pth e 4.12\\log_episode_92.csv\n",
      "\n",
      "Episode 93/200, Total Reward: -125947.00, Win Rate: 0.53, Wins: 709, Losses: 627, Epsilon: 0.1964, Steps: 36754, Time: 120.54s\n",
      "Ações: Manter=14304, Comprar=11704, Vender=10746\n",
      "Ganhos Totais: 32165.75, Perdas Totais: -158112.75\n",
      "Modelo e log do episódio 93 salvos em: 4.12\\model_episode_93.pth e 4.12\\log_episode_93.csv\n",
      "\n",
      "Episode 94/200, Total Reward: -154924.25, Win Rate: 0.51, Wins: 646, Losses: 611, Epsilon: 0.1944, Steps: 36754, Time: 120.48s\n",
      "Ações: Manter=14379, Comprar=12204, Vender=10171\n",
      "Ganhos Totais: 27966.75, Perdas Totais: -182891.00\n",
      "Modelo e log do episódio 94 salvos em: 4.12\\model_episode_94.pth e 4.12\\log_episode_94.csv\n",
      "\n",
      "Episode 95/200, Total Reward: -189266.50, Win Rate: 0.48, Wins: 602, Losses: 644, Epsilon: 0.1924, Steps: 36754, Time: 120.24s\n",
      "Ações: Manter=13900, Comprar=11959, Vender=10895\n",
      "Ganhos Totais: 26133.75, Perdas Totais: -215400.25\n",
      "Episode 96/200, Total Reward: -167794.00, Win Rate: 0.51, Wins: 638, Losses: 624, Epsilon: 0.1905, Steps: 36754, Time: 121.10s\n",
      "Ações: Manter=13489, Comprar=11856, Vender=11409\n",
      "Ganhos Totais: 27876.25, Perdas Totais: -195670.25\n",
      "Episode 97/200, Total Reward: -167292.50, Win Rate: 0.52, Wins: 650, Losses: 597, Epsilon: 0.1886, Steps: 36754, Time: 120.30s\n",
      "Ações: Manter=15079, Comprar=10670, Vender=11005\n",
      "Ganhos Totais: 26556.50, Perdas Totais: -193849.00\n",
      "Episode 98/200, Total Reward: -155153.25, Win Rate: 0.51, Wins: 605, Losses: 588, Epsilon: 0.1867, Steps: 36754, Time: 120.48s\n",
      "Ações: Manter=14166, Comprar=11237, Vender=11351\n",
      "Ganhos Totais: 26268.75, Perdas Totais: -181422.00\n",
      "Modelo e log do episódio 98 salvos em: 4.12\\model_episode_98.pth e 4.12\\log_episode_98.csv\n",
      "\n",
      "Episode 99/200, Total Reward: -157151.50, Win Rate: 0.50, Wins: 599, Losses: 603, Epsilon: 0.1849, Steps: 36754, Time: 120.58s\n",
      "Ações: Manter=15054, Comprar=11368, Vender=10332\n",
      "Ganhos Totais: 26152.50, Perdas Totais: -183304.00\n",
      "Modelo e log do episódio 99 salvos em: 4.12\\model_episode_99.pth e 4.12\\log_episode_99.csv\n",
      "\n",
      "Episode 100/200, Total Reward: -149615.00, Win Rate: 0.52, Wins: 662, Losses: 622, Epsilon: 0.1830, Steps: 36754, Time: 120.45s\n",
      "Ações: Manter=14148, Comprar=11769, Vender=10837\n",
      "Ganhos Totais: 29656.00, Perdas Totais: -179271.00\n",
      "Modelo e log do episódio 100 salvos em: 4.12\\model_episode_100.pth e 4.12\\log_episode_100.csv\n",
      "\n",
      "Episode 101/200, Total Reward: -133367.75, Win Rate: 0.51, Wins: 608, Losses: 586, Epsilon: 0.1812, Steps: 36754, Time: 120.84s\n",
      "Ações: Manter=14675, Comprar=11647, Vender=10432\n",
      "Ganhos Totais: 26759.25, Perdas Totais: -160127.00\n",
      "Modelo e log do episódio 101 salvos em: 4.12\\model_episode_101.pth e 4.12\\log_episode_101.csv\n",
      "\n",
      "Episode 102/200, Total Reward: -169111.50, Win Rate: 0.49, Wins: 577, Losses: 595, Epsilon: 0.1794, Steps: 36754, Time: 121.25s\n",
      "Ações: Manter=12462, Comprar=12645, Vender=11647\n",
      "Ganhos Totais: 25517.50, Perdas Totais: -194629.00\n",
      "Episode 103/200, Total Reward: -132094.00, Win Rate: 0.51, Wins: 634, Losses: 605, Epsilon: 0.1776, Steps: 36754, Time: 120.67s\n",
      "Ações: Manter=12676, Comprar=11832, Vender=12246\n",
      "Ganhos Totais: 29010.50, Perdas Totais: -161104.50\n",
      "Modelo e log do episódio 103 salvos em: 4.12\\model_episode_103.pth e 4.12\\log_episode_103.csv\n",
      "\n",
      "Episode 104/200, Total Reward: -138977.75, Win Rate: 0.51, Wins: 617, Losses: 603, Epsilon: 0.1758, Steps: 36754, Time: 121.10s\n",
      "Ações: Manter=12923, Comprar=11053, Vender=12778\n",
      "Ganhos Totais: 28149.25, Perdas Totais: -167127.00\n",
      "Modelo e log do episódio 104 salvos em: 4.12\\model_episode_104.pth e 4.12\\log_episode_104.csv\n",
      "\n",
      "Episode 105/200, Total Reward: -150060.00, Win Rate: 0.52, Wins: 643, Losses: 600, Epsilon: 0.1740, Steps: 36754, Time: 120.69s\n",
      "Ações: Manter=12067, Comprar=11472, Vender=13215\n",
      "Ganhos Totais: 27855.75, Perdas Totais: -177915.75\n",
      "Modelo e log do episódio 105 salvos em: 4.12\\model_episode_105.pth e 4.12\\log_episode_105.csv\n",
      "\n",
      "Episode 106/200, Total Reward: -150054.75, Win Rate: 0.52, Wins: 640, Losses: 600, Epsilon: 0.1723, Steps: 36754, Time: 124.57s\n",
      "Ações: Manter=12516, Comprar=13437, Vender=10801\n",
      "Ganhos Totais: 27711.00, Perdas Totais: -177765.75\n",
      "Modelo e log do episódio 106 salvos em: 4.12\\model_episode_106.pth e 4.12\\log_episode_106.csv\n",
      "\n",
      "Episode 107/200, Total Reward: -151229.25, Win Rate: 0.52, Wins: 636, Losses: 597, Epsilon: 0.1706, Steps: 36754, Time: 122.77s\n",
      "Ações: Manter=13499, Comprar=10675, Vender=12580\n",
      "Ganhos Totais: 27001.50, Perdas Totais: -178230.75\n",
      "Episode 108/200, Total Reward: -154332.00, Win Rate: 0.51, Wins: 601, Losses: 576, Epsilon: 0.1689, Steps: 36754, Time: 123.11s\n",
      "Ações: Manter=14239, Comprar=12393, Vender=10122\n",
      "Ganhos Totais: 26882.25, Perdas Totais: -181214.25\n",
      "Episode 109/200, Total Reward: -148862.00, Win Rate: 0.53, Wins: 607, Losses: 544, Epsilon: 0.1672, Steps: 36754, Time: 122.91s\n",
      "Ações: Manter=12974, Comprar=12394, Vender=11386\n",
      "Ganhos Totais: 25912.00, Perdas Totais: -174774.00\n",
      "Modelo e log do episódio 109 salvos em: 4.12\\model_episode_109.pth e 4.12\\log_episode_109.csv\n",
      "\n",
      "Episode 110/200, Total Reward: -130385.50, Win Rate: 0.52, Wins: 637, Losses: 595, Epsilon: 0.1655, Steps: 36754, Time: 123.06s\n",
      "Ações: Manter=13587, Comprar=11212, Vender=11955\n",
      "Ganhos Totais: 27895.75, Perdas Totais: -158281.25\n",
      "Modelo e log do episódio 110 salvos em: 4.12\\model_episode_110.pth e 4.12\\log_episode_110.csv\n",
      "\n",
      "Episode 111/200, Total Reward: -151212.25, Win Rate: 0.51, Wins: 595, Losses: 569, Epsilon: 0.1639, Steps: 36754, Time: 122.91s\n",
      "Ações: Manter=13951, Comprar=10304, Vender=12499\n",
      "Ganhos Totais: 26028.50, Perdas Totais: -177240.75\n",
      "Episode 112/200, Total Reward: -161484.50, Win Rate: 0.49, Wins: 604, Losses: 620, Epsilon: 0.1622, Steps: 36754, Time: 123.06s\n",
      "Ações: Manter=12493, Comprar=11797, Vender=12464\n",
      "Ganhos Totais: 26190.00, Perdas Totais: -187674.50\n",
      "Episode 113/200, Total Reward: -139795.75, Win Rate: 0.52, Wins: 633, Losses: 595, Epsilon: 0.1606, Steps: 36754, Time: 123.01s\n",
      "Ações: Manter=14505, Comprar=10309, Vender=11940\n",
      "Ganhos Totais: 26514.00, Perdas Totais: -166309.75\n",
      "Modelo e log do episódio 113 salvos em: 4.12\\model_episode_113.pth e 4.12\\log_episode_113.csv\n",
      "\n",
      "Episode 114/200, Total Reward: -145260.50, Win Rate: 0.50, Wins: 579, Losses: 569, Epsilon: 0.1590, Steps: 36754, Time: 123.39s\n",
      "Ações: Manter=13758, Comprar=12432, Vender=10564\n",
      "Ganhos Totais: 24843.50, Perdas Totais: -170104.00\n",
      "Modelo e log do episódio 114 salvos em: 4.12\\model_episode_114.pth e 4.12\\log_episode_114.csv\n",
      "\n",
      "Episode 115/200, Total Reward: -142670.00, Win Rate: 0.52, Wins: 635, Losses: 597, Epsilon: 0.1574, Steps: 36754, Time: 123.08s\n",
      "Ações: Manter=12779, Comprar=10160, Vender=13815\n",
      "Ganhos Totais: 28609.75, Perdas Totais: -171279.75\n",
      "Modelo e log do episódio 115 salvos em: 4.12\\model_episode_115.pth e 4.12\\log_episode_115.csv\n",
      "\n",
      "Episode 116/200, Total Reward: -132041.50, Win Rate: 0.50, Wins: 574, Losses: 564, Epsilon: 0.1558, Steps: 36754, Time: 123.27s\n",
      "Ações: Manter=14620, Comprar=10718, Vender=11416\n",
      "Ganhos Totais: 27382.50, Perdas Totais: -159424.00\n",
      "Modelo e log do episódio 116 salvos em: 4.12\\model_episode_116.pth e 4.12\\log_episode_116.csv\n",
      "\n",
      "Episode 117/200, Total Reward: -125211.25, Win Rate: 0.52, Wins: 611, Losses: 561, Epsilon: 0.1543, Steps: 36754, Time: 123.24s\n",
      "Ações: Manter=13750, Comprar=11230, Vender=11774\n",
      "Ganhos Totais: 27397.00, Perdas Totais: -152608.25\n",
      "Modelo e log do episódio 117 salvos em: 4.12\\model_episode_117.pth e 4.12\\log_episode_117.csv\n",
      "\n",
      "Episode 118/200, Total Reward: -136820.00, Win Rate: 0.52, Wins: 621, Losses: 563, Epsilon: 0.1527, Steps: 36754, Time: 123.20s\n",
      "Ações: Manter=12140, Comprar=10402, Vender=14212\n",
      "Ganhos Totais: 29054.75, Perdas Totais: -165874.75\n",
      "Modelo e log do episódio 118 salvos em: 4.12\\model_episode_118.pth e 4.12\\log_episode_118.csv\n",
      "\n",
      "Episode 119/200, Total Reward: -135336.50, Win Rate: 0.51, Wins: 598, Losses: 571, Epsilon: 0.1512, Steps: 36754, Time: 123.01s\n",
      "Ações: Manter=13654, Comprar=9988, Vender=13112\n",
      "Ganhos Totais: 29272.00, Perdas Totais: -164608.50\n",
      "Modelo e log do episódio 119 salvos em: 4.12\\model_episode_119.pth e 4.12\\log_episode_119.csv\n",
      "\n",
      "Episode 120/200, Total Reward: -123378.00, Win Rate: 0.53, Wins: 599, Losses: 522, Epsilon: 0.1497, Steps: 36754, Time: 122.88s\n",
      "Ações: Manter=14657, Comprar=9629, Vender=12468\n",
      "Ganhos Totais: 28047.00, Perdas Totais: -151425.00\n",
      "Modelo e log do episódio 120 salvos em: 4.12\\model_episode_120.pth e 4.12\\log_episode_120.csv\n",
      "\n",
      "Episode 121/200, Total Reward: -115986.75, Win Rate: 0.50, Wins: 554, Losses: 551, Epsilon: 0.1482, Steps: 36754, Time: 123.04s\n",
      "Ações: Manter=12773, Comprar=10358, Vender=13623\n",
      "Ganhos Totais: 27531.75, Perdas Totais: -143518.50\n",
      "Modelo e log do episódio 121 salvos em: 4.12\\model_episode_121.pth e 4.12\\log_episode_121.csv\n",
      "\n",
      "Episode 122/200, Total Reward: -140104.75, Win Rate: 0.51, Wins: 577, Losses: 552, Epsilon: 0.1467, Steps: 36754, Time: 123.85s\n",
      "Ações: Manter=12556, Comprar=11693, Vender=12505\n",
      "Ganhos Totais: 26252.50, Perdas Totais: -166357.25\n",
      "Episode 123/200, Total Reward: -132850.50, Win Rate: 0.49, Wins: 521, Losses: 539, Epsilon: 0.1452, Steps: 36754, Time: 123.51s\n",
      "Ações: Manter=14353, Comprar=11789, Vender=10612\n",
      "Ganhos Totais: 25863.50, Perdas Totais: -158714.00\n",
      "Modelo e log do episódio 123 salvos em: 4.12\\model_episode_123.pth e 4.12\\log_episode_123.csv\n",
      "\n",
      "Episode 124/200, Total Reward: -140739.50, Win Rate: 0.51, Wins: 561, Losses: 541, Epsilon: 0.1438, Steps: 36754, Time: 123.29s\n",
      "Ações: Manter=12599, Comprar=10854, Vender=13301\n",
      "Ganhos Totais: 27165.00, Perdas Totais: -167904.50\n",
      "Episode 125/200, Total Reward: -122196.00, Win Rate: 0.52, Wins: 583, Losses: 540, Epsilon: 0.1424, Steps: 36754, Time: 123.54s\n",
      "Ações: Manter=12430, Comprar=11659, Vender=12665\n",
      "Ganhos Totais: 27020.50, Perdas Totais: -149216.50\n",
      "Modelo e log do episódio 125 salvos em: 4.12\\model_episode_125.pth e 4.12\\log_episode_125.csv\n",
      "\n",
      "Episode 126/200, Total Reward: -128061.50, Win Rate: 0.52, Wins: 550, Losses: 515, Epsilon: 0.1409, Steps: 36754, Time: 123.61s\n",
      "Ações: Manter=12401, Comprar=11541, Vender=12812\n",
      "Ganhos Totais: 26031.75, Perdas Totais: -154093.25\n",
      "Modelo e log do episódio 126 salvos em: 4.12\\model_episode_126.pth e 4.12\\log_episode_126.csv\n",
      "\n",
      "Episode 127/200, Total Reward: -121957.25, Win Rate: 0.50, Wins: 533, Losses: 540, Epsilon: 0.1395, Steps: 36754, Time: 123.66s\n",
      "Ações: Manter=12217, Comprar=10708, Vender=13829\n",
      "Ganhos Totais: 23743.50, Perdas Totais: -145700.75\n",
      "Modelo e log do episódio 127 salvos em: 4.12\\model_episode_127.pth e 4.12\\log_episode_127.csv\n",
      "\n",
      "Episode 128/200, Total Reward: -121587.75, Win Rate: 0.50, Wins: 491, Losses: 494, Epsilon: 0.1381, Steps: 36754, Time: 123.31s\n",
      "Ações: Manter=15642, Comprar=11074, Vender=10038\n",
      "Ganhos Totais: 23805.25, Perdas Totais: -145393.00\n",
      "Modelo e log do episódio 128 salvos em: 4.12\\model_episode_128.pth e 4.12\\log_episode_128.csv\n",
      "\n",
      "Episode 129/200, Total Reward: -113422.75, Win Rate: 0.53, Wins: 545, Losses: 491, Epsilon: 0.1367, Steps: 36754, Time: 123.71s\n",
      "Ações: Manter=13096, Comprar=10566, Vender=13092\n",
      "Ganhos Totais: 26366.25, Perdas Totais: -139789.00\n",
      "Modelo e log do episódio 129 salvos em: 4.12\\model_episode_129.pth e 4.12\\log_episode_129.csv\n",
      "\n",
      "Episode 130/200, Total Reward: -139692.00, Win Rate: 0.50, Wins: 544, Losses: 550, Epsilon: 0.1354, Steps: 36754, Time: 124.27s\n",
      "Ações: Manter=14057, Comprar=11275, Vender=11422\n",
      "Ganhos Totais: 25505.25, Perdas Totais: -165197.25\n",
      "Episode 131/200, Total Reward: -116666.75, Win Rate: 0.52, Wins: 536, Losses: 491, Epsilon: 0.1340, Steps: 36754, Time: 123.86s\n",
      "Ações: Manter=12776, Comprar=11359, Vender=12619\n",
      "Ganhos Totais: 26392.75, Perdas Totais: -143059.50\n",
      "Modelo e log do episódio 131 salvos em: 4.12\\model_episode_131.pth e 4.12\\log_episode_131.csv\n",
      "\n",
      "Episode 132/200, Total Reward: -110852.00, Win Rate: 0.49, Wins: 518, Losses: 530, Epsilon: 0.1327, Steps: 36754, Time: 123.72s\n",
      "Ações: Manter=13314, Comprar=9899, Vender=13541\n",
      "Ganhos Totais: 25708.75, Perdas Totais: -136560.75\n",
      "Modelo e log do episódio 132 salvos em: 4.12\\model_episode_132.pth e 4.12\\log_episode_132.csv\n",
      "\n",
      "Episode 133/200, Total Reward: -113811.00, Win Rate: 0.53, Wins: 554, Losses: 499, Epsilon: 0.1314, Steps: 36754, Time: 123.70s\n",
      "Ações: Manter=13459, Comprar=10863, Vender=12432\n",
      "Ganhos Totais: 27923.50, Perdas Totais: -141734.50\n",
      "Modelo e log do episódio 133 salvos em: 4.12\\model_episode_133.pth e 4.12\\log_episode_133.csv\n",
      "\n",
      "Episode 134/200, Total Reward: -127146.75, Win Rate: 0.54, Wins: 589, Losses: 495, Epsilon: 0.1300, Steps: 36754, Time: 124.30s\n",
      "Ações: Manter=14374, Comprar=10392, Vender=11988\n",
      "Ganhos Totais: 27664.75, Perdas Totais: -154811.50\n",
      "Episode 135/200, Total Reward: -122909.25, Win Rate: 0.49, Wins: 471, Losses: 490, Epsilon: 0.1287, Steps: 36754, Time: 124.14s\n",
      "Ações: Manter=13685, Comprar=9995, Vender=13074\n",
      "Ganhos Totais: 26177.50, Perdas Totais: -149086.75\n",
      "Modelo e log do episódio 135 salvos em: 4.12\\model_episode_135.pth e 4.12\\log_episode_135.csv\n",
      "\n",
      "Episode 136/200, Total Reward: -109770.25, Win Rate: 0.50, Wins: 484, Losses: 486, Epsilon: 0.1275, Steps: 36754, Time: 123.91s\n",
      "Ações: Manter=13597, Comprar=10110, Vender=13047\n",
      "Ganhos Totais: 26415.75, Perdas Totais: -136186.00\n",
      "Modelo e log do episódio 136 salvos em: 4.12\\model_episode_136.pth e 4.12\\log_episode_136.csv\n",
      "\n",
      "Episode 137/200, Total Reward: -119984.00, Win Rate: 0.50, Wins: 523, Losses: 519, Epsilon: 0.1262, Steps: 36754, Time: 124.11s\n",
      "Ações: Manter=12857, Comprar=10372, Vender=13525\n",
      "Ganhos Totais: 25957.50, Perdas Totais: -145941.50\n",
      "Modelo e log do episódio 137 salvos em: 4.12\\model_episode_137.pth e 4.12\\log_episode_137.csv\n",
      "\n",
      "Episode 138/200, Total Reward: -133037.50, Win Rate: 0.51, Wins: 504, Losses: 489, Epsilon: 0.1249, Steps: 36754, Time: 123.92s\n",
      "Ações: Manter=10836, Comprar=10918, Vender=15000\n",
      "Ganhos Totais: 23266.75, Perdas Totais: -156304.25\n",
      "Episode 139/200, Total Reward: -120469.75, Win Rate: 0.48, Wins: 454, Losses: 488, Epsilon: 0.1237, Steps: 36754, Time: 124.33s\n",
      "Ações: Manter=14409, Comprar=10136, Vender=12209\n",
      "Ganhos Totais: 25738.75, Perdas Totais: -146208.50\n",
      "Modelo e log do episódio 139 salvos em: 4.12\\model_episode_139.pth e 4.12\\log_episode_139.csv\n",
      "\n",
      "Episode 140/200, Total Reward: -102238.25, Win Rate: 0.50, Wins: 500, Losses: 502, Epsilon: 0.1224, Steps: 36754, Time: 124.00s\n",
      "Ações: Manter=12577, Comprar=10725, Vender=13452\n",
      "Ganhos Totais: 27034.50, Perdas Totais: -129272.75\n",
      "Modelo e log do episódio 140 salvos em: 4.12\\model_episode_140.pth e 4.12\\log_episode_140.csv\n",
      "\n",
      "Episode 141/200, Total Reward: -107686.25, Win Rate: 0.52, Wins: 492, Losses: 457, Epsilon: 0.1212, Steps: 36754, Time: 124.47s\n",
      "Ações: Manter=12695, Comprar=10659, Vender=13400\n",
      "Ganhos Totais: 24921.25, Perdas Totais: -132607.50\n",
      "Modelo e log do episódio 141 salvos em: 4.12\\model_episode_141.pth e 4.12\\log_episode_141.csv\n",
      "\n",
      "Episode 142/200, Total Reward: -108924.00, Win Rate: 0.52, Wins: 505, Losses: 459, Epsilon: 0.1200, Steps: 36754, Time: 123.91s\n",
      "Ações: Manter=11615, Comprar=10715, Vender=14424\n",
      "Ganhos Totais: 25914.50, Perdas Totais: -134838.50\n",
      "Modelo e log do episódio 142 salvos em: 4.12\\model_episode_142.pth e 4.12\\log_episode_142.csv\n",
      "\n",
      "Episode 143/200, Total Reward: -96116.00, Win Rate: 0.51, Wins: 502, Losses: 483, Epsilon: 0.1188, Steps: 36754, Time: 124.68s\n",
      "Ações: Manter=11790, Comprar=10480, Vender=14484\n",
      "Ganhos Totais: 27536.25, Perdas Totais: -123652.25\n",
      "Modelo e log do episódio 143 salvos em: 4.12\\model_episode_143.pth e 4.12\\log_episode_143.csv\n",
      "\n",
      "Episode 144/200, Total Reward: -116388.75, Win Rate: 0.51, Wins: 487, Losses: 467, Epsilon: 0.1176, Steps: 36754, Time: 124.19s\n",
      "Ações: Manter=11456, Comprar=10680, Vender=14618\n",
      "Ganhos Totais: 27079.50, Perdas Totais: -143468.25\n",
      "Modelo e log do episódio 144 salvos em: 4.12\\model_episode_144.pth e 4.12\\log_episode_144.csv\n",
      "\n",
      "Episode 145/200, Total Reward: -129744.00, Win Rate: 0.51, Wins: 528, Losses: 503, Epsilon: 0.1164, Steps: 36754, Time: 123.99s\n",
      "Ações: Manter=11682, Comprar=10499, Vender=14573\n",
      "Ganhos Totais: 25087.25, Perdas Totais: -154831.25\n",
      "Episode 146/200, Total Reward: -98644.50, Win Rate: 0.53, Wins: 559, Losses: 490, Epsilon: 0.1153, Steps: 36754, Time: 124.57s\n",
      "Ações: Manter=13247, Comprar=11304, Vender=12203\n",
      "Ganhos Totais: 26506.50, Perdas Totais: -125151.00\n",
      "Modelo e log do episódio 146 salvos em: 4.12\\model_episode_146.pth e 4.12\\log_episode_146.csv\n",
      "\n",
      "Episode 147/200, Total Reward: -102919.75, Win Rate: 0.53, Wins: 550, Losses: 493, Epsilon: 0.1141, Steps: 36754, Time: 124.24s\n",
      "Ações: Manter=12940, Comprar=10368, Vender=13446\n",
      "Ganhos Totais: 28721.25, Perdas Totais: -131641.00\n",
      "Modelo e log do episódio 147 salvos em: 4.12\\model_episode_147.pth e 4.12\\log_episode_147.csv\n",
      "\n",
      "Episode 148/200, Total Reward: -108365.50, Win Rate: 0.50, Wins: 490, Losses: 496, Epsilon: 0.1130, Steps: 36754, Time: 124.24s\n",
      "Ações: Manter=11921, Comprar=9611, Vender=15222\n",
      "Ganhos Totais: 25339.25, Perdas Totais: -133704.75\n",
      "Modelo e log do episódio 148 salvos em: 4.12\\model_episode_148.pth e 4.12\\log_episode_148.csv\n",
      "\n",
      "Episode 149/200, Total Reward: -110456.75, Win Rate: 0.51, Wins: 460, Losses: 445, Epsilon: 0.1118, Steps: 36754, Time: 124.35s\n",
      "Ações: Manter=14139, Comprar=9549, Vender=13066\n",
      "Ganhos Totais: 25006.50, Perdas Totais: -135463.25\n",
      "Modelo e log do episódio 149 salvos em: 4.12\\model_episode_149.pth e 4.12\\log_episode_149.csv\n",
      "\n",
      "Episode 150/200, Total Reward: -101342.25, Win Rate: 0.51, Wins: 510, Losses: 486, Epsilon: 0.1107, Steps: 36754, Time: 124.22s\n",
      "Ações: Manter=13783, Comprar=10528, Vender=12443\n",
      "Ganhos Totais: 26502.75, Perdas Totais: -127845.00\n",
      "Modelo e log do episódio 150 salvos em: 4.12\\model_episode_150.pth e 4.12\\log_episode_150.csv\n",
      "\n",
      "Episode 151/200, Total Reward: -122218.75, Win Rate: 0.50, Wins: 500, Losses: 504, Epsilon: 0.1096, Steps: 36754, Time: 124.95s\n",
      "Ações: Manter=13684, Comprar=9441, Vender=13629\n",
      "Ganhos Totais: 24712.50, Perdas Totais: -146931.25\n",
      "Episode 152/200, Total Reward: -113478.00, Win Rate: 0.48, Wins: 473, Losses: 511, Epsilon: 0.1085, Steps: 36754, Time: 124.09s\n",
      "Ações: Manter=13214, Comprar=9086, Vender=14454\n",
      "Ganhos Totais: 24035.00, Perdas Totais: -137513.00\n",
      "Episode 153/200, Total Reward: -97316.75, Win Rate: 0.51, Wins: 502, Losses: 485, Epsilon: 0.1074, Steps: 36754, Time: 124.48s\n",
      "Ações: Manter=13715, Comprar=10428, Vender=12611\n",
      "Ganhos Totais: 25036.25, Perdas Totais: -122353.00\n",
      "Modelo e log do episódio 153 salvos em: 4.12\\model_episode_153.pth e 4.12\\log_episode_153.csv\n",
      "\n",
      "Episode 154/200, Total Reward: -107312.50, Win Rate: 0.49, Wins: 461, Losses: 478, Epsilon: 0.1064, Steps: 36754, Time: 123.34s\n",
      "Ações: Manter=13808, Comprar=10841, Vender=12105\n",
      "Ganhos Totais: 25398.75, Perdas Totais: -132711.25\n",
      "Modelo e log do episódio 154 salvos em: 4.12\\model_episode_154.pth e 4.12\\log_episode_154.csv\n",
      "\n",
      "Episode 155/200, Total Reward: -109027.25, Win Rate: 0.53, Wins: 556, Losses: 486, Epsilon: 0.1053, Steps: 36754, Time: 124.22s\n",
      "Ações: Manter=13161, Comprar=10705, Vender=12888\n",
      "Ganhos Totais: 28653.25, Perdas Totais: -137680.50\n",
      "Episode 156/200, Total Reward: -109563.25, Win Rate: 0.49, Wins: 478, Losses: 490, Epsilon: 0.1042, Steps: 36754, Time: 123.96s\n",
      "Ações: Manter=14554, Comprar=9751, Vender=12449\n",
      "Ganhos Totais: 25968.00, Perdas Totais: -135531.25\n",
      "Episode 157/200, Total Reward: -115702.00, Win Rate: 0.52, Wins: 524, Losses: 491, Epsilon: 0.1032, Steps: 36754, Time: 124.34s\n",
      "Ações: Manter=12983, Comprar=10988, Vender=12783\n",
      "Ganhos Totais: 27487.00, Perdas Totais: -143189.00\n",
      "Episode 158/200, Total Reward: -98439.25, Win Rate: 0.53, Wins: 477, Losses: 428, Epsilon: 0.1022, Steps: 36754, Time: 124.87s\n",
      "Ações: Manter=11818, Comprar=9436, Vender=15500\n",
      "Ganhos Totais: 26217.00, Perdas Totais: -124656.25\n",
      "Modelo e log do episódio 158 salvos em: 4.12\\model_episode_158.pth e 4.12\\log_episode_158.csv\n",
      "\n",
      "Episode 159/200, Total Reward: -85382.00, Win Rate: 0.52, Wins: 494, Losses: 464, Epsilon: 0.1012, Steps: 36754, Time: 124.55s\n",
      "Ações: Manter=11982, Comprar=10470, Vender=14302\n",
      "Ganhos Totais: 25838.50, Perdas Totais: -111220.50\n",
      "Modelo e log do episódio 159 salvos em: 4.12\\model_episode_159.pth e 4.12\\log_episode_159.csv\n",
      "\n",
      "Episode 160/200, Total Reward: -92011.50, Win Rate: 0.53, Wins: 470, Losses: 421, Epsilon: 0.1001, Steps: 36754, Time: 124.54s\n",
      "Ações: Manter=12639, Comprar=10199, Vender=13916\n",
      "Ganhos Totais: 25431.00, Perdas Totais: -117442.50\n",
      "Modelo e log do episódio 160 salvos em: 4.12\\model_episode_160.pth e 4.12\\log_episode_160.csv\n",
      "\n",
      "Episode 161/200, Total Reward: -90794.50, Win Rate: 0.54, Wins: 541, Losses: 463, Epsilon: 0.0991, Steps: 36754, Time: 124.31s\n",
      "Ações: Manter=12677, Comprar=9791, Vender=14286\n",
      "Ganhos Totais: 27824.00, Perdas Totais: -118618.50\n",
      "Modelo e log do episódio 161 salvos em: 4.12\\model_episode_161.pth e 4.12\\log_episode_161.csv\n",
      "\n",
      "Episode 162/200, Total Reward: -96006.25, Win Rate: 0.52, Wins: 473, Losses: 439, Epsilon: 0.0981, Steps: 36754, Time: 124.75s\n",
      "Ações: Manter=12241, Comprar=10289, Vender=14224\n",
      "Ganhos Totais: 27700.00, Perdas Totais: -123706.25\n",
      "Modelo e log do episódio 162 salvos em: 4.12\\model_episode_162.pth e 4.12\\log_episode_162.csv\n",
      "\n",
      "Episode 163/200, Total Reward: -110373.50, Win Rate: 0.51, Wins: 445, Losses: 430, Epsilon: 0.0972, Steps: 36754, Time: 124.78s\n",
      "Ações: Manter=14710, Comprar=9704, Vender=12340\n",
      "Ganhos Totais: 24514.50, Perdas Totais: -134888.00\n",
      "Episode 164/200, Total Reward: -103322.50, Win Rate: 0.50, Wins: 466, Losses: 474, Epsilon: 0.0962, Steps: 36754, Time: 124.41s\n",
      "Ações: Manter=11567, Comprar=11841, Vender=13346\n",
      "Ganhos Totais: 24242.00, Perdas Totais: -127564.50\n",
      "Episode 165/200, Total Reward: -73496.00, Win Rate: 0.51, Wins: 449, Losses: 430, Epsilon: 0.0952, Steps: 36754, Time: 124.58s\n",
      "Ações: Manter=13023, Comprar=12048, Vender=11683\n",
      "Ganhos Totais: 25474.00, Perdas Totais: -98970.00\n",
      "Modelo e log do episódio 165 salvos em: 4.12\\model_episode_165.pth e 4.12\\log_episode_165.csv\n",
      "\n",
      "Episode 166/200, Total Reward: -100563.00, Win Rate: 0.50, Wins: 467, Losses: 463, Epsilon: 0.0943, Steps: 36754, Time: 124.24s\n",
      "Ações: Manter=11501, Comprar=10900, Vender=14353\n",
      "Ganhos Totais: 24916.25, Perdas Totais: -125479.25\n",
      "Modelo e log do episódio 166 salvos em: 4.12\\model_episode_166.pth e 4.12\\log_episode_166.csv\n",
      "\n",
      "Episode 167/200, Total Reward: -85730.00, Win Rate: 0.51, Wins: 467, Losses: 450, Epsilon: 0.0933, Steps: 36754, Time: 124.89s\n",
      "Ações: Manter=12513, Comprar=11164, Vender=13077\n",
      "Ganhos Totais: 25556.50, Perdas Totais: -111286.50\n",
      "Modelo e log do episódio 167 salvos em: 4.12\\model_episode_167.pth e 4.12\\log_episode_167.csv\n",
      "\n",
      "Episode 168/200, Total Reward: -83934.00, Win Rate: 0.50, Wins: 450, Losses: 457, Epsilon: 0.0924, Steps: 36754, Time: 124.70s\n",
      "Ações: Manter=12730, Comprar=11229, Vender=12795\n",
      "Ganhos Totais: 25879.00, Perdas Totais: -109813.00\n",
      "Modelo e log do episódio 168 salvos em: 4.12\\model_episode_168.pth e 4.12\\log_episode_168.csv\n",
      "\n",
      "Episode 169/200, Total Reward: -99838.50, Win Rate: 0.51, Wins: 485, Losses: 461, Epsilon: 0.0915, Steps: 36754, Time: 124.39s\n",
      "Ações: Manter=11769, Comprar=11263, Vender=13722\n",
      "Ganhos Totais: 24284.00, Perdas Totais: -124122.50\n",
      "Episode 170/200, Total Reward: -100286.75, Win Rate: 0.52, Wins: 464, Losses: 436, Epsilon: 0.0906, Steps: 36754, Time: 125.10s\n",
      "Ações: Manter=13934, Comprar=10172, Vender=12648\n",
      "Ganhos Totais: 25495.00, Perdas Totais: -125781.75\n",
      "Episode 171/200, Total Reward: -65033.50, Win Rate: 0.54, Wins: 503, Losses: 422, Epsilon: 0.0897, Steps: 36754, Time: 124.90s\n",
      "Ações: Manter=12131, Comprar=10372, Vender=14251\n",
      "Ganhos Totais: 27956.50, Perdas Totais: -92990.00\n",
      "Modelo e log do episódio 171 salvos em: 4.12\\model_episode_171.pth e 4.12\\log_episode_171.csv\n",
      "\n",
      "Episode 172/200, Total Reward: -109458.00, Win Rate: 0.51, Wins: 438, Losses: 413, Epsilon: 0.0888, Steps: 36754, Time: 124.82s\n",
      "Ações: Manter=12721, Comprar=11842, Vender=12191\n",
      "Ganhos Totais: 25573.50, Perdas Totais: -135031.50\n",
      "Episode 173/200, Total Reward: -92245.50, Win Rate: 0.50, Wins: 423, Losses: 426, Epsilon: 0.0879, Steps: 36754, Time: 124.73s\n",
      "Ações: Manter=12508, Comprar=10698, Vender=13548\n",
      "Ganhos Totais: 24860.25, Perdas Totais: -117105.75\n",
      "Modelo e log do episódio 173 salvos em: 4.12\\model_episode_173.pth e 4.12\\log_episode_173.csv\n",
      "\n",
      "Episode 174/200, Total Reward: -73551.50, Win Rate: 0.51, Wins: 439, Losses: 417, Epsilon: 0.0870, Steps: 36754, Time: 124.41s\n",
      "Ações: Manter=10754, Comprar=11443, Vender=14557\n",
      "Ganhos Totais: 27650.25, Perdas Totais: -101201.75\n",
      "Modelo e log do episódio 174 salvos em: 4.12\\model_episode_174.pth e 4.12\\log_episode_174.csv\n",
      "\n",
      "Episode 175/200, Total Reward: -92643.25, Win Rate: 0.53, Wins: 467, Losses: 419, Epsilon: 0.0861, Steps: 36754, Time: 124.81s\n",
      "Ações: Manter=11827, Comprar=10961, Vender=13966\n",
      "Ganhos Totais: 25367.25, Perdas Totais: -118010.50\n",
      "Modelo e log do episódio 175 salvos em: 4.12\\model_episode_175.pth e 4.12\\log_episode_175.csv\n",
      "\n",
      "Episode 176/200, Total Reward: -93979.25, Win Rate: 0.51, Wins: 439, Losses: 425, Epsilon: 0.0853, Steps: 36754, Time: 124.73s\n",
      "Ações: Manter=13123, Comprar=9298, Vender=14333\n",
      "Ganhos Totais: 24396.25, Perdas Totais: -118375.50\n",
      "Episode 177/200, Total Reward: -104786.00, Win Rate: 0.50, Wins: 431, Losses: 437, Epsilon: 0.0844, Steps: 36754, Time: 124.65s\n",
      "Ações: Manter=12537, Comprar=9583, Vender=14634\n",
      "Ganhos Totais: 23618.25, Perdas Totais: -128404.25\n",
      "Episode 178/200, Total Reward: -83716.25, Win Rate: 0.52, Wins: 425, Losses: 399, Epsilon: 0.0836, Steps: 36754, Time: 124.56s\n",
      "Ações: Manter=13372, Comprar=10365, Vender=13017\n",
      "Ganhos Totais: 25803.00, Perdas Totais: -109519.25\n",
      "Modelo e log do episódio 178 salvos em: 4.12\\model_episode_178.pth e 4.12\\log_episode_178.csv\n",
      "\n",
      "Episode 179/200, Total Reward: -80642.75, Win Rate: 0.54, Wins: 490, Losses: 420, Epsilon: 0.0827, Steps: 36754, Time: 124.40s\n",
      "Ações: Manter=12244, Comprar=10592, Vender=13918\n",
      "Ganhos Totais: 28916.00, Perdas Totais: -109558.75\n",
      "Modelo e log do episódio 179 salvos em: 4.12\\model_episode_179.pth e 4.12\\log_episode_179.csv\n",
      "\n",
      "Episode 180/200, Total Reward: -79643.75, Win Rate: 0.50, Wins: 436, Losses: 429, Epsilon: 0.0819, Steps: 36754, Time: 124.93s\n",
      "Ações: Manter=11823, Comprar=9666, Vender=15265\n",
      "Ganhos Totais: 26610.75, Perdas Totais: -106254.50\n",
      "Modelo e log do episódio 180 salvos em: 4.12\\model_episode_180.pth e 4.12\\log_episode_180.csv\n",
      "\n",
      "Episode 181/200, Total Reward: -81273.00, Win Rate: 0.51, Wins: 433, Losses: 411, Epsilon: 0.0811, Steps: 36754, Time: 124.58s\n",
      "Ações: Manter=13237, Comprar=10233, Vender=13284\n",
      "Ganhos Totais: 27019.25, Perdas Totais: -108292.25\n",
      "Modelo e log do episódio 181 salvos em: 4.12\\model_episode_181.pth e 4.12\\log_episode_181.csv\n",
      "\n",
      "Episode 182/200, Total Reward: -84942.75, Win Rate: 0.53, Wins: 512, Losses: 447, Epsilon: 0.0803, Steps: 36754, Time: 124.49s\n",
      "Ações: Manter=12087, Comprar=10834, Vender=13833\n",
      "Ganhos Totais: 26001.25, Perdas Totais: -110944.00\n",
      "Modelo e log do episódio 182 salvos em: 4.12\\model_episode_182.pth e 4.12\\log_episode_182.csv\n",
      "\n",
      "Episode 183/200, Total Reward: -75376.50, Win Rate: 0.52, Wins: 441, Losses: 403, Epsilon: 0.0795, Steps: 36754, Time: 124.28s\n",
      "Ações: Manter=11668, Comprar=10068, Vender=15018\n",
      "Ganhos Totais: 25854.50, Perdas Totais: -101231.00\n",
      "Modelo e log do episódio 183 salvos em: 4.12\\model_episode_183.pth e 4.12\\log_episode_183.csv\n",
      "\n",
      "Episode 184/200, Total Reward: -86432.75, Win Rate: 0.53, Wins: 475, Losses: 425, Epsilon: 0.0787, Steps: 36754, Time: 124.14s\n",
      "Ações: Manter=12020, Comprar=10337, Vender=14397\n",
      "Ganhos Totais: 28415.75, Perdas Totais: -114848.50\n",
      "Episode 185/200, Total Reward: -87089.75, Win Rate: 0.51, Wins: 466, Losses: 450, Epsilon: 0.0779, Steps: 36754, Time: 124.30s\n",
      "Ações: Manter=10110, Comprar=9724, Vender=16920\n",
      "Ganhos Totais: 26611.00, Perdas Totais: -113700.75\n",
      "Episode 186/200, Total Reward: -81411.25, Win Rate: 0.51, Wins: 463, Losses: 444, Epsilon: 0.0771, Steps: 36754, Time: 124.92s\n",
      "Ações: Manter=12214, Comprar=9695, Vender=14845\n",
      "Ganhos Totais: 25579.00, Perdas Totais: -106990.25\n",
      "Modelo e log do episódio 186 salvos em: 4.12\\model_episode_186.pth e 4.12\\log_episode_186.csv\n",
      "\n",
      "Episode 187/200, Total Reward: -74904.00, Win Rate: 0.54, Wins: 474, Losses: 408, Epsilon: 0.0763, Steps: 36754, Time: 124.73s\n",
      "Ações: Manter=11279, Comprar=10653, Vender=14822\n",
      "Ganhos Totais: 27532.50, Perdas Totais: -102436.50\n",
      "Modelo e log do episódio 187 salvos em: 4.12\\model_episode_187.pth e 4.12\\log_episode_187.csv\n",
      "\n",
      "Episode 188/200, Total Reward: -79589.50, Win Rate: 0.50, Wins: 431, Losses: 438, Epsilon: 0.0756, Steps: 36754, Time: 124.29s\n",
      "Ações: Manter=10818, Comprar=12067, Vender=13869\n",
      "Ganhos Totais: 25960.75, Perdas Totais: -105550.25\n",
      "Modelo e log do episódio 188 salvos em: 4.12\\model_episode_188.pth e 4.12\\log_episode_188.csv\n",
      "\n",
      "Episode 189/200, Total Reward: -75254.00, Win Rate: 0.52, Wins: 461, Losses: 433, Epsilon: 0.0748, Steps: 36754, Time: 125.63s\n",
      "Ações: Manter=11299, Comprar=11047, Vender=14408\n",
      "Ganhos Totais: 26976.75, Perdas Totais: -102230.75\n",
      "Modelo e log do episódio 189 salvos em: 4.12\\model_episode_189.pth e 4.12\\log_episode_189.csv\n",
      "\n",
      "Episode 190/200, Total Reward: -80171.50, Win Rate: 0.51, Wins: 431, Losses: 416, Epsilon: 0.0741, Steps: 36754, Time: 124.17s\n",
      "Ações: Manter=10847, Comprar=10003, Vender=15904\n",
      "Ganhos Totais: 26291.00, Perdas Totais: -106462.50\n",
      "Modelo e log do episódio 190 salvos em: 4.12\\model_episode_190.pth e 4.12\\log_episode_190.csv\n",
      "\n",
      "Episode 191/200, Total Reward: -78278.00, Win Rate: 0.51, Wins: 438, Losses: 417, Epsilon: 0.0733, Steps: 36754, Time: 124.52s\n",
      "Ações: Manter=11080, Comprar=10653, Vender=15021\n",
      "Ganhos Totais: 25643.50, Perdas Totais: -103921.50\n",
      "Modelo e log do episódio 191 salvos em: 4.12\\model_episode_191.pth e 4.12\\log_episode_191.csv\n",
      "\n",
      "Episode 192/200, Total Reward: -84088.75, Win Rate: 0.52, Wins: 522, Losses: 480, Epsilon: 0.0726, Steps: 36754, Time: 124.72s\n",
      "Ações: Manter=12509, Comprar=10096, Vender=14149\n",
      "Ganhos Totais: 26639.75, Perdas Totais: -110728.50\n",
      "Episode 193/200, Total Reward: -84445.50, Win Rate: 0.53, Wins: 508, Losses: 446, Epsilon: 0.0719, Steps: 36754, Time: 124.47s\n",
      "Ações: Manter=13324, Comprar=9507, Vender=13923\n",
      "Ganhos Totais: 28162.00, Perdas Totais: -112607.50\n",
      "Episode 194/200, Total Reward: -98510.75, Win Rate: 0.56, Wins: 538, Losses: 422, Epsilon: 0.0712, Steps: 36754, Time: 124.65s\n",
      "Ações: Manter=11670, Comprar=10878, Vender=14206\n",
      "Ganhos Totais: 26064.50, Perdas Totais: -124575.25\n",
      "Episode 195/200, Total Reward: -82863.50, Win Rate: 0.52, Wins: 466, Losses: 435, Epsilon: 0.0704, Steps: 36754, Time: 124.58s\n",
      "Ações: Manter=13783, Comprar=9521, Vender=13450\n",
      "Ganhos Totais: 25545.00, Perdas Totais: -108408.50\n",
      "Episode 196/200, Total Reward: -95596.00, Win Rate: 0.52, Wins: 486, Losses: 455, Epsilon: 0.0697, Steps: 36754, Time: 125.00s\n",
      "Ações: Manter=14535, Comprar=8812, Vender=13407\n",
      "Ganhos Totais: 25133.75, Perdas Totais: -120729.75\n",
      "Episode 197/200, Total Reward: -77628.50, Win Rate: 0.51, Wins: 445, Losses: 428, Epsilon: 0.0690, Steps: 36754, Time: 124.65s\n",
      "Ações: Manter=13953, Comprar=9417, Vender=13384\n",
      "Ganhos Totais: 26415.00, Perdas Totais: -104043.50\n",
      "Modelo e log do episódio 197 salvos em: 4.12\\model_episode_197.pth e 4.12\\log_episode_197.csv\n",
      "\n",
      "Episode 198/200, Total Reward: -94160.75, Win Rate: 0.52, Wins: 493, Losses: 456, Epsilon: 0.0684, Steps: 36754, Time: 134.13s\n",
      "Ações: Manter=14481, Comprar=9875, Vender=12398\n",
      "Ganhos Totais: 25727.00, Perdas Totais: -119887.75\n",
      "Episode 199/200, Total Reward: -73801.75, Win Rate: 0.52, Wins: 439, Losses: 407, Epsilon: 0.0677, Steps: 36754, Time: 131.90s\n",
      "Ações: Manter=16249, Comprar=8453, Vender=12052\n",
      "Ganhos Totais: 24658.50, Perdas Totais: -98460.25\n",
      "Modelo e log do episódio 199 salvos em: 4.12\\model_episode_199.pth e 4.12\\log_episode_199.csv\n",
      "\n",
      "Episode 200/200, Total Reward: -69232.00, Win Rate: 0.52, Wins: 486, Losses: 457, Epsilon: 0.0670, Steps: 36754, Time: 125.69s\n",
      "Ações: Manter=15734, Comprar=8293, Vender=12727\n",
      "Ganhos Totais: 25227.50, Perdas Totais: -94459.50\n",
      "Modelo e log do episódio 200 salvos em: 4.12\\model_episode_200.pth e 4.12\\log_episode_200.csv\n",
      "\n",
      "\n",
      "Treinamento finalizado.\n",
      "Top 10 Melhores Episódios:\n",
      "Rank 1: Episode 171, Total Reward: -65033.50, Win Rate: 0.54, Wins: 503, Losses: 422, Ações: {0: 12131, 1: 10372, 2: 14251}, Steps: 36754, Time: 124.90s\n",
      "Rank 2: Episode 200, Total Reward: -69232.00, Win Rate: 0.52, Wins: 486, Losses: 457, Ações: {0: 15734, 1: 8293, 2: 12727}, Steps: 36754, Time: 125.69s\n",
      "Rank 3: Episode 165, Total Reward: -73496.00, Win Rate: 0.51, Wins: 449, Losses: 430, Ações: {0: 13023, 1: 12048, 2: 11683}, Steps: 36754, Time: 124.58s\n",
      "Rank 4: Episode 174, Total Reward: -73551.50, Win Rate: 0.51, Wins: 439, Losses: 417, Ações: {0: 10754, 1: 11443, 2: 14557}, Steps: 36754, Time: 124.41s\n",
      "Rank 5: Episode 199, Total Reward: -73801.75, Win Rate: 0.52, Wins: 439, Losses: 407, Ações: {0: 16249, 1: 8453, 2: 12052}, Steps: 36754, Time: 131.90s\n",
      "Rank 6: Episode 187, Total Reward: -74904.00, Win Rate: 0.54, Wins: 474, Losses: 408, Ações: {0: 11279, 1: 10653, 2: 14822}, Steps: 36754, Time: 124.73s\n",
      "Rank 7: Episode 189, Total Reward: -75254.00, Win Rate: 0.52, Wins: 461, Losses: 433, Ações: {0: 11299, 1: 11047, 2: 14408}, Steps: 36754, Time: 125.63s\n",
      "Rank 8: Episode 183, Total Reward: -75376.50, Win Rate: 0.52, Wins: 441, Losses: 403, Ações: {0: 11668, 1: 10068, 2: 15018}, Steps: 36754, Time: 124.28s\n",
      "Rank 9: Episode 197, Total Reward: -77628.50, Win Rate: 0.51, Wins: 445, Losses: 428, Ações: {0: 13953, 1: 9417, 2: 13384}, Steps: 36754, Time: 124.65s\n",
      "Rank 10: Episode 191, Total Reward: -78278.00, Win Rate: 0.51, Wins: 438, Losses: 417, Ações: {0: 11080, 1: 10653, 2: 15021}, Steps: 36754, Time: 124.52s\n"
     ]
    }
   ],
   "source": [
    "# Bloco 1: Preparar os Dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import os\n",
    "data = pd.read_csv('D:\\\\dados\\\\bar_M15_V03_data_01-01-2023_a_31-08-2024.csv')\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "# filtra o dataframe para pegar apenas o mês de 08 de 2024\n",
    "#data = data[(data['DateTime'] >= '2024-08-01') & (data['DateTime'] <= '2024-08-31')]\n",
    "\n",
    "# Criar a coluna \"Valor\", que é uma cópia de \"Close\" e não será normalizada\n",
    "data['Valor'] = data['Close']\n",
    "\n",
    "# Normalizar as colunas necessárias (exceto \"Valor\" e \"Gatilho\")\n",
    "scaler = MinMaxScaler()\n",
    "cols_to_normalize = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'PavioSuperior', 'PavioInferior',\n",
    "    'Corpo', 'Range','SMA4','SMA8','SMA12','SMA20', 'SMA50', 'SMA100', 'SMA200', 'StochasticoK',\n",
    "    'StochasticoD', 'RSI', 'MACD', 'MACDSignal', 'MACDHistogram','atr8','atr14','atr28','dayO','dayH','dayL'\n",
    "]\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "# Converter todos os valores para tipo float32 para evitar problemas de tipo\n",
    "data = data.astype({col: 'float32' for col in cols_to_normalize + ['Valor']})\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.current_step = 0\n",
    "        self.position = 0  # 0 = neutro, 1 = comprado, -1 = vendido\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None\n",
    "        self.entry_datetime = None  # Novo atributo para armazenar o DateTime de entrada\n",
    "        self.action_space = spaces.Discrete(3)  # 0 = Manter, 1 = Comprar, 2 = Vender\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(len(data.columns) - 3 + 1,), dtype=np.float32\n",
    "        )\n",
    "        self.trades = []  # Lista para armazenar as operações realizadas\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.position = 0\n",
    "        self.entry_price = 0.0\n",
    "        self.entry_step = None\n",
    "        self.entry_datetime = None\n",
    "        self.trades = []\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = self.data.iloc[self.current_step].drop(['Valor', 'DateTime', 'Gatilho']).values\n",
    "        obs = np.append(obs, self.position)  # Incluir a posição atual na observação\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        done = self.current_step >= len(self.data) - 2  # Ajustado para evitar índice fora do intervalo\n",
    "        reward = 0\n",
    "        info = {}\n",
    "\n",
    "        # Obter o valor atual e o próximo valor\n",
    "        current_price = self.data['Valor'].iloc[self.current_step]\n",
    "        next_price = self.data['Valor'].iloc[self.current_step + 1]\n",
    "        price_change = next_price - current_price\n",
    "\n",
    "        # Obter o valor do gatilho no passo atual\n",
    "        gatilho = int(self.data['Gatilho'].iloc[self.current_step])\n",
    "\n",
    "        # Se o gatilho estiver ativo, o agente pode executar todas as ações\n",
    "        if gatilho == 1:\n",
    "            if action == 1:  # Comprar\n",
    "                if self.position == 0:\n",
    "                    self.position = 1  # Abrir posição comprada\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step\n",
    "                    self.entry_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime\n",
    "                    }\n",
    "                elif self.position == -1:\n",
    "                    # Fechar posição vendida\n",
    "                    self.exit_price = current_price\n",
    "                    profit = self.entry_price - self.exit_price - 0.25  # Ganho da posição vendida\n",
    "                    self.exit_step = self.current_step\n",
    "                    self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    # se o profit for negativo, multipliuca por 10\n",
    "                    if profit < 0:\n",
    "                        profit = profit * 10\n",
    "                    reward += profit\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_short',\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime,\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    })\n",
    "                    # Resetar posição\n",
    "                    self.position = 0\n",
    "                    self.entry_step = None\n",
    "                    self.entry_datetime = None\n",
    "            elif action == 2:  # Vender\n",
    "                if self.position == 0:\n",
    "                    self.position = -1  # Abrir posição vendida\n",
    "                    self.entry_price = current_price\n",
    "                    self.entry_step = self.current_step\n",
    "                    self.entry_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    reward -= 0.25  # Custo de operação\n",
    "                    info['trade'] = {\n",
    "                        'type': 'sell',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime\n",
    "                    }\n",
    "                elif self.position == 1:\n",
    "                    # Fechar posição comprada\n",
    "                    self.exit_price = current_price\n",
    "                    profit = self.exit_price - self.entry_price - 0.25  # Ganho da posição comprada\n",
    "                    self.exit_step = self.current_step\n",
    "                    self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                    # se o profit for negativo, multipliuca por 10\n",
    "                    if profit < 0:\n",
    "                        profit = profit * 10\n",
    "                    reward += profit\n",
    "                    info['trade'] = {\n",
    "                        'type': 'close_long',\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    }\n",
    "                    # Registrar a operação\n",
    "                    self.trades.append({\n",
    "                        'type': 'buy',\n",
    "                        'entry_step': self.entry_step,\n",
    "                        'entry_price': self.entry_price,\n",
    "                        'entry_datetime': self.entry_datetime,\n",
    "                        'exit_step': self.exit_step,\n",
    "                        'exit_price': self.exit_price,\n",
    "                        'exit_datetime': self.exit_datetime,\n",
    "                        'profit': profit\n",
    "                    })\n",
    "                    # Resetar posição\n",
    "                    self.position = 0\n",
    "                    self.entry_step = None\n",
    "                    self.entry_datetime = None\n",
    "            else:  # Manter\n",
    "                pass  # Nenhuma ação necessária\n",
    "        else:  # Gatilho == 0, nenhuma posição deve ser mantida\n",
    "            # Se há uma posição aberta, fechá-la\n",
    "            if self.position == 1:  # Fechar posição comprada\n",
    "                self.exit_price = current_price\n",
    "                profit = self.exit_price - self.entry_price - 0.25  # Ganho da posição comprada\n",
    "                self.exit_step = self.current_step\n",
    "                self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                reward += profit\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_long',\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                }\n",
    "                # Registrar a operação\n",
    "                self.trades.append({\n",
    "                    'type': 'buy',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'entry_datetime': self.entry_datetime,\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                })\n",
    "                # Resetar posição\n",
    "                self.position = 0\n",
    "                self.entry_step = None\n",
    "                self.entry_datetime = None\n",
    "            elif self.position == -1:  # Fechar posição vendida\n",
    "                self.exit_price = current_price\n",
    "                profit = self.entry_price - self.exit_price - 0.25  # Ganho da posição vendida\n",
    "                self.exit_step = self.current_step\n",
    "                self.exit_datetime = self.data['DateTime'].iloc[self.current_step]\n",
    "                reward += profit\n",
    "                info['trade'] = {\n",
    "                    'type': 'close_short',\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                }\n",
    "                # Registrar a operação\n",
    "                self.trades.append({\n",
    "                    'type': 'sell',\n",
    "                    'entry_step': self.entry_step,\n",
    "                    'entry_price': self.entry_price,\n",
    "                    'entry_datetime': self.entry_datetime,\n",
    "                    'exit_step': self.exit_step,\n",
    "                    'exit_price': self.exit_price,\n",
    "                    'exit_datetime': self.exit_datetime,\n",
    "                    'profit': profit\n",
    "                })\n",
    "                # Resetar posição\n",
    "                self.position = 0\n",
    "                self.entry_step = None\n",
    "                self.entry_datetime = None\n",
    "\n",
    "        # Atualizar o passo atual\n",
    "        self.current_step += 1\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        return obs, reward, done, info\n",
    "\n",
    "# Bloco 3: Criar o Agente DQN usando PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import random\n",
    "\n",
    "# Configurações do dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Criar o ambiente\n",
    "env = TradingEnv(data)\n",
    "\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Definir a rede DQN\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, obs_size, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(obs_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instanciar a rede\n",
    "q_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net = DQN(obs_size, n_actions).to(device)\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "# Definir o otimizador\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=1e-4)\n",
    "\n",
    "# Hiperparâmetros para DQN\n",
    "memory_size = 10000\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "epsilon_start = 0.5\n",
    "epsilon_end = 0.05\n",
    "epsilon_decay = 0.99\n",
    "target_update = 10  # Atualizar a rede alvo a cada 10 episódios\n",
    "\n",
    "# Inicializar a memória de replay\n",
    "memory = collections.deque(maxlen=memory_size)\n",
    "\n",
    "# Função para selecionar ação usando epsilon-greedy\n",
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice([0, 1, 2])\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = q_net(state)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "# Bloco 4: Treinamento do Agente DQN com Salvamento dos Melhores Episódios Após Cada Episódio\n",
    "\n",
    "num_episodes = 200  # Defina o número de episódios de treinamento\n",
    "epsilon = epsilon_start\n",
    "best_episodes = []\n",
    "\n",
    "save_dir = \"4.12\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    start_time = time.time()\n",
    "    obs = env.reset()\n",
    "    obs = torch.FloatTensor(obs).unsqueeze(0).to(device)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    actions_count = {0: 0, 1: 0, 2: 0}\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    win_total = 0\n",
    "    lose_total = 0\n",
    "    trades = []\n",
    "    current_trade = None\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "\n",
    "        # Selecionar ação\n",
    "        action = select_action(obs, epsilon)\n",
    "\n",
    "        # Executar ação no ambiente\n",
    "        obs_next, reward, done, info = env.step(action)\n",
    "        obs_next = torch.FloatTensor(obs_next).unsqueeze(0).to(device)\n",
    "\n",
    "        # Armazenar na memória de replay\n",
    "        memory.append((obs, action, reward, obs_next, done))\n",
    "\n",
    "        # Atualizar o estado\n",
    "        obs = obs_next\n",
    "\n",
    "        # Atualizar contagem de ações\n",
    "        actions_count[action] += 1\n",
    "\n",
    "        # Processar informações de trade\n",
    "        if 'trade' in info:\n",
    "            trade_info = info['trade']\n",
    "            if trade_info['type'] in ['buy', 'sell']:\n",
    "                # Início de uma nova operação\n",
    "                current_trade = {\n",
    "                    'type': trade_info['type'],\n",
    "                    'entry_step': trade_info['entry_step'],\n",
    "                    'entry_price': trade_info['entry_price'],\n",
    "                    'entry_datetime': trade_info['entry_datetime'],\n",
    "                    'exit_step': None,\n",
    "                    'exit_price': None,\n",
    "                    'exit_datetime': None,\n",
    "                    'profit': None\n",
    "                }\n",
    "            elif trade_info['type'] in ['close_long', 'close_short']:\n",
    "                # Fechamento de uma operação existente\n",
    "                current_trade['exit_step'] = trade_info['exit_step']\n",
    "                current_trade['exit_price'] = trade_info['exit_price']\n",
    "                current_trade['exit_datetime'] = trade_info['exit_datetime']\n",
    "                current_trade['profit'] = trade_info['profit']\n",
    "                trades.append(current_trade.copy())\n",
    "                # Atualizar ganhos e perdas\n",
    "                if current_trade['profit'] > 0:\n",
    "                    wins += 1\n",
    "                    win_total += current_trade['profit']\n",
    "                elif current_trade['profit'] < 0:\n",
    "                    losses += 1\n",
    "                    lose_total += current_trade['profit']\n",
    "                # Atualizar recompensa total\n",
    "                total_reward += current_trade['profit']\n",
    "                current_trade = None\n",
    "\n",
    "        # Treinar a rede se a memória tiver tamanho suficiente\n",
    "        if len(memory) >= batch_size:\n",
    "            batch = random.sample(memory, batch_size)\n",
    "            states, actions_batch, rewards_batch, next_states, dones = zip(*batch)\n",
    "\n",
    "            states = torch.cat(states).to(device)\n",
    "            actions_batch = torch.tensor(actions_batch, dtype=torch.long, device=device).unsqueeze(1)\n",
    "            rewards_batch = torch.tensor(rewards_batch, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            next_states = torch.cat(next_states).to(device)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            # Computar Q-valor atual\n",
    "            q_values = q_net(states).gather(1, actions_batch)\n",
    "\n",
    "            # Computar Q-valor alvo usando a rede alvo\n",
    "            with torch.no_grad():\n",
    "                next_q_values = target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "            target_q_values = rewards_batch + gamma * next_q_values * (1 - dones)\n",
    "\n",
    "            # Calcular a perda\n",
    "            loss = nn.MSELoss()(q_values, target_q_values)\n",
    "\n",
    "            # Otimizar a rede\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Decaimento de epsilon\n",
    "    epsilon = max(epsilon_end, epsilon_decay * epsilon)\n",
    "\n",
    "    # Atualizar a rede alvo\n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    # Cálculo do tempo de treinamento do episódio\n",
    "    end_time = time.time()\n",
    "    episode_time = end_time - start_time\n",
    "\n",
    "    win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0\n",
    "    print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward:.2f}, Win Rate: {win_rate:.2f}, \"\n",
    "          f\"Wins: {wins}, Losses: {losses}, Epsilon: {epsilon:.4f}, Steps: {steps}, Time: {episode_time:.2f}s\")\n",
    "    print(f\"Ações: Manter={actions_count[0]}, Comprar={actions_count[1]}, Vender={actions_count[2]}\")\n",
    "    print(f\"Ganhos Totais: {win_total:.2f}, Perdas Totais: {lose_total:.2f}\")\n",
    "\n",
    "    # Salvar informações do episódio\n",
    "    episode_info = {\n",
    "        'episode': episode + 1,\n",
    "        'total_reward': total_reward,\n",
    "        'win_rate': win_rate,\n",
    "        'wins': wins,\n",
    "        'losses': losses,\n",
    "        'actions_count': actions_count.copy(),\n",
    "        'win_total': win_total,\n",
    "        'lose_total': lose_total,\n",
    "        'steps': steps,\n",
    "        'episode_time': episode_time,\n",
    "        'model_state_dict': q_net.state_dict(),\n",
    "        'trades': trades.copy()  # Salvar as operações do episódio\n",
    "    }\n",
    "\n",
    "    # Adicionar o episódio à lista e manter os top 10\n",
    "    best_episodes.append(episode_info)\n",
    "    best_episodes = sorted(best_episodes, key=lambda x: x['total_reward'], reverse=True)[:10]\n",
    "\n",
    "    # Salvar o modelo e log se o episódio for um dos top 10\n",
    "    if episode_info in best_episodes:\n",
    "        model_path = os.path.join(save_dir, f\"model_episode_{episode_info['episode']}.pth\")\n",
    "        torch.save(episode_info['model_state_dict'], model_path)\n",
    "        episode_info['model_path'] = model_path\n",
    "\n",
    "        # Salvar o log completo das operações\n",
    "        log_path = os.path.join(save_dir, f\"log_episode_{episode_info['episode']}.csv\")\n",
    "        trades_df = pd.DataFrame(episode_info['trades'])\n",
    "        trades_df.to_csv(log_path, index=False)\n",
    "        episode_info['log_path'] = log_path\n",
    "\n",
    "        print(f\"Modelo e log do episódio {episode_info['episode']} salvos em: {model_path} e {log_path}\\n\")\n",
    "\n",
    "print(\"\\nTreinamento finalizado.\")\n",
    "print(\"Top 10 Melhores Episódios:\")\n",
    "for idx, ep in enumerate(best_episodes, 1):\n",
    "    print(f\"Rank {idx}: Episode {ep['episode']}, Total Reward: {ep['total_reward']:.2f}, \"\n",
    "          f\"Win Rate: {ep['win_rate']:.2f}, Wins: {ep['wins']}, Losses: {ep['losses']}, \"\n",
    "          f\"Ações: {ep['actions_count']}, Steps: {ep['steps']}, Time: {ep['episode_time']:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
